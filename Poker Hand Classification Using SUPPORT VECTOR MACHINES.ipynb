{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries;\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set_style('white')\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import load_digits, make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler \n",
    "from sklearn.preprocessing import RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>1.1</th>\n",
       "      <th>11</th>\n",
       "      <th>1.2</th>\n",
       "      <th>13</th>\n",
       "      <th>1.3</th>\n",
       "      <th>12</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  10  1.1  11  1.2  13  1.3  12  1.4  1.5  9\n",
       "0  2  11    2  13    2  10    2  12    2    1  9\n",
       "1  3  12    3  11    3  13    3  10    3    1  9\n",
       "2  4  10    4  11    4   1    4  13    4   12  9\n",
       "3  4   1    4  13    4  12    4  11    4   10  9\n",
       "4  1   2    1   4    1   5    1   3    1    6  8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokerData = pd.read_csv('poker-hand-training-true.data')\n",
    "pokerData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Go from multi variable classification to binary by setting 2 pair, 3 of a kind and 4 of a kind to a 1, else 0\n",
    "\n",
    "pokerData.loc[pokerData['9'] == 1, '9'] = 0\n",
    "pokerData.loc[pokerData['9'] == 2, '9'] = 1\n",
    "pokerData.loc[pokerData['9'] == 3, '9'] = 1\n",
    "pokerData.loc[pokerData['9'] == 4, '9'] = 0\n",
    "pokerData.loc[pokerData['9'] == 5, '9'] = 0\n",
    "pokerData.loc[pokerData['9'] == 6, '9'] = 0\n",
    "pokerData.loc[pokerData['9'] == 7, '9'] = 1\n",
    "pokerData.loc[pokerData['9'] == 8, '9'] = 0\n",
    "pokerData.loc[pokerData['9'] == 9, '9'] = 0\n",
    "\n",
    "X = pokerData.iloc[:,0:9].values\n",
    "y = pokerData.iloc[:,10].values\n",
    "pokerData.head()\n",
    "\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size= 20000, random_state=1738)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL ONE ON POKER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL ONE RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = pokerData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_1_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL ONE RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.40064321, 0.41015458, 0.41165395, 0.4176609 , 0.41005211,\n",
       "        0.41185398, 0.42186284, 0.42956953, 0.47130547, 0.41715875,\n",
       "        0.41715865, 0.41335559, 0.4141562 , 0.41485658, 0.4145566 ,\n",
       "        0.43227172, 0.69119434, 1.8024498 , 0.43687539, 0.42215214,\n",
       "        0.40895162, 0.41245494, 0.42436466, 0.42966967, 0.51174035,\n",
       "        1.32163687, 3.0973639 , 0.47971206, 0.4438817 , 0.45509138,\n",
       "        0.4469842 , 0.43477368, 0.5535759 , 1.39900317, 1.48227563,\n",
       "        3.3587883 , 0.41465669, 0.40234571, 0.4090518 , 0.41225491,\n",
       "        0.48341537, 0.84792891, 2.00692606, 1.50249224, 3.5127212 ,\n",
       "        0.40604892, 0.40634947, 0.45479093, 0.4945251 , 1.20103297,\n",
       "        1.75020485, 2.29537368, 2.2381249 , 3.76373687, 0.5076365 ,\n",
       "        0.58730521, 0.95171833, 2.05646834, 2.0398541 , 2.29147043,\n",
       "        2.95444074, 2.2504354 , 3.61791129, 0.65386209, 0.84292474,\n",
       "        1.31863389, 1.95237899, 2.19118385, 2.95704288, 3.02219915,\n",
       "        2.1964891 , 3.50681572, 0.65456395, 0.80459194, 1.23386097,\n",
       "        2.03815284, 2.91340537, 3.10577102, 2.94943643, 2.16786413,\n",
       "        3.47618942, 0.45869474, 0.44107914, 0.43337264, 0.43977828,\n",
       "        0.42896886, 0.43077021, 0.43237176, 0.60241799, 1.12847018,\n",
       "        0.47570925, 0.46499977, 0.44998708, 0.45449128, 0.45419078,\n",
       "        0.45649257, 0.44228029, 0.69369659, 1.11025467, 0.4374764 ,\n",
       "        0.43887739, 0.42506542, 0.42756758, 0.42716737, 0.43107057,\n",
       "        0.43187146, 0.73403139, 1.12156463, 0.43697596, 0.43467374,\n",
       "        0.43006983, 0.42816839, 0.42876873, 0.43207173, 1.7522069 ,\n",
       "        0.71531515, 1.07922816, 0.43137088, 0.42356415, 0.42686691,\n",
       "        0.43077016, 0.43467379, 0.43737597, 1.79124045, 0.60502019,\n",
       "        1.05370569, 0.43177128, 0.42096171, 0.4260663 , 0.42706709,\n",
       "        0.43627481, 0.42936935, 1.90483818, 0.61182647, 1.13317466,\n",
       "        0.45729318, 0.47751045, 0.44668427, 0.43637519, 0.44428186,\n",
       "        2.10761271, 2.47873201, 0.66427126, 1.20013227, 0.4783114 ,\n",
       "        0.4828155 , 0.47961245, 0.47090449, 0.55037293, 2.49844861,\n",
       "        2.08779526, 0.62463703, 1.05991168, 0.43807712, 0.43857732,\n",
       "        0.44948659, 0.55457706, 1.47807078, 2.88958488, 2.07788658,\n",
       "        0.62233529, 1.1240665 , 0.33959246, 0.33568888, 0.2799408 ,\n",
       "        0.30335717, 0.30446181, 0.30656424, 0.30856519, 0.31316924,\n",
       "        0.723422  , 0.29575419, 0.28904862, 0.29175086, 0.27874031,\n",
       "        0.27763891, 0.30205979, 0.29625483, 0.43827715, 1.07142148,\n",
       "        0.30616336, 0.31336923, 0.31687245, 0.30246019, 0.28844776,\n",
       "        0.28634577, 0.27903986, 0.56979027, 2.23081851, 0.28654666,\n",
       "        0.28734694, 0.2791398 , 0.28664613, 0.29175048, 0.29055014,\n",
       "        0.36371217, 0.79308167, 2.26454735, 0.28154244, 0.28594608,\n",
       "        0.28514509, 0.2832437 , 0.3086659 , 0.30196099, 0.46419902,\n",
       "        1.05350609, 2.22241125, 0.29445348, 0.3253798 , 0.3041616 ,\n",
       "        0.30165915, 0.28404369, 0.27904019, 0.55037365, 2.29787641,\n",
       "        2.36823721, 0.28244352, 0.291851  , 0.28934875, 0.31206889,\n",
       "        0.36601467, 0.35610666, 0.81960387, 2.40326705, 2.4322916 ,\n",
       "        0.31947513, 0.3440958 , 0.3282825 , 0.35512743, 0.34089327,\n",
       "        0.47110538, 1.08873625, 2.22921696, 2.28986912, 0.30426173,\n",
       "        0.28074131, 0.28384414, 0.28974938, 0.29355259, 0.56148267,\n",
       "        2.22341218, 2.21450462, 2.21230264, 0.23770432, 0.22789593,\n",
       "        0.22969742, 0.2275959 , 0.23360105, 0.2506156 , 0.25501914,\n",
       "        0.24761319, 0.23420062, 0.23189945, 0.23660355, 0.2333005 ,\n",
       "        0.23059802, 0.23830519, 0.23460212, 0.24090734, 0.23350129,\n",
       "        0.23239975, 0.23790431, 0.23249998, 0.22889695, 0.23500195,\n",
       "        0.23420157, 0.23770461, 0.24000659, 0.22999763, 0.23590279,\n",
       "        0.29175105, 0.2858459 , 0.29155064, 0.29225125, 0.29375234,\n",
       "        0.29265161, 0.28784723, 0.29565444, 0.28574576, 0.9327023 ,\n",
       "        0.93790684, 0.92969952, 0.93930764, 0.93510442, 0.93240166,\n",
       "        0.93904443, 0.95382032, 0.94251056, 2.03164744, 2.00462356,\n",
       "        2.01303139, 2.00562496, 2.01593375, 1.9815043 , 1.9892107 ,\n",
       "        1.98911066, 1.99231343, 1.95778351, 1.95337973, 1.98210511,\n",
       "        1.97870188, 2.03184781, 2.03635178, 2.15175066, 2.30007811,\n",
       "        2.21570568, 2.25283747, 2.24242802, 2.143643  , 2.21460147,\n",
       "        2.14184189, 2.08079   , 2.15695519, 2.09620271, 2.04195595,\n",
       "        1.99331379, 2.09410076, 2.09740386, 2.05286541, 2.0668777 ,\n",
       "        1.98180418, 1.97169542, 1.84718838, 1.40921187]),\n",
       " 'std_fit_time': array([0.00374003, 0.01034707, 0.00609271, 0.00915489, 0.01869931,\n",
       "        0.01300745, 0.00818038, 0.01062313, 0.00662671, 0.01821905,\n",
       "        0.01004639, 0.00324325, 0.00995654, 0.01494285, 0.00746697,\n",
       "        0.01355212, 0.01664092, 0.01350022, 0.01513579, 0.00746082,\n",
       "        0.00097057, 0.00312373, 0.0081619 , 0.01122825, 0.00649905,\n",
       "        0.04274856, 0.06112045, 0.01733119, 0.02661608, 0.0272883 ,\n",
       "        0.00999542, 0.01181436, 0.01475535, 0.03171068, 0.02077334,\n",
       "        0.02080611, 0.00966499, 0.00358071, 0.00724928, 0.00551278,\n",
       "        0.0129496 , 0.02589022, 0.02140452, 0.02938094, 0.03348705,\n",
       "        0.00722173, 0.00286602, 0.037576  , 0.02913067, 0.07870358,\n",
       "        0.12352127, 0.07488454, 0.11473321, 0.14586285, 0.0355532 ,\n",
       "        0.0460792 , 0.05660705, 0.02113852, 0.09374601, 0.03031152,\n",
       "        0.07897514, 0.06804779, 0.06887568, 0.03418899, 0.05601446,\n",
       "        0.03214642, 0.03604708, 0.04644086, 0.01355037, 0.02866472,\n",
       "        0.04066923, 0.04814824, 0.011023  , 0.01563538, 0.02030709,\n",
       "        0.00591648, 0.03359262, 0.03390508, 0.05132621, 0.02490739,\n",
       "        0.03299123, 0.00867151, 0.00563211, 0.0138538 , 0.00630157,\n",
       "        0.00570925, 0.00684274, 0.00803815, 0.00741854, 0.02365515,\n",
       "        0.03369416, 0.02327799, 0.02459448, 0.03521172, 0.03873279,\n",
       "        0.02962685, 0.01555174, 0.01655607, 0.02705023, 0.00664196,\n",
       "        0.02610505, 0.00706717, 0.00354681, 0.00720777, 0.00563146,\n",
       "        0.00440835, 0.01429294, 0.02981904, 0.00297563, 0.0098553 ,\n",
       "        0.01206691, 0.00361657, 0.01656854, 0.01145791, 0.02253941,\n",
       "        0.01956823, 0.02465771, 0.01007338, 0.00832951, 0.00195116,\n",
       "        0.00759212, 0.00752694, 0.00814925, 0.02887023, 0.02229248,\n",
       "        0.03831912, 0.005621  , 0.00285539, 0.0038711 , 0.00610118,\n",
       "        0.00688652, 0.00650957, 0.06465394, 0.01720363, 0.07161579,\n",
       "        0.02785087, 0.04542911, 0.01401428, 0.01355042, 0.02007598,\n",
       "        0.12177008, 0.06400293, 0.05786718, 0.08325723, 0.0310904 ,\n",
       "        0.02567453, 0.02513861, 0.02525515, 0.02261421, 0.02097914,\n",
       "        0.02761905, 0.02855946, 0.02336947, 0.00652144, 0.01124156,\n",
       "        0.02385431, 0.04058762, 0.05940214, 0.06582371, 0.03868363,\n",
       "        0.01868585, 0.09037233, 0.05795275, 0.0497168 , 0.01528903,\n",
       "        0.0066155 , 0.01985287, 0.01912857, 0.0242544 , 0.0063566 ,\n",
       "        0.01045211, 0.01446225, 0.00807931, 0.00336456, 0.00599699,\n",
       "        0.0079845 , 0.01064214, 0.01097758, 0.00780053, 0.04618926,\n",
       "        0.00737771, 0.01410958, 0.01821843, 0.02120226, 0.01471183,\n",
       "        0.01124966, 0.00372608, 0.0233125 , 0.04648413, 0.00335848,\n",
       "        0.00430967, 0.00959691, 0.01304349, 0.00438563, 0.01242673,\n",
       "        0.03126734, 0.05256876, 0.0437703 , 0.00573733, 0.00660568,\n",
       "        0.00771639, 0.01153406, 0.01574065, 0.02604089, 0.03128815,\n",
       "        0.05834332, 0.03912677, 0.01896301, 0.01872314, 0.00987986,\n",
       "        0.02479889, 0.0042656 , 0.00461481, 0.01498744, 0.0704533 ,\n",
       "        0.09254501, 0.00647621, 0.00235569, 0.01624471, 0.02052962,\n",
       "        0.04374391, 0.03346799, 0.02496584, 0.04523797, 0.14318519,\n",
       "        0.02750046, 0.03102265, 0.03188661, 0.04277371, 0.05930154,\n",
       "        0.04977848, 0.04401501, 0.01656869, 0.04380579, 0.02653128,\n",
       "        0.00990785, 0.00756554, 0.01275844, 0.01449202, 0.01945655,\n",
       "        0.03143098, 0.06493418, 0.03068981, 0.01835148, 0.00602674,\n",
       "        0.00432788, 0.00922407, 0.00870491, 0.02689965, 0.0282973 ,\n",
       "        0.01834439, 0.00719618, 0.00265975, 0.00489685, 0.00594967,\n",
       "        0.00371038, 0.00829819, 0.00339989, 0.01223579, 0.00782075,\n",
       "        0.00784633, 0.00672601, 0.00383207, 0.00326796, 0.00604302,\n",
       "        0.00924371, 0.00466214, 0.00431164, 0.00659777, 0.00358917,\n",
       "        0.00592081, 0.00637271, 0.00358931, 0.00970362, 0.00453149,\n",
       "        0.00305914, 0.00801541, 0.00463441, 0.0048312 , 0.00536553,\n",
       "        0.00971114, 0.02640335, 0.01441717, 0.01174309, 0.01589581,\n",
       "        0.02458656, 0.01682237, 0.0164356 , 0.03374044, 0.02409229,\n",
       "        0.0237137 , 0.03735948, 0.03300701, 0.00722806, 0.01163333,\n",
       "        0.02206762, 0.02530088, 0.00672437, 0.01180257, 0.02933629,\n",
       "        0.02222967, 0.06366949, 0.07845187, 0.05845766, 0.16541567,\n",
       "        0.13670551, 0.14594001, 0.15699974, 0.09208891, 0.07042196,\n",
       "        0.06917775, 0.08758098, 0.03736388, 0.04812295, 0.09090024,\n",
       "        0.02660423, 0.0322031 , 0.04286972, 0.05651282, 0.04694471,\n",
       "        0.04352823, 0.0226244 , 0.0546946 , 0.16362035]),\n",
       " 'mean_score_time': array([0.03753223, 0.03873162, 0.03953538, 0.04103265, 0.03613105,\n",
       "        0.03643136, 0.03673172, 0.03643112, 0.03763218, 0.036131  ,\n",
       "        0.0361311 , 0.03853288, 0.0378324 , 0.03663149, 0.03753219,\n",
       "        0.03763242, 0.05224547, 0.12560802, 0.03903379, 0.03673182,\n",
       "        0.03733225, 0.03773217, 0.04193635, 0.03923373, 0.05144448,\n",
       "        0.07866745, 0.19526744, 0.03933411, 0.04013462, 0.03863311,\n",
       "        0.03853364, 0.04083529, 0.04904232, 0.06065216, 0.06635637,\n",
       "        0.19526796, 0.03763208, 0.03873324, 0.0377327 , 0.03763227,\n",
       "        0.05174475, 0.05975151, 0.0653563 , 0.06735778, 0.19556799,\n",
       "        0.03713198, 0.03853312, 0.04183598, 0.04303699, 0.07586532,\n",
       "        0.07996917, 0.08136992, 0.08897648, 0.19636879, 0.03893385,\n",
       "        0.04363751, 0.04603953, 0.05634847, 0.0921792 , 0.09838467,\n",
       "        0.16274004, 0.09348092, 0.1928659 , 0.04353747, 0.03913383,\n",
       "        0.04253659, 0.06405501, 0.09358039, 0.16344075, 0.1517303 ,\n",
       "        0.08217101, 0.19396663, 0.0390327 , 0.04003458, 0.04403811,\n",
       "        0.06735787, 0.16964574, 0.17434978, 0.16063819, 0.08167052,\n",
       "        0.20027223, 0.04213643, 0.04003434, 0.04003439, 0.04033484,\n",
       "        0.04033465, 0.03873358, 0.04033504, 0.04003439, 0.06045218,\n",
       "        0.0417356 , 0.04463849, 0.04563913, 0.04003401, 0.04023447,\n",
       "        0.03993421, 0.04023495, 0.04023471, 0.0594511 , 0.04073467,\n",
       "        0.0445385 , 0.04023466, 0.03963408, 0.03933363, 0.039434  ,\n",
       "        0.04173598, 0.04093518, 0.0595511 , 0.04053473, 0.03943419,\n",
       "        0.03903341, 0.03993411, 0.04043489, 0.03993416, 0.0428369 ,\n",
       "        0.0403347 , 0.06085253, 0.04053493, 0.03903356, 0.04023504,\n",
       "        0.03963428, 0.03903365, 0.03980246, 0.04153571, 0.03913388,\n",
       "        0.05945106, 0.04043498, 0.03973393, 0.03923373, 0.04023442,\n",
       "        0.04123564, 0.04053488, 0.04754138, 0.03933382, 0.05895066,\n",
       "        0.04193611, 0.04233656, 0.03973403, 0.04343767, 0.04133568,\n",
       "        0.0667573 , 0.05494695, 0.0454391 , 0.06275396, 0.04373755,\n",
       "        0.04223633, 0.04403782, 0.045439  , 0.05184464, 0.08337183,\n",
       "        0.04463873, 0.03963456, 0.06045194, 0.04183536, 0.04133534,\n",
       "        0.04373779, 0.05845032, 0.08307142, 0.08597369, 0.04343753,\n",
       "        0.03933382, 0.06855936, 0.03342857, 0.02502127, 0.02432165,\n",
       "        0.02602267, 0.03623118, 0.02442074, 0.02632279, 0.03032613,\n",
       "        0.03703165, 0.02502151, 0.0250217 , 0.02462134, 0.02592182,\n",
       "        0.02642283, 0.02752385, 0.02592258, 0.03092685, 0.04253654,\n",
       "        0.02652273, 0.02742386, 0.02582221, 0.0267231 , 0.02622304,\n",
       "        0.02572227, 0.02482176, 0.03593068, 0.0436377 , 0.02562199,\n",
       "        0.02542186, 0.02512159, 0.02772398, 0.02802482, 0.02972565,\n",
       "        0.02952547, 0.03723197, 0.04103537, 0.02482119, 0.02522163,\n",
       "        0.02442102, 0.02622275, 0.02952552, 0.02802272, 0.03533096,\n",
       "        0.04213586, 0.04193583, 0.02682295, 0.02432051, 0.02582231,\n",
       "        0.02412066, 0.02462125, 0.02962532, 0.03472991, 0.04884233,\n",
       "        0.05474696, 0.02672248, 0.02612267, 0.02762418, 0.03212738,\n",
       "        0.02732372, 0.03042631, 0.0387332 , 0.05194407, 0.04754128,\n",
       "        0.02572436, 0.02662301, 0.03072615, 0.03380747, 0.03342896,\n",
       "        0.03212771, 0.04223619, 0.04223623, 0.0417357 , 0.02462111,\n",
       "        0.02492166, 0.02842436, 0.02772374, 0.02612271, 0.03482966,\n",
       "        0.04273696, 0.04193587, 0.04443817, 0.02041769, 0.02051783,\n",
       "        0.0215189 , 0.02241955, 0.02111826, 0.02562184, 0.02071805,\n",
       "        0.02111793, 0.02051835, 0.02181888, 0.02161841, 0.022019  ,\n",
       "        0.02131848, 0.02191892, 0.02211905, 0.02201886, 0.0234201 ,\n",
       "        0.02101808, 0.02171874, 0.02191882, 0.02332034, 0.02131834,\n",
       "        0.02221909, 0.02241902, 0.02101793, 0.0216186 , 0.02271934,\n",
       "        0.02642279, 0.02702365, 0.02822437, 0.02492161, 0.02592239,\n",
       "        0.02662301, 0.02562251, 0.0293252 , 0.02552185, 0.03763237,\n",
       "        0.03663144, 0.03703179, 0.03813295, 0.03713155, 0.0372323 ,\n",
       "        0.03689494, 0.03753242, 0.03583126, 0.03863287, 0.04063563,\n",
       "        0.03693161, 0.03803253, 0.03583083, 0.03693171, 0.03903356,\n",
       "        0.03683195, 0.03733201, 0.03803287, 0.03673167, 0.03693137,\n",
       "        0.03893304, 0.04123511, 0.04073524, 0.03923421, 0.04814138,\n",
       "        0.04974232, 0.04293723, 0.04774103, 0.03993435, 0.03923392,\n",
       "        0.04744081, 0.03873277, 0.04684029, 0.03683243, 0.0369318 ,\n",
       "        0.04003458, 0.04303708, 0.03733211, 0.03763223, 0.03703141,\n",
       "        0.03593082, 0.03352895, 0.0241209 , 0.02051773]),\n",
       " 'std_score_time': array([0.00130501, 0.00314487, 0.00311804, 0.00851103, 0.00049049,\n",
       "        0.0008007 , 0.00092798, 0.00097049, 0.00058353, 0.0005835 ,\n",
       "        0.00049062, 0.00226021, 0.00244357, 0.00049058, 0.00054803,\n",
       "        0.0003745 , 0.0025037 , 0.0033342 , 0.00303572, 0.00116737,\n",
       "        0.000679  , 0.00074883, 0.00691525, 0.00180732, 0.01122704,\n",
       "        0.0075257 , 0.01101551, 0.00175066, 0.00327997, 0.00295876,\n",
       "        0.00130462, 0.00262148, 0.00301923, 0.00159498, 0.00299567,\n",
       "        0.00310744, 0.00058346, 0.00341765, 0.0006005 , 0.00058359,\n",
       "        0.00098075, 0.00229556, 0.00335842, 0.00383238, 0.00377726,\n",
       "        0.00058345, 0.00114116, 0.00432352, 0.00245142, 0.00356118,\n",
       "        0.00772341, 0.0045821 , 0.00668725, 0.01008129, 0.00229116,\n",
       "        0.00139398, 0.00450944, 0.0017509 , 0.00698782, 0.00762637,\n",
       "        0.01441169, 0.01424428, 0.00372593, 0.00966224, 0.0015635 ,\n",
       "        0.00629016, 0.01288341, 0.00245136, 0.00372625, 0.00285536,\n",
       "        0.00554912, 0.00453846, 0.00176062, 0.00176189, 0.00685441,\n",
       "        0.00235992, 0.00907981, 0.00861301, 0.00788096, 0.00407028,\n",
       "        0.00995532, 0.00351576, 0.00070797, 0.00083728, 0.00087294,\n",
       "        0.0019664 , 0.00040079, 0.00087247, 0.0008953 , 0.00213291,\n",
       "        0.00375297, 0.00553125, 0.00785138, 0.00083728, 0.00175055,\n",
       "        0.00149811, 0.00156988, 0.00103054, 0.00086101, 0.00103068,\n",
       "        0.00460828, 0.00312696, 0.00106861, 0.00098084, 0.00049052,\n",
       "        0.00317456, 0.0031712 , 0.00114105, 0.00181826, 0.00091724,\n",
       "        0.00151775, 0.00139421, 0.0019355 , 0.00149768, 0.00128972,\n",
       "        0.00074903, 0.00150461, 0.00104962, 0.00077546, 0.00081304,\n",
       "        0.00080051, 0.00031628, 0.00163196, 0.00118426, 0.00066382,\n",
       "        0.00203659, 0.0006636 , 0.00081308, 0.00081306, 0.0006787 ,\n",
       "        0.00175086, 0.00083734, 0.0106108 , 0.00163216, 0.00171622,\n",
       "        0.0039708 , 0.00231721, 0.00092808, 0.00519489, 0.00092844,\n",
       "        0.00842519, 0.00769684, 0.00722706, 0.00613383, 0.00679249,\n",
       "        0.001209  , 0.00629003, 0.00574425, 0.00194058, 0.00314284,\n",
       "        0.00233434, 0.00156388, 0.00171629, 0.00229485, 0.00180758,\n",
       "        0.00401089, 0.00705857, 0.00456443, 0.00527131, 0.00185653,\n",
       "        0.00191501, 0.01486183, 0.01710699, 0.0010503 , 0.00051101,\n",
       "        0.00148424, 0.00933853, 0.00111481, 0.00116742, 0.00763256,\n",
       "        0.00083743, 0.00094937, 0.00077528, 0.00073541, 0.00201158,\n",
       "        0.00382922, 0.0022157 , 0.00198676, 0.00132022, 0.00181763,\n",
       "        0.00219282, 0.00259849, 0.0009806 , 0.00188866, 0.00216061,\n",
       "        0.00136494, 0.0009804 , 0.00159477, 0.00304241, 0.00208527,\n",
       "        0.00066408, 0.00252033, 0.00199182, 0.00243131, 0.00183443,\n",
       "        0.00192511, 0.00169254, 0.00151785, 0.0006787 , 0.00116728,\n",
       "        0.00020006, 0.00252383, 0.00510359, 0.00352507, 0.00220657,\n",
       "        0.0013941 , 0.00120111, 0.0024638 , 0.00067913, 0.00196615,\n",
       "        0.00066418, 0.00058348, 0.00892055, 0.0013647 , 0.00769158,\n",
       "        0.00769139, 0.00213686, 0.00397051, 0.00425121, 0.00591592,\n",
       "        0.00448316, 0.00377697, 0.00250389, 0.0099708 , 0.00523939,\n",
       "        0.00143648, 0.00097016, 0.00601853, 0.00512833, 0.00516531,\n",
       "        0.00247979, 0.00103057, 0.0017507 , 0.00196649, 0.00058346,\n",
       "        0.00080058, 0.00338511, 0.00480634, 0.00132026, 0.00143651,\n",
       "        0.00218346, 0.00128186, 0.0030421 , 0.00086112, 0.00114114,\n",
       "        0.00104982, 0.00357247, 0.00128189, 0.00682837, 0.00067864,\n",
       "        0.00073549, 0.00031583, 0.0007489 , 0.00174476, 0.00114097,\n",
       "        0.00160127, 0.00128148, 0.00159517, 0.00083723, 0.0025204 ,\n",
       "        0.00114124, 0.00092844, 0.00097059, 0.00500024, 0.00087245,\n",
       "        0.00024517, 0.0026369 , 0.00104976, 0.00132038, 0.00107791,\n",
       "        0.00111462, 0.00130484, 0.00225145, 0.00058376, 0.00115855,\n",
       "        0.00231334, 0.00106894, 0.00823281, 0.00077546, 0.00091751,\n",
       "        0.00182925, 0.0014845 , 0.00271162, 0.00153096, 0.00196627,\n",
       "        0.00180373, 0.00200211, 0.00087259, 0.00217948, 0.00434432,\n",
       "        0.00159518, 0.00245161, 0.00169281, 0.00222416, 0.00574095,\n",
       "        0.00175058, 0.00128923, 0.00158274, 0.00107793, 0.00215528,\n",
       "        0.00282042, 0.00341792, 0.00291089, 0.00156994, 0.00597529,\n",
       "        0.00341744, 0.00419146, 0.01299044, 0.00331028, 0.00427714,\n",
       "        0.01165666, 0.00124986, 0.00887119, 0.00074762, 0.00146426,\n",
       "        0.00370507, 0.00418723, 0.00051029, 0.00271159, 0.00303546,\n",
       "        0.00086112, 0.00281363, 0.00185621, 0.00054807]),\n",
       " 'param_classifier': masked_array(data=[SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__gamma': masked_array(data=[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'}],\n",
       " 'split0_test_recall_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.94 ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.913, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.803, 0.891, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.75 , 0.831, 0.891, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.775, 0.683, 0.678, 0.891, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.91 , 0.898,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.903, 0.899,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.893, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911, 0.901, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.847, 0.892, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.634, 0.818, 0.894, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.862,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.862, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.862, 0.861, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709,\n",
       "        0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706,\n",
       "        0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706,\n",
       "        0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706]),\n",
       " 'split1_test_recall_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.939,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.902, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.887, 0.878, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.657, 0.734, 0.878, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.8  , 0.732, 0.747, 0.878, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.9  ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.914, 0.868,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.886, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.877, 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.901, 0.88 , 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.866, 0.884, 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.654, 0.762, 0.869, 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.878,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.903, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.886, 0.848, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688,\n",
       "        0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701,\n",
       "        0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701,\n",
       "        0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701]),\n",
       " 'split2_test_recall_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.937,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.933, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.896, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.772, 0.886, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.867, 0.689, 0.886, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.687, 0.789, 0.689, 0.886, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.913,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.913, 0.865,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.885, 0.88 ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.885, 0.872,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.908, 0.874, 0.876,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.871, 0.88 , 0.876,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.7  , 0.793, 0.868, 0.876,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.815, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ]),\n",
       " 'split3_test_recall_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.939,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.935, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.912, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.855, 0.889, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.867, 0.661, 0.897, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.775, 0.791, 0.705, 0.897, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.891,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911, 0.871,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.894, 0.87 ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.888, 0.869,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.91 , 0.886, 0.873,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.853, 0.885, 0.873,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.672, 0.794, 0.889, 0.873,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.867,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.891, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.877, 0.858, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705,\n",
       "        0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707,\n",
       "        0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707,\n",
       "        0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707]),\n",
       " 'split4_test_recall_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.939,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.935, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.908, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.803, 0.89 , 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.752, 0.838, 0.89 , 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.729, 0.77 , 0.838, 0.89 , 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.902,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911, 0.888,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.891, 0.895,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.89 , 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.908, 0.874, 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.869, 0.876, 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.692, 0.853, 0.881, 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.883,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.888, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.888, 0.846, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.654, 0.654, 0.654, 0.654, 0.654, 0.654, 0.654, 0.654, 0.654,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709]),\n",
       " 'mean_test_recall_micro': array([0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9388, 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9334, 0.944 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.9062, 0.944 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.824 , 0.8868, 0.944 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.7786, 0.7506, 0.8884, 0.944 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.7532, 0.753 , 0.7314, 0.8884,\n",
       "        0.944 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9034, 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9118, 0.878 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.8918, 0.8784, 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8866, 0.8756, 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.9076, 0.883 , 0.8772,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8612, 0.8834,\n",
       "        0.8772, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.6704, 0.804 ,\n",
       "        0.8802, 0.8772, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.8676, 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8456, 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8456, 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8784, 0.8456,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8456,\n",
       "        0.8456, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.8456, 0.8456, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.8722, 0.8456, 0.8456, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.6842, 0.6842, 0.6842, 0.6842, 0.6842, 0.6842, 0.6842, 0.6842,\n",
       "        0.6842, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926,\n",
       "        0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926,\n",
       "        0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926,\n",
       "        0.6926, 0.6926, 0.6926, 0.6926]),\n",
       " 'std_test_recall_micro': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0009798 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00135647, 0.00109545,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0064    , 0.00109545, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04126984, 0.00470744, 0.00109545, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07992647, 0.0723895 ,\n",
       "        0.00628013, 0.00109545, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04027108, 0.04091455, 0.0582292 , 0.00628013,\n",
       "        0.00109545, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00796492, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00146969, 0.01279062, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00649307,\n",
       "        0.0184239 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0054626 , 0.0129244 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00349857, 0.01003992, 0.01243222, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00947418, 0.00535164, 0.01243222, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02424541, 0.0302721 ,\n",
       "        0.01041921, 0.01243222, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01233856, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01632912, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01632912, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.02024451,\n",
       "        0.01632912, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01632912, 0.01632912,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01632912, 0.01632912, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0151842 , 0.01632912, 0.01632912, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02164625, 0.02164625,\n",
       "        0.02164625, 0.02164625, 0.02164625, 0.02164625, 0.02164625,\n",
       "        0.02164625, 0.02164625, 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ]),\n",
       " 'rank_test_recall_micro': array([  8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   6,   8,   8,   8,\n",
       "          8,   8,   8,   8,   7,   1,   8,   8,   8,   8,   8,   8,   8,\n",
       "        252,   1,   8,   8,   8,   8,   8,   8, 281, 257,   1,   8,   8,\n",
       "          8,   8,   8, 283, 286, 255,   1,   8,   8,   8,   8, 284, 285,\n",
       "        287, 255,   1,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8, 253,   8,   8,   8,   8,   8,   8,   8, 250, 264,\n",
       "          8,   8,   8,   8,   8,   8,   8, 254, 263,   8,   8,   8,   8,\n",
       "          8,   8,   8, 258, 268,   8,   8,   8,   8,   8,   8, 251, 260,\n",
       "        265,   8,   8,   8,   8,   8,   8, 271, 259, 265,   8,   8,   8,\n",
       "          8,   8, 324, 282, 261, 265,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8, 270,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 272,   8,   8,   8,   8,   8,   8,   8,   8, 272,   8,\n",
       "          8,   8,   8,   8,   8,   8, 262, 272,   8,   8,   8,   8,   8,\n",
       "          8,   8, 272, 272,   8,   8,   8,   8,   8,   8,   8, 272, 272,\n",
       "          8,   8,   8,   8,   8,   8, 269, 272, 272,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 315, 315, 315, 315, 315, 315, 315, 315, 315, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288]),\n",
       " 'split0_test_f1_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.94 ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.913, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.803, 0.891, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.75 , 0.831, 0.891, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.775, 0.683, 0.678, 0.891, 0.946,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.91 , 0.898,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.903, 0.899,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.893, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911, 0.901, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.847, 0.892, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.634, 0.818, 0.894, 0.893,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.862,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.862, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.861, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.862, 0.861, 0.861,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709,\n",
       "        0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706,\n",
       "        0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706,\n",
       "        0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706]),\n",
       " 'split1_test_f1_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.939,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.902, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.887, 0.878, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.657, 0.734, 0.878, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.8  , 0.732, 0.747, 0.878, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.9  ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.914, 0.868,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.886, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.877, 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.901, 0.88 , 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.866, 0.884, 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.654, 0.762, 0.869, 0.857,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.878,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.903, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.886, 0.848, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688,\n",
       "        0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701,\n",
       "        0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701,\n",
       "        0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701]),\n",
       " 'split2_test_f1_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.937,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.933, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.896, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.772, 0.886, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.867, 0.689, 0.886, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.687, 0.789, 0.689, 0.886, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.913,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.913, 0.865,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.885, 0.88 ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.885, 0.872,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.908, 0.874, 0.876,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.871, 0.88 , 0.876,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.7  , 0.793, 0.868, 0.876,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.815, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.848, 0.815, 0.815,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ]),\n",
       " 'split3_test_f1_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.939,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.935, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.912, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.855, 0.889, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.867, 0.661, 0.897, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.775, 0.791, 0.705, 0.897, 0.944,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.891,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911, 0.871,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.894, 0.87 ,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.888, 0.869,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.91 , 0.886, 0.873,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.853, 0.885, 0.873,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.672, 0.794, 0.889, 0.873,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.867,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.891, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.858, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.877, 0.858, 0.858,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705,\n",
       "        0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707,\n",
       "        0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707,\n",
       "        0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707]),\n",
       " 'split4_test_f1_micro': array([0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.939,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.935, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.908, 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.803, 0.89 , 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.752, 0.838, 0.89 , 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.729, 0.77 , 0.838, 0.89 , 0.943,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.902,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.911, 0.888,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.891, 0.895,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.89 , 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.908, 0.874, 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.869, 0.876, 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.692, 0.853, 0.881, 0.887,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.883,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.888, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.846, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.888, 0.846, 0.846,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932,\n",
       "        0.654, 0.654, 0.654, 0.654, 0.654, 0.654, 0.654, 0.654, 0.654,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709,\n",
       "        0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709]),\n",
       " 'mean_test_f1_micro': array([0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9388, 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9334, 0.944 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.9062, 0.944 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.824 , 0.8868, 0.944 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.7786, 0.7506, 0.8884, 0.944 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.7532, 0.753 , 0.7314, 0.8884,\n",
       "        0.944 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9034, 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.9118, 0.878 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.8918, 0.8784, 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8866, 0.8756, 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.9076, 0.883 , 0.8772,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8612, 0.8834,\n",
       "        0.8772, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.6704, 0.804 ,\n",
       "        0.8802, 0.8772, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.8676, 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8456, 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8456, 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8784, 0.8456,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.8456,\n",
       "        0.8456, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.8456, 0.8456, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.8722, 0.8456, 0.8456, 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 , 0.932 ,\n",
       "        0.6842, 0.6842, 0.6842, 0.6842, 0.6842, 0.6842, 0.6842, 0.6842,\n",
       "        0.6842, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926,\n",
       "        0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926,\n",
       "        0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926, 0.6926,\n",
       "        0.6926, 0.6926, 0.6926, 0.6926]),\n",
       " 'std_test_f1_micro': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0009798 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00135647, 0.00109545,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0064    , 0.00109545, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04126984, 0.00470744, 0.00109545, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07992647, 0.0723895 ,\n",
       "        0.00628013, 0.00109545, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04027108, 0.04091455, 0.0582292 , 0.00628013,\n",
       "        0.00109545, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00796492, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00146969, 0.01279062, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00649307,\n",
       "        0.0184239 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0054626 , 0.0129244 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00349857, 0.01003992, 0.01243222, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00947418, 0.00535164, 0.01243222, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02424541, 0.0302721 ,\n",
       "        0.01041921, 0.01243222, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01233856, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01632912, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01632912, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.02024451,\n",
       "        0.01632912, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01632912, 0.01632912,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01632912, 0.01632912, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0151842 , 0.01632912, 0.01632912, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02164625, 0.02164625,\n",
       "        0.02164625, 0.02164625, 0.02164625, 0.02164625, 0.02164625,\n",
       "        0.02164625, 0.02164625, 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ,\n",
       "        0.0264318 , 0.0264318 , 0.0264318 , 0.0264318 ]),\n",
       " 'rank_test_f1_micro': array([  8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   6,   8,   8,   8,\n",
       "          8,   8,   8,   8,   7,   1,   8,   8,   8,   8,   8,   8,   8,\n",
       "        252,   1,   8,   8,   8,   8,   8,   8, 281, 257,   1,   8,   8,\n",
       "          8,   8,   8, 283, 286, 255,   1,   8,   8,   8,   8, 284, 285,\n",
       "        287, 255,   1,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8, 253,   8,   8,   8,   8,   8,   8,   8, 250, 264,\n",
       "          8,   8,   8,   8,   8,   8,   8, 254, 263,   8,   8,   8,   8,\n",
       "          8,   8,   8, 258, 268,   8,   8,   8,   8,   8,   8, 251, 260,\n",
       "        265,   8,   8,   8,   8,   8,   8, 271, 259, 265,   8,   8,   8,\n",
       "          8,   8, 324, 282, 261, 265,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8, 270,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 272,   8,   8,   8,   8,   8,   8,   8,   8, 272,   8,\n",
       "          8,   8,   8,   8,   8,   8, 262, 272,   8,   8,   8,   8,   8,\n",
       "          8,   8, 272, 272,   8,   8,   8,   8,   8,   8,   8, 272, 272,\n",
       "          8,   8,   8,   8,   8,   8, 269, 272, 272,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 315, 315, 315, 315, 315, 315, 315, 315, 315, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288]),\n",
       " 'split0_test_roc_auc_ovo': array([0.42367773, 0.55094989, 0.44923946, 0.54514327, 0.57274047,\n",
       "        0.48991732, 0.5325202 , 0.5568354 , 0.67314125, 0.46910502,\n",
       "        0.51205504, 0.42803269, 0.50629576, 0.57274047, 0.48991732,\n",
       "        0.52884373, 0.64259341, 0.70231633, 0.49414605, 0.5       ,\n",
       "        0.50271396, 0.54514327, 0.57274047, 0.51331734, 0.51964466,\n",
       "        0.63904317, 0.71266726, 0.54244509, 0.43374464, 0.48945973,\n",
       "        0.45485673, 0.57135193, 0.52008647, 0.56753345, 0.63257384,\n",
       "        0.70938526, 0.54244509, 0.56625536, 0.48930194, 0.56829084,\n",
       "        0.49826433, 0.58075612, 0.58304405, 0.639769  , 0.71082113,\n",
       "        0.45755491, 0.56625536, 0.53939977, 0.52985357, 0.50227215,\n",
       "        0.52120677, 0.57409745, 0.63785976, 0.71142073, 0.54145102,\n",
       "        0.42093221, 0.56125347, 0.46822141, 0.50189346, 0.50951464,\n",
       "        0.56653938, 0.62703547, 0.70955882, 0.51819301, 0.49111651,\n",
       "        0.44993373, 0.46736935, 0.5580977 , 0.54118278, 0.48909682,\n",
       "        0.62782441, 0.70895923, 0.51522658, 0.4445847 , 0.48693512,\n",
       "        0.49305731, 0.52819679, 0.53507637, 0.53121055, 0.62787175,\n",
       "        0.71061601, 0.50272974, 0.52523037, 0.56382542, 0.46481318,\n",
       "        0.55898132, 0.54164037, 0.48461563, 0.54978225, 0.54911954,\n",
       "        0.5297589 , 0.58689409, 0.5       , 0.53518682, 0.55898132,\n",
       "        0.54164037, 0.54508016, 0.5676439 , 0.5581766 , 0.58689409,\n",
       "        0.5       , 0.56382542, 0.53518682, 0.55898132, 0.47011487,\n",
       "        0.40299167, 0.56171106, 0.56073277, 0.58689409, 0.5297589 ,\n",
       "        0.43617458, 0.46481318, 0.47227657, 0.51216549, 0.58318606,\n",
       "        0.56423567, 0.55342716, 0.58689409, 0.5297589 , 0.56382542,\n",
       "        0.44706198, 0.48767672, 0.51285976, 0.57655895, 0.57577001,\n",
       "        0.56185307, 0.41310591, 0.5297589 , 0.47719957, 0.49921106,\n",
       "        0.414526  , 0.5403465 , 0.54954557, 0.552654  , 0.57588046,\n",
       "        0.58689409, 0.56109568, 0.46938904, 0.48952285, 0.44837162,\n",
       "        0.5577979 , 0.59244825, 0.56090634, 0.57578579, 0.53125789,\n",
       "        0.47958218, 0.4647974 , 0.42012749, 0.47071447, 0.50044181,\n",
       "        0.53614933, 0.55180194, 0.57453926, 0.54208218, 0.51113986,\n",
       "        0.47402802, 0.57621182, 0.49338866, 0.52321068, 0.4833691 ,\n",
       "        0.56352562, 0.57583312, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.50912806, 0.50913595, 0.50913595, 0.53577064,\n",
       "        0.4832902 , 0.5       , 0.5       , 0.5       , 0.49739649,\n",
       "        0.50913595, 0.50913595, 0.50913595, 0.50197236, 0.50740028,\n",
       "        0.5       , 0.5       , 0.5       , 0.47684455, 0.50913595,\n",
       "        0.5       , 0.50913595, 0.51650467, 0.48237503, 0.5       ,\n",
       "        0.5       , 0.49678112, 0.50912017, 0.50913595, 0.50913595,\n",
       "        0.53569174, 0.51486367, 0.51819301, 0.5       , 0.5       ,\n",
       "        0.50213803, 0.50913595, 0.49099817, 0.50913595, 0.50175145,\n",
       "        0.50637465, 0.51822456, 0.5       , 0.5       , 0.47697078,\n",
       "        0.50913595, 0.5       , 0.50913595, 0.51184991, 0.48248548,\n",
       "        0.51819301, 0.5       , 0.5       , 0.50919907, 0.50913595,\n",
       "        0.50913595, 0.53543928, 0.49711247, 0.51820879, 0.51819301,\n",
       "        0.5       , 0.47992931, 0.50913595, 0.50913595, 0.50913595,\n",
       "        0.50219326, 0.50313999, 0.48179121, 0.48180699, 0.5       ,\n",
       "        0.5100669 , 0.50913595, 0.50913595, 0.50913595, 0.51756185,\n",
       "        0.48251704, 0.51820879, 0.51819301, 0.50396049, 0.49585016,\n",
       "        0.50616953, 0.50408672, 0.50414984, 0.49585016, 0.49585016,\n",
       "        0.50394471, 0.50307687, 0.52616132, 0.52630333, 0.47369667,\n",
       "        0.47317597, 0.52630333, 0.47369667, 0.47369667, 0.52630333,\n",
       "        0.52630333, 0.51409051, 0.48619351, 0.48590949, 0.51409051,\n",
       "        0.51409051, 0.48669843, 0.48291151, 0.51409051, 0.51409051,\n",
       "        0.48611462, 0.51388538, 0.48611462, 0.51388538, 0.48611462,\n",
       "        0.51388538, 0.51388538, 0.51388538, 0.48611462, 0.54347071,\n",
       "        0.45652929, 0.54337604, 0.45652929, 0.4580125 , 0.45652929,\n",
       "        0.45652929, 0.45652929, 0.54345494, 0.47415425, 0.52584575,\n",
       "        0.52584575, 0.47593726, 0.47415425, 0.47415425, 0.47142451,\n",
       "        0.47415425, 0.47600038, 0.47696289, 0.47696289, 0.47420159,\n",
       "        0.52245329, 0.47696289, 0.52303711, 0.52303711, 0.47696289,\n",
       "        0.52278465, 0.52303711, 0.52303711, 0.52294244, 0.52303711,\n",
       "        0.52303711, 0.47696289, 0.52303711, 0.47696289, 0.47696289,\n",
       "        0.52303711, 0.52303711, 0.52303711, 0.52303711, 0.52303711,\n",
       "        0.47696289, 0.52303711, 0.52303711, 0.477026  ]),\n",
       " 'split1_test_roc_auc_ovo': array([0.50099407, 0.52463078, 0.54111967, 0.52486746, 0.52261108,\n",
       "        0.48464719, 0.49747539, 0.58227089, 0.74236304, 0.48191745,\n",
       "        0.43246655, 0.5       , 0.48622507, 0.52261108, 0.48464719,\n",
       "        0.52671358, 0.68923567, 0.75809455, 0.43958281, 0.5       ,\n",
       "        0.48594105, 0.50156211, 0.52261108, 0.51629955, 0.56238955,\n",
       "        0.67448245, 0.7663311 , 0.5       , 0.46018998, 0.45996907,\n",
       "        0.54010982, 0.44084511, 0.53072141, 0.58227089, 0.67812737,\n",
       "        0.76454809, 0.45813873, 0.5423662 , 0.46186253, 0.52985357,\n",
       "        0.46733779, 0.53577064, 0.56573466, 0.67694395, 0.7658893 ,\n",
       "        0.54179816, 0.45757069, 0.4568922 , 0.52126988, 0.51219705,\n",
       "        0.57865754, 0.5988229 , 0.66043928, 0.76566839, 0.52158546,\n",
       "        0.50302954, 0.51508457, 0.53084764, 0.50579084, 0.55208596,\n",
       "        0.58173441, 0.64816334, 0.76464277, 0.53089498, 0.50975133,\n",
       "        0.5231949 , 0.52186948, 0.55748233, 0.49898226, 0.52527771,\n",
       "        0.64854203, 0.76413784, 0.55035029, 0.50474943, 0.51876105,\n",
       "        0.46650151, 0.49993688, 0.48344799, 0.48187011, 0.64832113,\n",
       "        0.76390116, 0.4792666 , 0.54986115, 0.5       , 0.5       ,\n",
       "        0.47555857, 0.49233148, 0.50530169, 0.49346756, 0.53452411,\n",
       "        0.51259941, 0.47575581, 0.5       , 0.52740785, 0.47707334,\n",
       "        0.49250505, 0.49491921, 0.52633489, 0.53946289, 0.4699413 ,\n",
       "        0.5       , 0.49796453, 0.52740785, 0.47508521, 0.49809076,\n",
       "        0.47716801, 0.52750252, 0.47506943, 0.5       , 0.48483653,\n",
       "        0.50203547, 0.52740785, 0.51481633, 0.50598018, 0.53397185,\n",
       "        0.5117079 , 0.53856349, 0.4699413 , 0.48483653, 0.50203547,\n",
       "        0.55113923, 0.52797589, 0.49878503, 0.52226395, 0.52732896,\n",
       "        0.54135635, 0.47289195, 0.47016221, 0.5425871 , 0.45176407,\n",
       "        0.52829147, 0.52807056, 0.52174325, 0.51779854, 0.54623201,\n",
       "        0.47022532, 0.53577064, 0.48430005, 0.50725827, 0.54080409,\n",
       "        0.50454431, 0.52521459, 0.531321  , 0.54612156, 0.51413784,\n",
       "        0.57494951, 0.48857612, 0.52313178, 0.47609505, 0.52108054,\n",
       "        0.53506059, 0.52633489, 0.54381785, 0.47405958, 0.47301818,\n",
       "        0.54249243, 0.47932971, 0.53441366, 0.49927417, 0.52302133,\n",
       "        0.52737629, 0.54646869, 0.5       , 0.5       , 0.5       ,\n",
       "        0.48109695, 0.48102594, 0.51898195, 0.51898195, 0.53272532,\n",
       "        0.59052323, 0.5       , 0.5       , 0.5       , 0.44968916,\n",
       "        0.51898195, 0.48101805, 0.51898195, 0.537885  , 0.56235799,\n",
       "        0.5       , 0.5       , 0.5       , 0.47326275, 0.51898195,\n",
       "        0.5       , 0.51898195, 0.56704431, 0.54601111, 0.5       ,\n",
       "        0.5       , 0.5       , 0.51895039, 0.51898195, 0.51898195,\n",
       "        0.53259909, 0.57881532, 0.45839119, 0.5       , 0.5       ,\n",
       "        0.47940072, 0.51898195, 0.51898195, 0.51898195, 0.53780611,\n",
       "        0.55427922, 0.54160881, 0.5       , 0.5       , 0.47361777,\n",
       "        0.51898195, 0.5       , 0.48101805, 0.57507574, 0.51429563,\n",
       "        0.45839119, 0.5       , 0.48093916, 0.51891094, 0.51898195,\n",
       "        0.51898195, 0.53255175, 0.56642893, 0.45839119, 0.54419654,\n",
       "        0.5       , 0.48097071, 0.51898195, 0.48101805, 0.48275372,\n",
       "        0.53646491, 0.53769566, 0.45839119, 0.54160881, 0.5       ,\n",
       "        0.47250536, 0.51898195, 0.5       , 0.51898195, 0.56944269,\n",
       "        0.53435054, 0.45839119, 0.45850164, 0.50523858, 0.49561348,\n",
       "        0.50523858, 0.49476142, 0.50523858, 0.50523858, 0.49697046,\n",
       "        0.50517546, 0.49417761, 0.52452032, 0.47547968, 0.47547968,\n",
       "        0.52407852, 0.52452032, 0.47547968, 0.52452032, 0.52452032,\n",
       "        0.47506943, 0.4609158 , 0.5390842 , 0.4609158 , 0.46041088,\n",
       "        0.5390842 , 0.5390842 , 0.46096314, 0.4609158 , 0.53725385,\n",
       "        0.48808697, 0.51191303, 0.48808697, 0.51191303, 0.48808697,\n",
       "        0.48808697, 0.48808697, 0.48808697, 0.48756627, 0.49163721,\n",
       "        0.50766852, 0.49233148, 0.49233148, 0.50766852, 0.50766852,\n",
       "        0.50766852, 0.50766852, 0.49375158, 0.44275435, 0.55724565,\n",
       "        0.44275435, 0.55724565, 0.55724565, 0.44748801, 0.55724565,\n",
       "        0.55724565, 0.44658861, 0.53285155, 0.53285155, 0.53285155,\n",
       "        0.53285155, 0.46714845, 0.53250442, 0.53285155, 0.53285155,\n",
       "        0.53285155, 0.46714845, 0.53285155, 0.46714845, 0.53285155,\n",
       "        0.53285155, 0.53285155, 0.4683003 , 0.53501325, 0.46714845,\n",
       "        0.46714845, 0.46714845, 0.53285155, 0.53285155, 0.46714845,\n",
       "        0.46714845, 0.53285155, 0.46714845, 0.53285155]),\n",
       " 'split2_test_roc_auc_ovo': array([0.39653812, 0.56616069, 0.51678869, 0.49356223, 0.52680826,\n",
       "        0.4650183 , 0.52688715, 0.54820437, 0.66851805, 0.51483211,\n",
       "        0.52589308, 0.49332555, 0.54609   , 0.52680826, 0.5349817 ,\n",
       "        0.60141063, 0.60705945, 0.66963835, 0.56259467, 0.5       ,\n",
       "        0.49599217, 0.49349912, 0.52680826, 0.55782946, 0.60428238,\n",
       "        0.618436  , 0.67449823, 0.5       , 0.45195342, 0.42336216,\n",
       "        0.59820752, 0.48231192, 0.54779412, 0.59850732, 0.61976142,\n",
       "        0.67246276, 0.54927733, 0.54798346, 0.57663784, 0.52011803,\n",
       "        0.50799987, 0.56447236, 0.6048662 , 0.61558003, 0.67255743,\n",
       "        0.45053332, 0.45201654, 0.52671358, 0.49384625, 0.56251578,\n",
       "        0.54119856, 0.55536796, 0.6372286 , 0.67246276, 0.4600953 ,\n",
       "        0.51865059, 0.38465665, 0.53299356, 0.57072078, 0.51420096,\n",
       "        0.50197236, 0.6376073 , 0.67284145, 0.4612156 , 0.51868215,\n",
       "        0.55385319, 0.53558129, 0.52857549, 0.58821163, 0.45148006,\n",
       "        0.63771775, 0.67347261, 0.46686443, 0.47790962, 0.54755743,\n",
       "        0.4304153 , 0.50418139, 0.48190167, 0.54851994, 0.63954809,\n",
       "        0.67279412, 0.41522027, 0.54981381, 0.54994004, 0.5       ,\n",
       "        0.51041404, 0.51106097, 0.52059139, 0.52191681, 0.53261487,\n",
       "        0.49741227, 0.49223681, 0.5       , 0.4707618 , 0.51041404,\n",
       "        0.51106097, 0.48024489, 0.52475701, 0.52358937, 0.54929311,\n",
       "        0.5       , 0.48390558, 0.5292382 , 0.48958596, 0.47276572,\n",
       "        0.53300934, 0.51967622, 0.52936443, 0.5       , 0.48095494,\n",
       "        0.51609442, 0.4707618 , 0.50919907, 0.48767672, 0.54867773,\n",
       "        0.54424388, 0.51560528, 0.48630396, 0.48095494, 0.51609442,\n",
       "        0.53581798, 0.54137213, 0.53349849, 0.52788122, 0.54268177,\n",
       "        0.53597576, 0.48630396, 0.48095494, 0.4437642 , 0.44381154,\n",
       "        0.47432782, 0.47764138, 0.53515526, 0.54593221, 0.52128566,\n",
       "        0.48630396, 0.52497791, 0.49633931, 0.5606381 , 0.51700959,\n",
       "        0.4705409 , 0.53752209, 0.54405453, 0.52145923, 0.53767988,\n",
       "        0.43732643, 0.56081166, 0.51967622, 0.4697204 , 0.53853194,\n",
       "        0.50206703, 0.52018114, 0.52183792, 0.52710805, 0.50468632,\n",
       "        0.50197236, 0.53981002, 0.54902487, 0.55767167, 0.50904128,\n",
       "        0.5338614 , 0.52161702, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.50459953, 0.53488702, 0.53488702, 0.49013822,\n",
       "        0.51525814, 0.5       , 0.5       , 0.5       , 0.47074602,\n",
       "        0.53487913, 0.53488702, 0.53488702, 0.48393714, 0.52363671,\n",
       "        0.5       , 0.5       , 0.5       , 0.50071005, 0.53488702,\n",
       "        0.46511298, 0.53488702, 0.51756185, 0.51866637, 0.5       ,\n",
       "        0.5       , 0.5       , 0.50460742, 0.53488702, 0.53488702,\n",
       "        0.49031179, 0.53854772, 0.48786607, 0.5       , 0.5       ,\n",
       "        0.48959385, 0.53487913, 0.53488702, 0.53488702, 0.48201212,\n",
       "        0.53682782, 0.48786607, 0.5       , 0.5       , 0.49931362,\n",
       "        0.46511298, 0.5       , 0.53488702, 0.52635067, 0.51865059,\n",
       "        0.48800808, 0.5       , 0.5       , 0.5045522 , 0.53488702,\n",
       "        0.53488702, 0.49024867, 0.52123832, 0.51214971, 0.48786607,\n",
       "        0.5       , 0.5001499 , 0.53489491, 0.53488702, 0.53488702,\n",
       "        0.48332176, 0.54896175, 0.51214971, 0.51213393, 0.5       ,\n",
       "        0.50048914, 0.53488702, 0.46511298, 0.53488702, 0.51427985,\n",
       "        0.51866637, 0.48773984, 0.48786607, 0.4639769 , 0.46443449,\n",
       "        0.46468695, 0.46471851, 0.53321447, 0.4639769 , 0.54432277,\n",
       "        0.53824792, 0.4639769 , 0.46888412, 0.53111588, 0.46904191,\n",
       "        0.53111588, 0.46915236, 0.53305668, 0.46888412, 0.46888412,\n",
       "        0.53502903, 0.48770828, 0.4874716 , 0.48770828, 0.48770828,\n",
       "        0.48770828, 0.51229172, 0.51229172, 0.5114081 , 0.51229172,\n",
       "        0.49490343, 0.49490343, 0.50509657, 0.50509657, 0.50509657,\n",
       "        0.49439851, 0.49441429, 0.50509657, 0.49490343, 0.52971156,\n",
       "        0.52971156, 0.47109316, 0.52949066, 0.52971156, 0.47028844,\n",
       "        0.47028844, 0.47028844, 0.47027266, 0.54132479, 0.54110389,\n",
       "        0.54132479, 0.45867521, 0.54132479, 0.54132479, 0.46060023,\n",
       "        0.45867521, 0.45897501, 0.44591012, 0.55408988, 0.55408988,\n",
       "        0.55195973, 0.44587857, 0.55408988, 0.55408988, 0.44591012,\n",
       "        0.44591012, 0.55077632, 0.44591012, 0.44591012, 0.55408988,\n",
       "        0.55408988, 0.44591012, 0.44591012, 0.55408988, 0.55393209,\n",
       "        0.55408988, 0.44591012, 0.55408988, 0.55408988, 0.44591012,\n",
       "        0.55408988, 0.44591012, 0.44591012, 0.55404254]),\n",
       " 'split3_test_roc_auc_ovo': array([0.53607044, 0.4800082 , 0.51737251, 0.48199634, 0.50146743,\n",
       "        0.4809076 , 0.49528213, 0.56576622, 0.61988765, 0.48138096,\n",
       "        0.49368846, 0.4860515 , 0.47983464, 0.50130964, 0.47885635,\n",
       "        0.54900909, 0.62034524, 0.70476206, 0.49056425, 0.5       ,\n",
       "        0.53032694, 0.50044181, 0.50146743, 0.49545569, 0.53835837,\n",
       "        0.63819111, 0.7128566 , 0.5       , 0.51350669, 0.49091139,\n",
       "        0.48351111, 0.44303837, 0.55730876, 0.59969073, 0.63721283,\n",
       "        0.71512876, 0.51771964, 0.51369604, 0.49091139, 0.52026004,\n",
       "        0.51123454, 0.56644471, 0.59028654, 0.63606097, 0.71015842,\n",
       "        0.51771964, 0.51317533, 0.51311222, 0.52695027, 0.56925335,\n",
       "        0.55046074, 0.5706261 , 0.6421516 , 0.71033199, 0.47424893,\n",
       "        0.51618909, 0.47407536, 0.47981886, 0.54867773, 0.55296958,\n",
       "        0.53233085, 0.65778844, 0.71028465, 0.49506122, 0.50175145,\n",
       "        0.50934108, 0.52660313, 0.55197551, 0.54219263, 0.52199571,\n",
       "        0.67681772, 0.71052133, 0.46356665, 0.48256438, 0.51789321,\n",
       "        0.46249369, 0.50309265, 0.47838298, 0.5103667 , 0.6769124 ,\n",
       "        0.71034777, 0.48624085, 0.47984253, 0.47600038, 0.5       ,\n",
       "        0.50209859, 0.4953768 , 0.5234947 , 0.51981823, 0.53592843,\n",
       "        0.47551123, 0.47235547, 0.5       , 0.46179942, 0.50209859,\n",
       "        0.4953768 , 0.55336405, 0.51257574, 0.54230308, 0.47764138,\n",
       "        0.46945216, 0.47230813, 0.46179942, 0.50156211, 0.50036291,\n",
       "        0.49596062, 0.5684644 , 0.52996402, 0.5       , 0.53054784,\n",
       "        0.47230813, 0.46179942, 0.52262686, 0.49635509, 0.55446857,\n",
       "        0.54272911, 0.52302133, 0.49588172, 0.53054784, 0.47230813,\n",
       "        0.5398258 , 0.49845367, 0.47415425, 0.5687642 , 0.53712762,\n",
       "        0.57433413, 0.49618152, 0.53054784, 0.49952663, 0.53250442,\n",
       "        0.53763254, 0.54033072, 0.55640937, 0.57725322, 0.5876357 ,\n",
       "        0.49521901, 0.46080535, 0.46178364, 0.49413027, 0.49264706,\n",
       "        0.50545948, 0.57169907, 0.54531684, 0.59457839, 0.48067092,\n",
       "        0.51713582, 0.49296264, 0.53389296, 0.49392515, 0.53616511,\n",
       "        0.53902108, 0.58690987, 0.59573024, 0.52851237, 0.48327443,\n",
       "        0.48983842, 0.49517167, 0.51293865, 0.48291151, 0.55383741,\n",
       "        0.5843537 , 0.59467306, 0.5       , 0.5       , 0.5       ,\n",
       "        0.52136455, 0.44385098, 0.50967243, 0.50967243, 0.5024615 ,\n",
       "        0.58014075, 0.5       , 0.5       , 0.5       , 0.47437516,\n",
       "        0.50967243, 0.49032757, 0.50967243, 0.54771522, 0.53771144,\n",
       "        0.5       , 0.5       , 0.5       , 0.50788942, 0.50967243,\n",
       "        0.5       , 0.50967243, 0.53291467, 0.48190167, 0.5       ,\n",
       "        0.5       , 0.5       , 0.44393777, 0.50967243, 0.50967243,\n",
       "        0.50236683, 0.5184928 , 0.44332239, 0.5       , 0.5       ,\n",
       "        0.48298252, 0.50967243, 0.48965697, 0.50967243, 0.54653181,\n",
       "        0.55046074, 0.44330661, 0.5       , 0.5       , 0.50769219,\n",
       "        0.50967243, 0.49032757, 0.49032757, 0.54295001, 0.56971093,\n",
       "        0.44330661, 0.5       , 0.47626862, 0.55622002, 0.50967243,\n",
       "        0.50967243, 0.50239838, 0.54220841, 0.44332239, 0.44332239,\n",
       "        0.5       , 0.47451717, 0.50967243, 0.50967243, 0.49032757,\n",
       "        0.54788879, 0.5507132 , 0.44332239, 0.44325928, 0.5       ,\n",
       "        0.49132164, 0.49032757, 0.5       , 0.50967243, 0.5668234 ,\n",
       "        0.53095809, 0.44332239, 0.55876041, 0.49526635, 0.49526635,\n",
       "        0.49526635, 0.49526635, 0.50413406, 0.49547147, 0.49526635,\n",
       "        0.50844168, 0.50473365, 0.50025246, 0.49974754, 0.49974754,\n",
       "        0.50025246, 0.51112408, 0.49974754, 0.50905706, 0.50025246,\n",
       "        0.49974754, 0.53315135, 0.53315135, 0.46684865, 0.46623327,\n",
       "        0.46684865, 0.46684865, 0.53315135, 0.46741669, 0.46740091,\n",
       "        0.51361714, 0.51361714, 0.52067029, 0.51410629, 0.48638286,\n",
       "        0.51361714, 0.51361714, 0.51361714, 0.48638286, 0.49514012,\n",
       "        0.49514012, 0.50485988, 0.49514012, 0.50485988, 0.49514012,\n",
       "        0.49514012, 0.49523479, 0.49514012, 0.49603951, 0.50396049,\n",
       "        0.49603951, 0.50396049, 0.49603951, 0.49603951, 0.50396049,\n",
       "        0.49603951, 0.50396049, 0.47251325, 0.47251325, 0.47251325,\n",
       "        0.47237124, 0.47251325, 0.47251325, 0.47181899, 0.52748675,\n",
       "        0.52748675, 0.47251325, 0.52748675, 0.47251325, 0.47251325,\n",
       "        0.47251325, 0.52748675, 0.52748675, 0.52748675, 0.47251325,\n",
       "        0.47251325, 0.47251325, 0.52748675, 0.52748675, 0.52748675,\n",
       "        0.52748675, 0.47251325, 0.47251325, 0.47251325]),\n",
       " 'split4_test_roc_auc_ovo': array([0.49032757, 0.48919149, 0.48726647, 0.53518682, 0.47517988,\n",
       "        0.54818859, 0.55678806, 0.53594421, 0.63028591, 0.45553522,\n",
       "        0.55803459, 0.42749621, 0.47364933, 0.52482012, 0.54818859,\n",
       "        0.57158861, 0.63161134, 0.69791404, 0.46760603, 0.5       ,\n",
       "        0.53215728, 0.47364933, 0.52482012, 0.59694522, 0.60994698,\n",
       "        0.6590823 , 0.69905011, 0.5       , 0.45116448, 0.47254481,\n",
       "        0.49441429, 0.50657978, 0.61016789, 0.63606097, 0.6615438 ,\n",
       "        0.69897122, 0.54572709, 0.45116448, 0.52745519, 0.53376673,\n",
       "        0.65183981, 0.62367458, 0.65710995, 0.66179626, 0.69770891,\n",
       "        0.45427291, 0.45116448, 0.58430636, 0.46093158, 0.63713393,\n",
       "        0.59189599, 0.68028907, 0.65930321, 0.69813494, 0.44486872,\n",
       "        0.52549861, 0.46886834, 0.51535281, 0.57938336, 0.51427985,\n",
       "        0.53353004, 0.66604077, 0.69856097, 0.45632416, 0.55423189,\n",
       "        0.5150688 , 0.52721851, 0.55681962, 0.53755365, 0.61469642,\n",
       "        0.66722419, 0.69854519, 0.5357233 , 0.49422494, 0.46126294,\n",
       "        0.570705  , 0.52005491, 0.52895418, 0.61619541, 0.66681394,\n",
       "        0.69856097, 0.45993752, 0.55514706, 0.52642956, 0.5       ,\n",
       "        0.5474312 , 0.4525688 , 0.57120992, 0.54724186, 0.51981823,\n",
       "        0.55514706, 0.52067029, 0.5       , 0.47308129, 0.5474312 ,\n",
       "        0.5474312 , 0.49796453, 0.57509152, 0.52660313, 0.54006248,\n",
       "        0.53379828, 0.52642956, 0.47308129, 0.4525688 , 0.53963646,\n",
       "        0.46156274, 0.55983338, 0.53643335, 0.5       , 0.53403497,\n",
       "        0.52347892, 0.47308129, 0.53928932, 0.54979803, 0.57362408,\n",
       "        0.55681962, 0.50424451, 0.54006248, 0.53379828, 0.47652108,\n",
       "        0.55617268, 0.54946668, 0.49110073, 0.54766789, 0.56592401,\n",
       "        0.50818922, 0.54006248, 0.53379828, 0.43241921, 0.48325865,\n",
       "        0.49461941, 0.47754671, 0.56270512, 0.55090255, 0.53226774,\n",
       "        0.54006248, 0.4732233 , 0.52573529, 0.51560528, 0.51323845,\n",
       "        0.51680447, 0.55259089, 0.55424766, 0.5308003 , 0.46585458,\n",
       "        0.5305005 , 0.48710868, 0.56305226, 0.43661638, 0.53105276,\n",
       "        0.53561285, 0.58506375, 0.53289889, 0.41135446, 0.45189031,\n",
       "        0.42516094, 0.50356602, 0.5862945 , 0.52510414, 0.53081608,\n",
       "        0.57250379, 0.53113166, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.56130081, 0.53345115, 0.53345115, 0.56488261,\n",
       "        0.57763191, 0.5       , 0.5       , 0.5       , 0.40499558,\n",
       "        0.46654096, 0.46654885, 0.53345115, 0.59875978, 0.59006564,\n",
       "        0.5       , 0.5       , 0.5       , 0.48767672, 0.53345115,\n",
       "        0.5       , 0.53345115, 0.59393146, 0.55764012, 0.5       ,\n",
       "        0.5       , 0.5       , 0.43892799, 0.46654885, 0.53345115,\n",
       "        0.43511739, 0.59401035, 0.45728667, 0.5       , 0.5       ,\n",
       "        0.40509025, 0.53345904, 0.53345115, 0.53345115, 0.59894913,\n",
       "        0.5824918 , 0.45728667, 0.5       , 0.5       , 0.491795  ,\n",
       "        0.53345115, 0.5       , 0.53345115, 0.61958786, 0.54418076,\n",
       "        0.45728667, 0.5       , 0.5       , 0.56122191, 0.46654885,\n",
       "        0.53345115, 0.56488261, 0.60144219, 0.45728667, 0.54271333,\n",
       "        0.5       , 0.40959511, 0.46654096, 0.53345115, 0.53345115,\n",
       "        0.59972229, 0.58911891, 0.45728667, 0.45728667, 0.5       ,\n",
       "        0.49217369, 0.53345115, 0.5       , 0.53345115, 0.5826338 ,\n",
       "        0.5440072 , 0.54235042, 0.45728667, 0.46077379, 0.46077379,\n",
       "        0.46077379, 0.46077379, 0.53922621, 0.53922621, 0.53906842,\n",
       "        0.46077379, 0.53922621, 0.56699697, 0.56699697, 0.56699697,\n",
       "        0.56699697, 0.4396617 , 0.56707586, 0.43300303, 0.43350795,\n",
       "        0.43300303, 0.50749495, 0.50711626, 0.49288374, 0.50711626,\n",
       "        0.50711626, 0.50711626, 0.50615375, 0.50711626, 0.50711626,\n",
       "        0.47574792, 0.52676092, 0.47323908, 0.52676092, 0.47323908,\n",
       "        0.47319174, 0.47312863, 0.52650846, 0.47401224, 0.53305668,\n",
       "        0.53255175, 0.46694332, 0.46694332, 0.53305668, 0.53305668,\n",
       "        0.53300934, 0.52920664, 0.53305668, 0.43327127, 0.43428112,\n",
       "        0.56491416, 0.43428112, 0.56571888, 0.43286102, 0.56571888,\n",
       "        0.43428112, 0.56388854, 0.5242363 , 0.52363671, 0.4757637 ,\n",
       "        0.4757637 , 0.5242363 , 0.5242363 , 0.5242363 , 0.4757637 ,\n",
       "        0.4757637 , 0.5242363 , 0.4757637 , 0.5242363 , 0.4757637 ,\n",
       "        0.4757637 , 0.5242363 , 0.5242363 , 0.5242363 , 0.4757637 ,\n",
       "        0.5242363 , 0.52321068, 0.4757637 , 0.5242363 , 0.52403118,\n",
       "        0.4757637 , 0.5242363 , 0.47607927, 0.5242363 ]),\n",
       " 'mean_test_roc_auc_ovo': array([0.46952159, 0.52218821, 0.50235736, 0.51615122, 0.51976142,\n",
       "        0.4937358 , 0.52179058, 0.55780422, 0.66683918, 0.48055415,\n",
       "        0.50442754, 0.46698119, 0.49841896, 0.52965791, 0.50731823,\n",
       "        0.55551313, 0.63816902, 0.70654506, 0.49089876, 0.5       ,\n",
       "        0.50942628, 0.50285913, 0.52968947, 0.53596945, 0.56692439,\n",
       "        0.64584701, 0.71308066, 0.50848902, 0.46211184, 0.46724943,\n",
       "        0.51421989, 0.48882542, 0.55321573, 0.59681267, 0.64584385,\n",
       "        0.71209922, 0.52266158, 0.52429311, 0.50923378, 0.53445784,\n",
       "        0.52733527, 0.57422368, 0.60020828, 0.64603004, 0.71142704,\n",
       "        0.48437579, 0.48803648, 0.52408483, 0.50657031, 0.55667445,\n",
       "        0.55668392, 0.5958407 , 0.64739649, 0.71160376, 0.48844989,\n",
       "        0.49686001, 0.48078768, 0.50544686, 0.54129323, 0.5286102 ,\n",
       "        0.54322141, 0.64732706, 0.71117773, 0.49233779, 0.51510666,\n",
       "        0.51027834, 0.51572835, 0.55059013, 0.54162459, 0.52050934,\n",
       "        0.65162522, 0.71112724, 0.50634625, 0.48080661, 0.50648195,\n",
       "        0.48463456, 0.51109253, 0.50155264, 0.53763254, 0.65189346,\n",
       "        0.711244  , 0.468679  , 0.53197898, 0.52323908, 0.49296264,\n",
       "        0.51889674, 0.49859568, 0.52104267, 0.52644534, 0.53440104,\n",
       "        0.51408577, 0.50958249, 0.5       , 0.49364744, 0.5191997 ,\n",
       "        0.51760288, 0.51431457, 0.54128061, 0.53802701, 0.52476647,\n",
       "        0.50065009, 0.50888664, 0.50534272, 0.49555668, 0.49619414,\n",
       "        0.47413848, 0.54743752, 0.5263128 , 0.51737882, 0.51202663,\n",
       "        0.4900183 , 0.47957271, 0.51164163, 0.5103951 , 0.55878566,\n",
       "        0.54394724, 0.52697236, 0.51581671, 0.5119793 , 0.5061569 ,\n",
       "        0.52600353, 0.52098902, 0.50207965, 0.54862724, 0.54976647,\n",
       "        0.54434171, 0.48170916, 0.50904443, 0.47909934, 0.48210995,\n",
       "        0.48987945, 0.51278717, 0.54511171, 0.5489081 , 0.55266031,\n",
       "        0.51574097, 0.51117458, 0.48750947, 0.51343095, 0.50241416,\n",
       "        0.51102941, 0.55589498, 0.54716928, 0.55374905, 0.50592022,\n",
       "        0.50789889, 0.4988513 , 0.51197614, 0.46941429, 0.52545443,\n",
       "        0.52958218, 0.55405832, 0.55376483, 0.49662333, 0.48480182,\n",
       "        0.48669843, 0.51881785, 0.53521207, 0.51763444, 0.52001704,\n",
       "        0.55632416, 0.55394471, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5004923 , 0.49998107, 0.5212257 , 0.5212257 , 0.52519566,\n",
       "        0.54936885, 0.5       , 0.5       , 0.5       , 0.45944048,\n",
       "        0.50784209, 0.49638349, 0.5212257 , 0.5340539 , 0.54423441,\n",
       "        0.5       , 0.5       , 0.5       , 0.4892767 , 0.5212257 ,\n",
       "        0.4930226 , 0.5212257 , 0.54559139, 0.51731886, 0.5       ,\n",
       "        0.5       , 0.49935622, 0.48310875, 0.50784524, 0.5212257 ,\n",
       "        0.49921737, 0.54894597, 0.47301187, 0.5       , 0.5       ,\n",
       "        0.47184108, 0.5212257 , 0.51359505, 0.5212257 , 0.53341012,\n",
       "        0.54608685, 0.48965855, 0.5       , 0.5       , 0.48987787,\n",
       "        0.50727089, 0.49806551, 0.50976395, 0.55516284, 0.52586468,\n",
       "        0.47303711, 0.5       , 0.49144156, 0.53002083, 0.50784524,\n",
       "        0.5212257 , 0.52510414, 0.54568606, 0.47787175, 0.50725827,\n",
       "        0.5       , 0.46903244, 0.50784524, 0.51363292, 0.51011108,\n",
       "        0.5339182 , 0.5459259 , 0.47058824, 0.48721914, 0.5       ,\n",
       "        0.49331135, 0.51735673, 0.49484979, 0.5212257 , 0.55014832,\n",
       "        0.52209985, 0.49000252, 0.49612156, 0.48584322, 0.48238765,\n",
       "        0.48642704, 0.48392136, 0.51719263, 0.49995266, 0.51429563,\n",
       "        0.50331671, 0.50103825, 0.51736304, 0.51992868, 0.49699255,\n",
       "        0.51912396, 0.49415236, 0.50981129, 0.48183224, 0.49069364,\n",
       "        0.49383047, 0.50067218, 0.51060338, 0.47885319, 0.48711184,\n",
       "        0.50296958, 0.50240785, 0.49909429, 0.49218947, 0.50763065,\n",
       "        0.49169402, 0.51221598, 0.4946415 , 0.51435244, 0.48778402,\n",
       "        0.49663595, 0.49662648, 0.5094389 , 0.48579588, 0.51860326,\n",
       "        0.50432025, 0.49572078, 0.48808697, 0.50666183, 0.49253661,\n",
       "        0.49252714, 0.49178553, 0.50713519, 0.47750884, 0.51248738,\n",
       "        0.51417571, 0.48601994, 0.52689662, 0.47837352, 0.51178995,\n",
       "        0.48407915, 0.48988261, 0.49049482, 0.51201086, 0.50188399,\n",
       "        0.5110799 , 0.47734789, 0.52127619, 0.52120677, 0.491795  ,\n",
       "        0.50095935, 0.50754229, 0.50100985, 0.48655011, 0.5116511 ,\n",
       "        0.5116511 , 0.50148952, 0.49779412, 0.52355781, 0.48926407,\n",
       "        0.508205  , 0.48636392, 0.5226458 , 0.53234032, 0.49752272,\n",
       "        0.50029033, 0.49970967, 0.47693764, 0.51213393]),\n",
       " 'std_test_roc_auc_ovo': array([0.05153717, 0.03356997, 0.03157683, 0.02431331, 0.03220789,\n",
       "        0.02846593, 0.02306448, 0.0157033 , 0.04309751, 0.01967003,\n",
       "        0.04168063, 0.03232334, 0.02623804, 0.0234133 , 0.02850439,\n",
       "        0.02809973, 0.02812783, 0.02868801, 0.04080892, 0.        ,\n",
       "        0.01860442, 0.02339357, 0.02337515, 0.03670774, 0.03554861,\n",
       "        0.01924282, 0.03007089, 0.01697804, 0.02710299, 0.02473994,\n",
       "        0.0501667 , 0.04809747, 0.03128334, 0.02289244, 0.02106938,\n",
       "        0.03003605, 0.03411576, 0.04027107, 0.03962916, 0.0177401 ,\n",
       "        0.06415495, 0.02871342, 0.03111584, 0.02130742, 0.03055208,\n",
       "        0.03789458, 0.04546493, 0.04123915, 0.02614699, 0.04817453,\n",
       "        0.02553383, 0.04446798, 0.01033178, 0.03045673, 0.03691085,\n",
       "        0.03865671, 0.05844539, 0.02662584, 0.03219979, 0.01960671,\n",
       "        0.02807487, 0.01390371, 0.02996926, 0.0297595 , 0.02156913,\n",
       "        0.03385529, 0.02457938, 0.01121817, 0.02830481, 0.05412567,\n",
       "        0.01815154, 0.02963569, 0.03540377, 0.02038048, 0.02964802,\n",
       "        0.04740847, 0.01103712, 0.02500183, 0.04513264, 0.01783693,\n",
       "        0.02970935, 0.03004736, 0.02806552, 0.03206843, 0.01407473,\n",
       "        0.03050679, 0.02890088, 0.02862753, 0.02063525, 0.00932557,\n",
       "        0.02720252, 0.04226344, 0.        , 0.03106864, 0.03007943,\n",
       "        0.02295311, 0.02924254, 0.02513394, 0.01237176, 0.04454647,\n",
       "        0.0203636 , 0.03288573, 0.03125813, 0.03566914, 0.02504887,\n",
       "        0.04282798, 0.01983741, 0.02805597, 0.03475764, 0.02386037,\n",
       "        0.03211475, 0.02425574, 0.02213921, 0.02139375, 0.01761869,\n",
       "        0.01799036, 0.01729501, 0.04245659, 0.02381686, 0.03306182,\n",
       "        0.04015253, 0.02405334, 0.02007273, 0.02150357, 0.01816935,\n",
       "        0.02276883, 0.04103613, 0.02758654, 0.03969681, 0.03231412,\n",
       "        0.04404158, 0.02908217, 0.01484615, 0.01896374, 0.02531404,\n",
       "        0.0424586 , 0.03811817, 0.02253729, 0.02535925, 0.03104825,\n",
       "        0.02804655, 0.02398198, 0.01003106, 0.02749585, 0.028146  ,\n",
       "        0.04663528, 0.03248661, 0.04839221, 0.01856287, 0.0138697 ,\n",
       "        0.01382524, 0.02814926, 0.02737273, 0.04856468, 0.02151019,\n",
       "        0.03821917, 0.03488785, 0.03176837, 0.02542696, 0.02337949,\n",
       "        0.0220991 , 0.02742009, 0.        , 0.        , 0.        ,\n",
       "        0.012748  , 0.03840571, 0.01114242, 0.01114242, 0.02641759,\n",
       "        0.04235403, 0.        , 0.        , 0.        , 0.03114756,\n",
       "        0.0226535 , 0.0236982 , 0.01114242, 0.03982229, 0.02916345,\n",
       "        0.        , 0.        , 0.        , 0.01334706, 0.01114242,\n",
       "        0.01395481, 0.01114242, 0.03029647, 0.03138889, 0.        ,\n",
       "        0.        , 0.00128755, 0.0343794 , 0.02265251, 0.01114242,\n",
       "        0.03644929, 0.03200031, 0.02684956, 0.        , 0.        ,\n",
       "        0.03426374, 0.01114222, 0.01980042, 0.01114242, 0.0403259 ,\n",
       "        0.02479659, 0.0366456 , 0.        , 0.        , 0.01296952,\n",
       "        0.02284334, 0.00386897, 0.02189405, 0.03847703, 0.02941297,\n",
       "        0.02686882, 0.        , 0.01058546, 0.02393964, 0.02265251,\n",
       "        0.01114242, 0.02636309, 0.03607823, 0.03098048, 0.03796029,\n",
       "        0.        , 0.03095945, 0.02265727, 0.01971871, 0.02144467,\n",
       "        0.04024503, 0.0275541 , 0.02417432, 0.03587951, 0.        ,\n",
       "        0.01241299, 0.01653566, 0.01528363, 0.01114242, 0.02847477,\n",
       "        0.02138723, 0.03665877, 0.03847684, 0.01949268, 0.01619566,\n",
       "        0.01976104, 0.01764889, 0.01565706, 0.0240895 , 0.02244028,\n",
       "        0.02473946, 0.02406967, 0.03235782, 0.03086813, 0.03659221,\n",
       "        0.03139277, 0.03417066, 0.03578766, 0.03219191, 0.03535399,\n",
       "        0.03698317, 0.0246176 , 0.02219301, 0.01257712, 0.02134121,\n",
       "        0.02442443, 0.02439777, 0.02489883, 0.02308053, 0.02262603,\n",
       "        0.01256457, 0.01015994, 0.01649569, 0.00701243, 0.01015994,\n",
       "        0.01557964, 0.01559819, 0.01267564, 0.0067139 , 0.02111101,\n",
       "        0.02764489, 0.02757062, 0.02539673, 0.02682907, 0.02708925,\n",
       "        0.02707509, 0.0259601 , 0.02710312, 0.03896653, 0.04287092,\n",
       "        0.04213688, 0.04224042, 0.03569404, 0.03825717, 0.04309433,\n",
       "        0.04176145, 0.04170715, 0.03294488, 0.03202674, 0.03462851,\n",
       "        0.03168632, 0.02575419, 0.02680484, 0.0270872 , 0.03329251,\n",
       "        0.03424149, 0.03239338, 0.0342738 , 0.03152687, 0.03224849,\n",
       "        0.03224849, 0.03425631, 0.03399966, 0.02549674, 0.03251222,\n",
       "        0.03329251, 0.03130556, 0.02574648, 0.01139374, 0.03417011,\n",
       "        0.03428745, 0.03428745, 0.02531406, 0.03204492]),\n",
       " 'rank_test_roc_auc_ovo': array([317,  91, 194, 124, 111, 252,  93,  24,   9, 303, 187, 322, 234,\n",
       "         71, 175,  29,  17,   8, 265, 206, 162, 191,  70,  60,  22,  15,\n",
       "          1, 166, 323, 321, 132, 276,  35,  19,  16,   2,  89,  85, 163,\n",
       "         62,  74,  21,  18,  14,   4, 293, 279,  86, 180,  26,  25,  20,\n",
       "         12,   3, 277, 239, 302, 185,  56,  73,  54,  13,   6, 259, 128,\n",
       "        156, 127,  37,  55, 108,  11,   7, 182, 301, 181, 292, 151, 197,\n",
       "         59,  10,   5, 320,  68,  88, 256, 114, 233, 106,  77,  63, 134,\n",
       "        160, 206, 253, 112, 118, 130,  57,  58,  84, 203, 165, 186, 247,\n",
       "        244, 312,  44,  78, 119, 142, 268, 304, 149, 155,  23,  53,  75,\n",
       "        125, 144, 183,  79, 107, 195,  43,  39,  51, 300, 164, 305, 298,\n",
       "        271, 138,  50,  42,  36, 126, 150, 281, 137, 192, 153,  28,  45,\n",
       "         34, 184, 168, 232, 145, 318,  81,  72,  31,  33, 242, 291, 284,\n",
       "        115,  61, 117, 109,  27,  32, 206, 206, 206, 204, 226,  95,  95,\n",
       "         82,  40, 206, 206, 206, 324, 172, 243,  95,  64,  52, 206, 206,\n",
       "        206, 274,  95, 255,  95,  49, 122, 206, 206, 229, 296, 169,  95,\n",
       "        230,  41, 314, 206, 206, 315, 104, 136,  95,  66,  46, 273, 206,\n",
       "        206, 272, 176, 235, 159,  30,  80, 313, 206, 264,  69, 169,  95,\n",
       "         83,  48, 308, 177, 206, 319, 169, 135, 157,  65,  47, 316, 282,\n",
       "        206, 254, 121, 248,  95,  38,  92, 269, 245, 289, 297, 286, 295,\n",
       "        123, 227, 131, 189, 199, 120, 110, 238, 113, 250, 158, 299, 266,\n",
       "        251, 202, 154, 306, 283, 190, 193, 231, 260, 173, 263, 140, 249,\n",
       "        129, 280, 240, 241, 161, 290, 116, 188, 246, 278, 179, 257, 258,\n",
       "        262, 178, 309, 139, 133, 288,  76, 307, 146, 294, 270, 267, 143,\n",
       "        196, 152, 310,  94, 105, 261, 201, 174, 200, 285, 147, 147, 198,\n",
       "        236,  87, 275, 167, 287,  90,  67, 237, 205, 228, 311, 141]),\n",
       " 'split0_test_neg_log_loss': array([-0.24843458, -0.24843456, -0.24847471, -0.24843396, -0.24833585,\n",
       "        -0.24843819, -0.24835714, -0.24789043, -0.20998915, -0.24843464,\n",
       "        -0.24852433, -0.24856187, -0.24842072, -0.24824394, -0.24846876,\n",
       "        -0.25033491, -0.23902444, -0.20437258, -0.24847837, -0.24843494,\n",
       "        -0.24843033, -0.24843435, -0.24827217, -0.2485866 , -0.24980016,\n",
       "        -0.23701428, -0.20363334, -0.24831716, -0.24853157, -0.24847634,\n",
       "        -0.24858951, -0.24838081, -0.2495192 , -0.24749813, -0.23725641,\n",
       "        -0.20394754, -0.24833567, -0.24823322, -0.24859433, -0.24805803,\n",
       "        -0.24863677, -0.24582539, -0.24645765, -0.23742775, -0.1998444 ,\n",
       "        -0.24857851, -0.24819525, -0.24811659, -0.24839914, -0.2523971 ,\n",
       "        -0.25382777, -0.24603178, -0.23945789, -0.19986381, -0.24832443,\n",
       "        -0.24939895, -0.24820529, -0.25050392, -0.25979314, -0.2483932 ,\n",
       "        -0.31249273, -0.24248243, -0.20035141, -0.24842709, -0.24892937,\n",
       "        -0.24884486, -0.24857133, -0.24692956, -2.63989156, -0.24846105,\n",
       "        -0.24243771, -0.20008705, -0.2484296 , -0.24883611, -0.24846046,\n",
       "        -0.24847104, -0.32100501, -0.24816423, -0.24841072, -0.24245182,\n",
       "        -0.19983092, -0.24843457, -0.24843456, -0.24834979, -0.24844067,\n",
       "        -0.24836345, -0.24832813, -0.24844361, -0.24774322, -0.24819462,\n",
       "        -0.24843447, -0.2483029 , -0.24843494, -0.2483552 , -0.24830681,\n",
       "        -0.24834662, -0.24821573, -0.24758797, -0.24834423, -0.24843328,\n",
       "        -0.24843494, -0.24839519, -0.24836496, -0.2483783 , -0.24965459,\n",
       "        -0.24905165, -0.24747877, -0.2485405 , -0.24841322, -0.24837606,\n",
       "        -0.24846436, -0.24845591, -0.24852111, -0.24838603, -0.2465636 ,\n",
       "        -0.24648979, -0.24821942, -0.2481211 , -0.2483484 , -0.24818108,\n",
       "        -0.24873913, -0.24872749, -0.24832336, -0.24635121, -0.24671314,\n",
       "        -0.24817742, -0.24845062, -0.24841416, -0.24858688, -0.24843973,\n",
       "        -0.24923155, -0.2478752 , -0.24765602, -0.24745447, -0.24745322,\n",
       "        -0.24803466, -0.24797241, -0.24849555, -0.24892885, -0.2490287 ,\n",
       "        -0.24751818, -0.24632937, -0.24785341, -0.24710318, -0.24822412,\n",
       "        -0.24862835, -0.25003814, -0.24945578, -0.25186715, -0.24944854,\n",
       "        -0.24813004, -0.24791401, -0.24692124, -0.24834301, -0.24828598,\n",
       "        -0.24905543, -0.24783784, -0.24844681, -0.24834753, -0.24935971,\n",
       "        -0.24727447, -0.24711068, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843461, -0.25178682, -0.24824776,\n",
       "        -0.24932614, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.248695  , -0.250616  , -0.24939411, -0.24871861,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843494, -0.24995029, -0.24879363, -0.25448513, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843472, -0.2499939 ,\n",
       "        -0.24831422, -0.24839032, -0.24841135, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843494, -0.24853845, -0.24947551,\n",
       "        -0.24916373, -0.24864946, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843494, -0.25068557, -0.24880393, -0.26071318,\n",
       "        -0.2483871 , -0.24843457, -0.24843457, -0.24843457, -0.2484346 ,\n",
       "        -0.25119305, -0.24878541, -0.24914696, -0.24842895, -0.24839159,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24861847, -0.25006871,\n",
       "        -0.24977332, -0.24966309, -0.24843797, -0.24855245, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24859918, -0.24981816, -0.24935159,\n",
       "        -0.2498877 , -0.24842824, -0.2484562 , -0.2485489 , -0.24843499,\n",
       "        -0.24851038, -0.24852078, -0.2484916 , -0.2484487 , -0.24852023,\n",
       "        -0.24854477, -0.24882985, -0.24810625, -0.24841099, -0.24853286,\n",
       "        -0.24906895, -0.24840873, -0.24855369, -0.24856587, -0.24825948,\n",
       "        -0.24834707, -0.24823648, -0.24879694, -0.24867987, -0.24834987,\n",
       "        -0.24838954, -0.24890819, -0.24937484, -0.24832737, -0.24824909,\n",
       "        -0.24845959, -0.24839171, -0.2484555 , -0.24834821, -0.24852201,\n",
       "        -0.24837428, -0.24841466, -0.24834247, -0.24856161, -0.24841213,\n",
       "        -0.24854835, -0.24793535, -0.24887239, -0.24916025, -0.24854097,\n",
       "        -0.24906733, -0.24887759, -0.2479908 , -0.24849858, -0.24827172,\n",
       "        -0.24828471, -0.24894768, -0.24858164, -0.24856644, -0.24960886,\n",
       "        -0.24868583, -0.24893017, -0.24856999, -0.24849833, -0.24889341,\n",
       "        -0.24834425, -0.24848384, -0.24837556, -0.24836007, -0.24857227,\n",
       "        -0.24833585, -0.24835695, -0.24839385, -0.24832847, -0.2484203 ,\n",
       "        -0.24835194, -0.24861471, -0.24841703, -0.24861877, -0.24843684,\n",
       "        -0.24835067, -0.24841096, -0.248362  , -0.24834491, -0.24832792,\n",
       "        -0.24853236, -0.24836917, -0.24843074, -0.24873673]),\n",
       " 'split1_test_neg_log_loss': array([-0.24843457, -0.24843454, -0.24823464, -0.24841513, -0.24837901,\n",
       "        -0.24859107, -0.24865123, -0.24617493, -0.20519428, -0.24843463,\n",
       "        -0.24855595, -0.24843494, -0.24849673, -0.24837611, -0.24855394,\n",
       "        -0.24974107, -0.23223307, -0.206136  , -0.24857067, -0.24843494,\n",
       "        -0.24851264, -0.24840751, -0.24839139, -0.24839838, -0.24704481,\n",
       "        -0.23346594, -0.20574728, -0.24843494, -0.24907441, -0.24849249,\n",
       "        -0.24832658, -0.24895541, -0.25203871, -0.24622564, -0.23270622,\n",
       "        -0.20617593, -0.24966209, -0.24843184, -0.24919711, -0.24843273,\n",
       "        -0.25081486, -0.24805249, -0.24681622, -0.23250954, -0.20141065,\n",
       "        -0.24825394, -0.24896207, -0.24881517, -0.24838738, -0.25094074,\n",
       "        -0.24678813, -0.24272218, -0.23590933, -0.20210272, -0.24839741,\n",
       "        -0.24847171, -0.24834707, -0.24841865, -0.25273377, -0.24759912,\n",
       "        -0.25813983, -0.24010933, -0.2024561 , -0.24846645, -0.24880839,\n",
       "        -0.24848485, -0.24827791, -0.24760059, -9.82563913, -0.24894899,\n",
       "        -0.24046054, -0.20195449, -0.24818451, -0.2484341 , -0.24839608,\n",
       "        -0.24926117, -0.35844954, -0.24875765, -0.24911733, -0.24041725,\n",
       "        -0.20222409, -0.24843457, -0.24843451, -0.24843494, -0.24843494,\n",
       "        -0.24855773, -0.24857094, -0.24848534, -0.24893723, -0.24820506,\n",
       "        -0.24843457, -0.24843494, -0.24843494, -0.2483519 , -0.2487766 ,\n",
       "        -0.24851598, -0.24845638, -0.25017755, -0.24767439, -0.24866033,\n",
       "        -0.24843494, -0.24844327, -0.24836438, -0.24888199, -0.24853295,\n",
       "        -0.24857465, -0.24953973, -0.24891565, -0.24843494, -0.24855459,\n",
       "        -0.24844121, -0.24840724, -0.24842183, -0.24843468, -0.24840453,\n",
       "        -0.24924635, -0.24805612, -0.24856989, -0.24844747, -0.24845141,\n",
       "        -0.24821638, -0.24837729, -0.24842941, -0.2481739 , -0.24841843,\n",
       "        -0.24788524, -0.24903929, -0.24898107, -0.24817646, -0.24888516,\n",
       "        -0.24822794, -0.24823847, -0.25118076, -0.24901059, -0.24814188,\n",
       "        -0.24878511, -0.24802478, -0.24863853, -0.24841691, -0.24810626,\n",
       "        -0.24855831, -0.24925379, -0.24877112, -0.24755415, -0.24836183,\n",
       "        -0.24822269, -0.24847634, -0.24813325, -0.24864621, -0.2481079 ,\n",
       "        -0.24825311, -0.2504557 , -0.2475605 , -0.24913294, -0.24942649,\n",
       "        -0.2480148 , -0.24865984, -0.24815199, -0.24846912, -0.24825506,\n",
       "        -0.24873499, -0.24777562, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843456, -0.24839097, -0.24774885,\n",
       "        -0.24559041, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843556, -0.24833271, -0.24794139, -0.24759946,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843494, -0.24841494, -0.2466309 , -0.25077015, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843456, -0.24832934,\n",
       "        -0.24734763, -0.24634897, -0.24846409, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843328, -0.24836954, -0.24775937,\n",
       "        -0.24762638, -0.24841325, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843494, -0.24852613, -0.24643759, -0.24951578,\n",
       "        -0.2489328 , -0.24843457, -0.24843457, -0.24843457, -0.24843456,\n",
       "        -0.24837064, -0.24756546, -0.24688463, -0.24908041, -0.24803112,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843477, -0.24877688,\n",
       "        -0.24785869, -0.2481432 , -0.24846845, -0.24841753, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843494, -0.24838691, -0.24716021,\n",
       "        -0.25153972, -0.24878581, -0.24958088, -0.24841944, -0.24884599,\n",
       "        -0.24831375, -0.24852194, -0.24836495, -0.24838026, -0.24899707,\n",
       "        -0.24829106, -0.2489025 , -0.24836027, -0.2485403 , -0.24843701,\n",
       "        -0.2482524 , -0.24839056, -0.24844145, -0.24838521, -0.24830686,\n",
       "        -0.24919003, -0.24848835, -0.24812933, -0.24863236, -0.24938741,\n",
       "        -0.24808681, -0.24819923, -0.24918727, -0.24908534, -0.24802577,\n",
       "        -0.24845101, -0.24842093, -0.24849118, -0.24842048, -0.24845768,\n",
       "        -0.24847999, -0.2485079 , -0.24844962, -0.24866853, -0.24893368,\n",
       "        -0.24843052, -0.24843732, -0.24851304, -0.24838167, -0.248379  ,\n",
       "        -0.24838575, -0.24838715, -0.24883858, -0.24851371, -0.24791382,\n",
       "        -0.24880345, -0.24838929, -0.24818422, -0.24938724, -0.2481677 ,\n",
       "        -0.24801556, -0.24948765, -0.24818235, -0.24826725, -0.24816766,\n",
       "        -0.24827635, -0.24844568, -0.24809432, -0.24838333, -0.24817828,\n",
       "        -0.24835627, -0.24876721, -0.24817285, -0.24853523, -0.24843198,\n",
       "        -0.24840028, -0.24830251, -0.24948803, -0.24788429, -0.24852336,\n",
       "        -0.24847014, -0.2486634 , -0.24819332, -0.24822461, -0.24855783,\n",
       "        -0.248448  , -0.24833235, -0.24858951, -0.24834439]),\n",
       " 'split2_test_neg_log_loss': array([-0.24843458, -0.24843399, -0.24839122, -0.248457  , -0.2484104 ,\n",
       "        -0.2484892 , -0.24832156, -0.24991636, -0.21905871, -0.24843456,\n",
       "        -0.24842615, -0.24843627, -0.24837345, -0.24841291, -0.24838707,\n",
       "        -0.24692476, -0.24197219, -0.21792171, -0.24835415, -0.24843494,\n",
       "        -0.24844699, -0.24854534, -0.24838014, -0.24810519, -0.24385372,\n",
       "        -0.24047962, -0.21770568, -0.24843494, -0.249184  , -0.24861901,\n",
       "        -0.24839639, -0.24917961, -0.2481265 , -0.24405365, -0.2405857 ,\n",
       "        -0.21784452, -0.24803136, -0.24835505, -0.24828979, -0.24837007,\n",
       "        -0.24828484, -0.24696751, -0.24514524, -0.24108247, -0.21595636,\n",
       "        -0.2489539 , -0.2490803 , -0.24836367, -0.24844533, -0.24708093,\n",
       "        -0.24899409, -0.24690838, -0.240135  , -0.2159938 , -0.25104295,\n",
       "        -0.24837692, -0.25447959, -0.24841877, -0.24657022, -0.24898437,\n",
       "        -0.30566382, -0.24051282, -0.2158277 , -0.24859726, -0.24837759,\n",
       "        -0.24784788, -0.24822669, -0.24917846, -0.80990473, -0.24912054,\n",
       "        -0.24080196, -0.21612517, -0.24850785, -0.24877019, -0.24812557,\n",
       "        -0.24852893, -0.60363402, -0.24854035, -0.24806124, -0.24109741,\n",
       "        -0.21584845, -0.24843457, -0.24843361, -0.24837577, -0.24843494,\n",
       "        -0.24843708, -0.24838552, -0.24838743, -0.24936596, -0.24799892,\n",
       "        -0.24843457, -0.24844719, -0.24843494, -0.24843482, -0.24842554,\n",
       "        -0.24841622, -0.24897837, -0.24849445, -0.24806267, -0.248422  ,\n",
       "        -0.24843494, -0.24850774, -0.24831449, -0.24844266, -0.24863649,\n",
       "        -0.24830144, -0.24831299, -0.24892182, -0.24843494, -0.24846436,\n",
       "        -0.24842294, -0.24846015, -0.24864393, -0.2488653 , -0.2470732 ,\n",
       "        -0.24743234, -0.24832422, -0.24843727, -0.24857472, -0.2484039 ,\n",
       "        -0.24822477, -0.24805491, -0.24829289, -0.24866912, -0.24741472,\n",
       "        -0.24838012, -0.24847979, -0.24852134, -0.24849089, -0.24918045,\n",
       "        -0.24846673, -0.24929166, -0.24833316, -0.24735773, -0.24815706,\n",
       "        -0.24844293, -0.24839663, -0.24850902, -0.24796744, -0.24839211,\n",
       "        -0.24899449, -0.24910015, -0.24805559, -0.24820111, -0.24817236,\n",
       "        -0.24985035, -0.24819646, -0.24833098, -0.24891106, -0.24768625,\n",
       "        -0.25055885, -0.24814199, -0.24814875, -0.24833602, -0.2484671 ,\n",
       "        -0.2484405 , -0.24838987, -0.24824746, -0.24840328, -0.24951406,\n",
       "        -0.24749855, -0.24826677, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843456, -0.24856417, -0.24933916,\n",
       "        -0.24810912, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24842515, -0.24919305, -0.24911967, -0.24778329,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24844547, -0.24855158, -0.2478463 , -0.25238458, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843453, -0.24841202,\n",
       "        -0.24880745, -0.24771104, -0.24876134, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843227, -0.24841974, -0.25015311,\n",
       "        -0.24806037, -0.24848358, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843494, -0.24914651, -0.24764428, -0.25130714,\n",
       "        -0.24914643, -0.24843457, -0.24843457, -0.24843457, -0.24843365,\n",
       "        -0.24859311, -0.24896498, -0.24848525, -0.24834968, -0.24858089,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24842489, -0.24848178,\n",
       "        -0.25002673, -0.24732236, -0.24842159, -0.2483256 , -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24844383, -0.24981873, -0.24830024,\n",
       "        -0.25215441, -0.24955401, -0.24897036, -0.24861368, -0.25059709,\n",
       "        -0.25060327, -0.25092849, -0.24816001, -0.24911866, -0.24806414,\n",
       "        -0.24807609, -0.24855631, -0.24887464, -0.24815409, -0.24931345,\n",
       "        -0.24828902, -0.24904221, -0.24787311, -0.24868651, -0.2486225 ,\n",
       "        -0.24786203, -0.24845213, -0.24900616, -0.24845445, -0.24846248,\n",
       "        -0.24845404, -0.24848191, -0.24843119, -0.24854228, -0.24843305,\n",
       "        -0.24857338, -0.24851082, -0.24844654, -0.24843742, -0.24845226,\n",
       "        -0.24865622, -0.24903388, -0.24843975, -0.24852586, -0.24832423,\n",
       "        -0.2482554 , -0.24898756, -0.24819914, -0.24843178, -0.24874834,\n",
       "        -0.24863194, -0.24845169, -0.24876119, -0.24815167, -0.24803107,\n",
       "        -0.24826096, -0.24858167, -0.2483865 , -0.24819797, -0.24923972,\n",
       "        -0.24861319, -0.24890417, -0.24867687, -0.248252  , -0.24800249,\n",
       "        -0.24780636, -0.24929872, -0.24839375, -0.24841043, -0.24869299,\n",
       "        -0.24845675, -0.24792439, -0.24875479, -0.24876531, -0.2480523 ,\n",
       "        -0.24814894, -0.24851026, -0.24871705, -0.24838425, -0.24786804,\n",
       "        -0.24821215, -0.24870642, -0.24834047, -0.24809227, -0.24888172,\n",
       "        -0.24829928, -0.24857844, -0.24872753, -0.2478897 ]),\n",
       " 'split3_test_neg_log_loss': array([-0.24843456, -0.24843458, -0.24842104, -0.24850661, -0.24856223,\n",
       "        -0.2485253 , -0.24847416, -0.24721028, -0.21748598, -0.24843465,\n",
       "        -0.24855583, -0.24858262, -0.24863921, -0.24850605, -0.24875305,\n",
       "        -0.24882096, -0.23842433, -0.21057249, -0.24891789, -0.24843494,\n",
       "        -0.24826061, -0.24845733, -0.24853656, -0.24920333, -0.24861163,\n",
       "        -0.23591036, -0.21029339, -0.24843494, -0.24857824, -0.24848502,\n",
       "        -0.24908016, -0.24919464, -0.24698739, -0.24466953, -0.2351066 ,\n",
       "        -0.21055529, -0.24839642, -0.24849269, -0.24849554, -0.24835704,\n",
       "        -0.24820798, -0.24673194, -0.24463027, -0.2348457 , -0.20599113,\n",
       "        -0.24841495, -0.24842404, -0.24848383, -0.2482982 , -0.24692151,\n",
       "        -0.24732824, -0.24525431, -0.2372658 , -0.20601393, -0.24868154,\n",
       "        -0.24833903, -0.24898492, -0.24928004, -0.25072602, -0.24771313,\n",
       "        -0.27801131, -0.2399773 , -0.20622548, -0.24845072, -0.24843149,\n",
       "        -0.24908014, -0.24941182, -0.24804285, -0.85024895, -0.24818723,\n",
       "        -0.2376416 , -0.20618493, -0.24857001, -0.24915574, -0.24903701,\n",
       "        -0.24843867, -0.25429183, -0.24885693, -0.24860937, -0.23824083,\n",
       "        -0.20608659, -0.24843457, -0.24843477, -0.2484392 , -0.24843494,\n",
       "        -0.24841279, -0.24847419, -0.24840148, -0.24835331, -0.24809557,\n",
       "        -0.24843473, -0.24853016, -0.24843494, -0.24867886, -0.24841401,\n",
       "        -0.24844434, -0.24824992, -0.24810674, -0.24798117, -0.24876674,\n",
       "        -0.24845232, -0.24862296, -0.24857579, -0.24848058, -0.24872863,\n",
       "        -0.248753  , -0.24671669, -0.24841934, -0.24843494, -0.24835183,\n",
       "        -0.24855127, -0.24846477, -0.24827356, -0.24860967, -0.24773423,\n",
       "        -0.24694836, -0.2482803 , -0.24846444, -0.24836374, -0.24845386,\n",
       "        -0.24821474, -0.24844085, -0.24881886, -0.2460819 , -0.24767725,\n",
       "        -0.24747255, -0.24843142, -0.2483258 , -0.24849033, -0.24833643,\n",
       "        -0.24801293, -0.24801914, -0.2479146 , -0.24798138, -0.2471662 ,\n",
       "        -0.24850952, -0.24907912, -0.24955074, -0.24916084, -0.24872891,\n",
       "        -0.24852924, -0.24773013, -0.24726374, -0.24718084, -0.24847104,\n",
       "        -0.24842875, -0.24845928, -0.24814425, -0.24884256, -0.24807334,\n",
       "        -0.24798362, -0.2451799 , -0.24739841, -0.24826324, -0.24865775,\n",
       "        -0.24846153, -0.24867095, -0.24858427, -0.24868632, -0.24797716,\n",
       "        -0.24728546, -0.24716254, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24841453, -0.24869038,\n",
       "        -0.24569997, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.248438  , -0.24868828, -0.2475826 , -0.24809865,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843494, -0.24844377, -0.24772407, -0.25321624, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843456, -0.2484272 ,\n",
       "        -0.24861906, -0.24792523, -0.24916142, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843494, -0.24853101, -0.24754516,\n",
       "        -0.24666895, -0.24941453, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.2484883 , -0.24844619, -0.24686523, -0.24982432,\n",
       "        -0.24935932, -0.24843457, -0.24843457, -0.24843457, -0.24843456,\n",
       "        -0.24863287, -0.24890489, -0.247477  , -0.24873265, -0.24915119,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24859021, -0.24859553,\n",
       "        -0.24748165, -0.24740848, -0.24857376, -0.25006843, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843494, -0.24864958, -0.24636052,\n",
       "        -0.25576119, -0.2491335 , -0.24787747, -0.24850881, -0.24843768,\n",
       "        -0.24846854, -0.248514  , -0.24855135, -0.24877345, -0.24844038,\n",
       "        -0.24879812, -0.24843354, -0.2484434 , -0.2484391 , -0.24850122,\n",
       "        -0.24849806, -0.24861279, -0.24844228, -0.24860779, -0.24843498,\n",
       "        -0.24845644, -0.24823116, -0.24831958, -0.24851485, -0.24904261,\n",
       "        -0.24869631, -0.2488603 , -0.24824055, -0.2488254 , -0.24882685,\n",
       "        -0.24841328, -0.24838314, -0.24789722, -0.24813668, -0.24877993,\n",
       "        -0.24822983, -0.24837225, -0.24822513, -0.24869913, -0.24866373,\n",
       "        -0.24852607, -0.24842175, -0.24847108, -0.24841496, -0.24860246,\n",
       "        -0.24863841, -0.24864934, -0.24845056, -0.24856038, -0.24841225,\n",
       "        -0.24845654, -0.24839112, -0.24847529, -0.24863244, -0.24838828,\n",
       "        -0.24862857, -0.24839121, -0.24861186, -0.2484939 , -0.24859691,\n",
       "        -0.24876529, -0.24845518, -0.24859733, -0.24882011, -0.24842599,\n",
       "        -0.24838802, -0.24846101, -0.24841119, -0.24845021, -0.24855021,\n",
       "        -0.24864764, -0.24829131, -0.24829737, -0.24841828, -0.24851364,\n",
       "        -0.24846889, -0.24869501, -0.24827517, -0.24838154, -0.24837658,\n",
       "        -0.24830594, -0.24844227, -0.24861933, -0.24843716]),\n",
       " 'split4_test_neg_log_loss': array([-0.24843458, -0.24843464, -0.24848506, -0.24829795, -0.24844062,\n",
       "        -0.24828114, -0.24836658, -0.24916338, -0.21982314, -0.24843549,\n",
       "        -0.2481081 , -0.2486257 , -0.24861971, -0.24843424, -0.24819618,\n",
       "        -0.24831866, -0.23883019, -0.21209207, -0.24871821, -0.24843494,\n",
       "        -0.24831745, -0.24849473, -0.24837854, -0.2476445 , -0.24461401,\n",
       "        -0.23552874, -0.21200437, -0.24843494, -0.24872411, -0.24849334,\n",
       "        -0.24859886, -0.24845779, -0.24453507, -0.24102441, -0.23527481,\n",
       "        -0.2115639 , -0.24838554, -0.24863085, -0.24836247, -0.24839408,\n",
       "        -0.24515369, -0.24324359, -0.23939976, -0.23559977, -0.21130339,\n",
       "        -0.2488685 , -0.24865659, -0.24773277, -0.24857527, -0.24203941,\n",
       "        -0.24775357, -0.24153802, -0.23787624, -0.21119777, -0.2491474 ,\n",
       "        -0.24843196, -0.24951575, -0.24849518, -0.24632038, -0.24925765,\n",
       "        -0.27795907, -0.23787478, -0.21131659, -0.25141391, -0.24798623,\n",
       "        -0.24846241, -0.24825386, -0.24763403, -0.68717172, -0.24635785,\n",
       "        -0.2363676 , -0.21146436, -0.2483165 , -0.24924543, -0.2486817 ,\n",
       "        -0.24829034, -0.38495921, -0.24825085, -0.2463058 , -0.23610229,\n",
       "        -0.21130595, -0.24843457, -0.24843445, -0.24838764, -0.24843494,\n",
       "        -0.24824291, -0.24857563, -0.2481585 , -0.24761848, -0.24782549,\n",
       "        -0.24843452, -0.24837139, -0.24843494, -0.24857343, -0.24816626,\n",
       "        -0.2481898 , -0.24855619, -0.24632857, -0.24778992, -0.24829938,\n",
       "        -0.24840487, -0.24838091, -0.24845434, -0.24850186, -0.24804549,\n",
       "        -0.24923564, -0.24704817, -0.24831051, -0.24843494, -0.24807049,\n",
       "        -0.24843382, -0.24847658, -0.24813858, -0.24806137, -0.24677185,\n",
       "        -0.24731156, -0.24892058, -0.24836541, -0.24820318, -0.24852315,\n",
       "        -0.24815746, -0.24772445, -0.24860471, -0.24780372, -0.24740061,\n",
       "        -0.24840294, -0.2482124 , -0.2481401 , -0.24940098, -0.24863798,\n",
       "        -0.24878594, -0.24869581, -0.24726405, -0.24744471, -0.24806355,\n",
       "        -0.24825088, -0.25052262, -0.24955628, -0.24837913, -0.24842157,\n",
       "        -0.24827572, -0.24786717, -0.24793277, -0.24802122, -0.25015189,\n",
       "        -0.24843244, -0.24843658, -0.24762744, -0.24867649, -0.24819511,\n",
       "        -0.24790116, -0.24586083, -0.24802393, -0.25124418, -0.24997987,\n",
       "        -0.24959489, -0.24888604, -0.24650451, -0.2482361 , -0.24773716,\n",
       "        -0.24716514, -0.24799666, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843456, -0.24837391, -0.24818068,\n",
       "        -0.24840124, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24856313, -0.24831649, -0.24719647, -0.24617679,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843494, -0.24841817, -0.24632797, -0.24800506, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843458, -0.24839768,\n",
       "        -0.24873286, -0.24583947, -0.24889439, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843308, -0.24837274, -0.24599599,\n",
       "        -0.24701084, -0.24894426, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843494, -0.24839177, -0.24694246, -0.24919496,\n",
       "        -0.24923847, -0.24843457, -0.24843457, -0.24843457, -0.24843459,\n",
       "        -0.24836326, -0.24839202, -0.24573864, -0.24910945, -0.24833901,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24837956, -0.24838768,\n",
       "        -0.24546269, -0.24775241, -0.24870649, -0.24923067, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843494, -0.24841171, -0.24790501,\n",
       "        -0.24837783, -0.24824737, -0.24872958, -0.2484406 , -0.24854194,\n",
       "        -0.24846369, -0.24844744, -0.24823189, -0.24824696, -0.24838117,\n",
       "        -0.24874445, -0.24826013, -0.24842989, -0.2471809 , -0.2481036 ,\n",
       "        -0.24831651, -0.25143841, -0.24735819, -0.24908363, -0.24916433,\n",
       "        -0.2487134 , -0.24840648, -0.24842114, -0.24847182, -0.24843625,\n",
       "        -0.24842177, -0.24841947, -0.24847304, -0.24841937, -0.24842111,\n",
       "        -0.24951805, -0.24829811, -0.24868157, -0.24840443, -0.24859926,\n",
       "        -0.24890578, -0.24890785, -0.24812351, -0.24933146, -0.248396  ,\n",
       "        -0.24813664, -0.24849091, -0.2486158 , -0.24828005, -0.24826754,\n",
       "        -0.24824787, -0.24853472, -0.24843071, -0.24997573, -0.24851389,\n",
       "        -0.24698883, -0.24882099, -0.24830047, -0.24998812, -0.24814547,\n",
       "        -0.2488768 , -0.24749356, -0.24828191, -0.24827503, -0.24867122,\n",
       "        -0.24847602, -0.24833369, -0.24831122, -0.24829187, -0.24845791,\n",
       "        -0.24859301, -0.24832239, -0.2484881 , -0.2482955 , -0.24857703,\n",
       "        -0.24854706, -0.2483288 , -0.24838407, -0.24834928, -0.24859539,\n",
       "        -0.24826464, -0.24830117, -0.24875494, -0.24828769, -0.24825406,\n",
       "        -0.24846673, -0.24842593, -0.24888657, -0.24841893]),\n",
       " 'mean_test_neg_log_loss': array([-0.24843457, -0.24843446, -0.24840133, -0.24842213, -0.24842562,\n",
       "        -0.24846498, -0.24843413, -0.24807107, -0.21431025, -0.24843479,\n",
       "        -0.24843407, -0.24852828, -0.24850996, -0.24839465, -0.2484718 ,\n",
       "        -0.24882807, -0.23809684, -0.21021897, -0.24860786, -0.24843494,\n",
       "        -0.2483936 , -0.24846785, -0.24839176, -0.2483876 , -0.24678487,\n",
       "        -0.23647979, -0.20987681, -0.24841138, -0.24881846, -0.24851324,\n",
       "        -0.2485983 , -0.24883365, -0.24824138, -0.24469427, -0.23618595,\n",
       "        -0.21001744, -0.24856222, -0.24842873, -0.24858785, -0.24832239,\n",
       "        -0.24821963, -0.24616419, -0.24448983, -0.23629305, -0.20690119,\n",
       "        -0.24861396, -0.24866365, -0.2483024 , -0.24842106, -0.24787594,\n",
       "        -0.24893836, -0.24449094, -0.23812885, -0.20703441, -0.24911874,\n",
       "        -0.24860371, -0.24990653, -0.24902331, -0.2512287 , -0.24838949,\n",
       "        -0.28645335, -0.24019133, -0.20723546, -0.24907109, -0.24850662,\n",
       "        -0.24854403, -0.24854832, -0.2478771 , -2.96257122, -0.24821513,\n",
       "        -0.23954188, -0.2071632 , -0.2484017 , -0.24888831, -0.24854016,\n",
       "        -0.24859803, -0.38446792, -0.248514  , -0.24810089, -0.23966192,\n",
       "        -0.2070592 , -0.24843457, -0.24843438, -0.24839747, -0.24843609,\n",
       "        -0.24840279, -0.24846688, -0.24837527, -0.24840364, -0.24806393,\n",
       "        -0.24843457, -0.24841732, -0.24843494, -0.24847884, -0.24841784,\n",
       "        -0.24838259, -0.24849132, -0.24813906, -0.24797048, -0.24851635,\n",
       "        -0.2484324 , -0.24847002, -0.24841479, -0.24853708, -0.24871963,\n",
       "        -0.24878328, -0.24781927, -0.24862157, -0.24843059, -0.24836347,\n",
       "        -0.24846272, -0.24845293, -0.2483998 , -0.24847141, -0.24730948,\n",
       "        -0.24748568, -0.24836013, -0.24839162, -0.2483875 , -0.24840268,\n",
       "        -0.2483105 , -0.248265  , -0.24849385, -0.24741597, -0.24752483,\n",
       "        -0.24806365, -0.2485227 , -0.24847649, -0.24862911, -0.24869595,\n",
       "        -0.24854502, -0.24842406, -0.24846972, -0.24784978, -0.24779638,\n",
       "        -0.24840462, -0.24879911, -0.24895003, -0.24857063, -0.24853551,\n",
       "        -0.24837519, -0.24805612, -0.24797532, -0.2476121 , -0.24867625,\n",
       "        -0.24871252, -0.24872136, -0.24833834, -0.2493887 , -0.24830222,\n",
       "        -0.24856536, -0.24751049, -0.24761057, -0.24906388, -0.24896344,\n",
       "        -0.24871343, -0.24848891, -0.24798701, -0.24842847, -0.24856863,\n",
       "        -0.24759172, -0.24766246, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24910608, -0.24844137,\n",
       "        -0.24742537, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24851137, -0.24902931, -0.24824685, -0.24767536,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843705, -0.24875575, -0.24746457, -0.25177223, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24843459, -0.24871203,\n",
       "        -0.24836425, -0.247243  , -0.24873852, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.2484337 , -0.24844629, -0.24818583,\n",
       "        -0.24770605, -0.24878102, -0.24843457, -0.24843457, -0.24843457,\n",
       "        -0.24843457, -0.24844561, -0.24903923, -0.2473387 , -0.25211108,\n",
       "        -0.24901282, -0.24843457, -0.24843457, -0.24843457, -0.24843439,\n",
       "        -0.24903059, -0.24852255, -0.2475465 , -0.24874023, -0.24849876,\n",
       "        -0.24843457, -0.24843457, -0.24843457, -0.24848958, -0.24886212,\n",
       "        -0.24812061, -0.24805791, -0.24852165, -0.24891894, -0.24843457,\n",
       "        -0.24843457, -0.24843457, -0.24846957, -0.24901702, -0.24781551,\n",
       "        -0.25154417, -0.24882979, -0.2487229 , -0.24850628, -0.24897154,\n",
       "        -0.24887193, -0.24898653, -0.24835996, -0.2485936 , -0.2484806 ,\n",
       "        -0.2484909 , -0.24859646, -0.24844289, -0.24814508, -0.24857763,\n",
       "        -0.24848499, -0.24917854, -0.24813374, -0.2486658 , -0.24855763,\n",
       "        -0.24851379, -0.24836292, -0.24853463, -0.24855067, -0.24873572,\n",
       "        -0.24840969, -0.24857382, -0.24874138, -0.24863995, -0.24839117,\n",
       "        -0.24868306, -0.24840094, -0.2483944 , -0.24834945, -0.24856223,\n",
       "        -0.24852922, -0.24864731, -0.2483161 , -0.24875732, -0.24854595,\n",
       "        -0.2483794 , -0.24845458, -0.24853429, -0.24853374, -0.24850766,\n",
       "        -0.24859426, -0.2485801 , -0.24849437, -0.24874001, -0.24822855,\n",
       "        -0.2481589 , -0.24862615, -0.24838562, -0.24895444, -0.24871001,\n",
       "        -0.24856399, -0.24864135, -0.24846459, -0.2483573 , -0.24846634,\n",
       "        -0.24833365, -0.24860342, -0.24835444, -0.24845316, -0.24846549,\n",
       "        -0.24842598, -0.24836639, -0.24844416, -0.24847494, -0.24840637,\n",
       "        -0.24841917, -0.24840952, -0.24866071, -0.24833098, -0.24838745,\n",
       "        -0.2483533 , -0.24855539, -0.24838518, -0.2482662 , -0.24847962,\n",
       "        -0.24841046, -0.24842963, -0.24865073, -0.24836538]),\n",
       " 'std_test_neg_log_loss': array([4.99629058e-09, 2.41346154e-07, 9.01901308e-05, 6.92277959e-05,\n",
       "        7.66152951e-05, 1.04537352e-04, 1.19913856e-04, 1.33919063e-03,\n",
       "        5.74104322e-03, 3.47758661e-07, 1.69791018e-04, 7.84208043e-05,\n",
       "        1.05379643e-04, 8.64501191e-05, 1.83848653e-04, 1.18205565e-03,\n",
       "        3.19085308e-03, 4.77109431e-03, 1.95352535e-04, 1.24126708e-17,\n",
       "        9.14939416e-05, 4.81684996e-05, 8.43529465e-05, 5.17125559e-04,\n",
       "        2.27160106e-03, 2.30635315e-03, 4.94014388e-03, 4.71096755e-05,\n",
       "        2.63835863e-04, 5.32373220e-05, 2.63386921e-04, 3.49615615e-04,\n",
       "        2.50499429e-03, 2.19479380e-03, 2.63086937e-03, 4.80718175e-03,\n",
       "        5.65961684e-04, 1.33121056e-04, 3.22301049e-04, 1.34663744e-04,\n",
       "        1.80630167e-03, 1.62345456e-03, 2.66992436e-03, 2.86762990e-03,\n",
       "        6.03569540e-03, 2.64886879e-04, 3.28485755e-04, 3.62936478e-04,\n",
       "        9.06409632e-05, 3.61778682e-03, 2.55065266e-03, 2.03220007e-03,\n",
       "        1.51828459e-03, 5.90566990e-03, 1.00456925e-03, 4.00202368e-04,\n",
       "        2.33414055e-03, 8.08469147e-04, 4.93276001e-03, 6.61777132e-04,\n",
       "        1.99607994e-02, 1.46774890e-03, 5.68743691e-03, 1.17290356e-03,\n",
       "        3.35522912e-04, 4.17777905e-04, 4.49315498e-04, 7.42209440e-04,\n",
       "        3.50654088e+00, 9.86817628e-04, 2.21380670e-03, 5.94939553e-03,\n",
       "        1.37701127e-04, 2.90530103e-04, 3.05250400e-04, 3.40799438e-04,\n",
       "        1.18054508e-01, 2.71751962e-04, 9.60377284e-04, 2.24076479e-03,\n",
       "        5.86273237e-03, 1.80733700e-10, 4.01794965e-07, 3.46028186e-05,\n",
       "        2.29336308e-06, 1.02362407e-04, 9.85710528e-05, 1.13676022e-04,\n",
       "        6.73191794e-04, 1.40769218e-04, 8.82475672e-08, 7.63375389e-05,\n",
       "        1.24126708e-17, 1.28291450e-04, 2.02190806e-04, 1.10632793e-04,\n",
       "        2.74543357e-04, 1.25414026e-03, 2.31765485e-04, 1.71055340e-04,\n",
       "        1.53234036e-05, 8.83966141e-05, 9.22698016e-05, 1.77496290e-04,\n",
       "        5.23535548e-04, 3.32647044e-04, 1.01291122e-03, 2.53323763e-04,\n",
       "        8.68845830e-06, 1.62993386e-04, 4.63112149e-05, 2.38680424e-05,\n",
       "        1.78310256e-04, 2.64965830e-04, 6.75387701e-04, 9.39535053e-04,\n",
       "        2.94616901e-04, 1.50355369e-04, 1.22241172e-04, 1.17145203e-04,\n",
       "        2.15647764e-04, 3.44601900e-04, 1.95715368e-04, 1.02065234e-03,\n",
       "        5.49206824e-04, 3.49126576e-04, 2.75141466e-04, 2.81552734e-04,\n",
       "        4.10081501e-04, 3.06203506e-04, 4.28755618e-04, 5.15021812e-04,\n",
       "        1.39944853e-03, 6.20848107e-04, 4.08833510e-04, 2.52093277e-04,\n",
       "        9.48040229e-04, 4.95268723e-04, 4.24452701e-04, 3.15736096e-04,\n",
       "        4.86857549e-04, 1.06282987e-03, 4.82236671e-04, 4.38785222e-04,\n",
       "        7.45225536e-04, 5.83204701e-04, 6.66221034e-04, 6.05612929e-04,\n",
       "        1.24319463e-03, 5.99179647e-04, 1.00405049e-03, 1.86488165e-03,\n",
       "        4.43439342e-04, 1.13568664e-03, 6.39731742e-04, 5.51354102e-04,\n",
       "        3.61599380e-04, 7.56439771e-04, 1.49887564e-04, 7.29267517e-04,\n",
       "        5.81748460e-04, 4.56962677e-04, 2.14993764e-17, 2.14993764e-17,\n",
       "        2.14993764e-17, 7.36523201e-14, 7.19036233e-14, 1.96418582e-08,\n",
       "        1.34206545e-03, 5.39083998e-04, 1.50843315e-03, 2.14993764e-17,\n",
       "        2.14993764e-17, 2.14993764e-17, 3.18196654e-14, 3.90079550e-12,\n",
       "        1.04847940e-04, 8.54876743e-04, 8.62071248e-04, 8.40318354e-04,\n",
       "        2.14993764e-17, 2.14993764e-17, 5.02519644e-14, 9.13972182e-15,\n",
       "        5.78407456e-10, 4.21314789e-06, 5.99339294e-04, 8.90654071e-04,\n",
       "        2.23677149e-03, 2.14993764e-17, 2.14993764e-17, 7.55639559e-14,\n",
       "        2.63858902e-14, 6.55302586e-08, 6.41807187e-04, 5.35398560e-04,\n",
       "        9.76733929e-04, 2.77853694e-04, 2.14993764e-17, 2.14993764e-17,\n",
       "        2.92336817e-14, 1.35522294e-12, 1.06611898e-06, 7.44006557e-05,\n",
       "        1.47791595e-03, 8.73570158e-04, 3.65792310e-04, 2.14993764e-17,\n",
       "        6.67207934e-14, 2.74572907e-14, 2.96410544e-10, 2.13452059e-05,\n",
       "        8.66731088e-04, 8.28667207e-04, 4.36144531e-03, 3.42566976e-04,\n",
       "        2.14993764e-17, 4.79981383e-14, 2.45416959e-14, 3.70487265e-07,\n",
       "        1.08689002e-03, 5.18475419e-04, 1.19616101e-03, 3.16710325e-04,\n",
       "        3.70974512e-04, 2.14993764e-17, 9.17532650e-14, 2.22743901e-12,\n",
       "        9.59522954e-05, 6.17081448e-04, 1.66770251e-03, 8.53229585e-04,\n",
       "        1.06514982e-04, 6.56699639e-04, 8.91535824e-14, 2.12138499e-14,\n",
       "        2.50175903e-10, 6.48978083e-05, 6.60759288e-04, 1.01478155e-03,\n",
       "        2.48697719e-03, 4.73101035e-04, 5.62724022e-04, 7.10120942e-05,\n",
       "        8.26512895e-04, 8.68241912e-04, 9.71377203e-04, 1.48572102e-04,\n",
       "        3.14547996e-04, 3.01083835e-04, 2.73339869e-04, 2.40583279e-04,\n",
       "        2.47682447e-04, 4.98614293e-04, 3.98434565e-04, 3.03995524e-04,\n",
       "        1.15405327e-03, 4.55114366e-04, 2.31121933e-04, 3.28363454e-04,\n",
       "        4.36582975e-04, 1.08569074e-04, 3.20791625e-04, 8.95832526e-05,\n",
       "        4.07950120e-04, 1.94381732e-04, 2.70724675e-04, 4.51474925e-04,\n",
       "        2.78806131e-04, 2.63125648e-04, 4.20906145e-04, 6.84827179e-05,\n",
       "        2.62860236e-04, 1.10524158e-04, 1.21163998e-04, 2.34090548e-04,\n",
       "        2.70754476e-04, 1.25842749e-04, 2.94205696e-04, 2.25280742e-04,\n",
       "        1.59362340e-04, 3.33577023e-04, 2.18050217e-04, 3.17648566e-04,\n",
       "        1.68660882e-04, 2.79510188e-04, 1.72668147e-04, 2.99741598e-04,\n",
       "        6.34807684e-04, 2.25867718e-04, 6.16334133e-04, 2.25682447e-04,\n",
       "        1.37315624e-04, 6.45335175e-04, 6.00805467e-04, 2.89849122e-04,\n",
       "        6.70627993e-04, 1.95395673e-04, 1.13590665e-04, 3.30385564e-04,\n",
       "        3.12415495e-04, 3.51385052e-04, 1.61566135e-04, 1.87633563e-04,\n",
       "        1.71619939e-04, 9.30282245e-05, 2.70923888e-04, 1.87430623e-04,\n",
       "        1.68651127e-04, 1.87633633e-04, 1.71146926e-04, 1.29760350e-04,\n",
       "        4.37160017e-04, 2.42134148e-04, 2.64522598e-04, 1.04694677e-04,\n",
       "        1.67007413e-04, 1.93995886e-04, 1.01923463e-04, 2.24637554e-04,\n",
       "        9.24334428e-05, 8.41875212e-05, 1.51427360e-04, 2.72996422e-04]),\n",
       " 'rank_test_neg_log_loss': array([174, 135, 105, 121, 123, 192, 132,  52,   9, 177, 131, 227, 218,\n",
       "        101, 201, 292,  13,   8, 259, 178,  99, 196,  98,  94,  22,  12,\n",
       "          6, 115, 291, 220, 256, 294,  63,  20,  10,   7, 242, 126, 251,\n",
       "         71,  61,  21,  18,  11,   1, 260, 269,  68, 120,  43, 299,  19,\n",
       "         14,   2, 314, 258, 317, 307, 318,  95, 322,  17,   5, 312, 216,\n",
       "        235, 238,  44, 324,  60,  15,   4, 106, 297, 234, 255, 323, 222,\n",
       "         53,  16,   3, 173, 133, 102, 180, 108, 195,  87, 109,  51, 175,\n",
       "        117, 178, 204, 118,  89, 211,  56,  45, 223, 129, 199, 116, 233,\n",
       "        278, 289,  41, 261, 128,  82, 190, 187, 103, 200,  24,  29,  80,\n",
       "         97,  93, 107,  69,  65, 212,  26,  31,  50, 226, 203, 263, 273,\n",
       "        236, 122, 198,  42,  39, 110, 290, 300, 247, 232,  86,  48,  46,\n",
       "         35, 271, 276, 279,  74, 316,  67, 245,  30,  34, 311, 302, 277,\n",
       "        208,  47, 125, 246,  33,  36, 157, 157, 157, 153, 146, 136, 313,\n",
       "        182,  27, 157, 157, 157, 149, 172, 219, 308,  64,  37, 157, 157,\n",
       "        154, 143, 137, 181, 286,  28, 320, 157, 157, 151, 145, 176, 275,\n",
       "         83,  23, 282, 157, 157, 142, 140, 130, 186,  59,  38, 288, 157,\n",
       "        152, 147, 138, 185, 310,  25, 321, 305, 157, 148, 141, 134, 309,\n",
       "        225,  32, 284, 214, 157, 150, 156, 209, 295,  54,  49, 224, 298,\n",
       "        155, 144, 139, 197, 306,  40, 319, 293, 280, 215, 303, 296, 304,\n",
       "         79, 252, 206, 210, 254, 183,  57, 249, 207, 315,  55, 270, 241,\n",
       "        221,  81, 231, 239, 281, 113, 248, 285, 264,  96, 272, 104, 100,\n",
       "         75, 243, 228, 266,  70, 287, 237,  88, 189, 230, 229, 217, 253,\n",
       "        250, 213, 283,  62,  58, 262,  91, 301, 274, 244, 265, 191,  78,\n",
       "        194,  73, 257,  77, 188, 193, 124,  85, 184, 202, 111, 119, 112,\n",
       "        268,  72,  92,  76, 240,  90,  66, 205, 114, 127, 267,  84])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIAL_1_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL ONE NEG LOG LOSS RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL ONE NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_1_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL ONE F1 RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL ONE F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_1_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL ONE ROC AUC RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL ONE ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_1_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 1 svm using best NEG LOG LOSS hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 1 svm using best F1 hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 1 svm using best ROC_AUC hyperparameters :0.9319\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 1 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 1 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 1 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL TWO ON POKER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL TWO RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = pokerData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    \n",
    "    pipe = Pipeline([('std', MinMaxScaler(feature_range = (0, 1))),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_2_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL TWO RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.4285686 , 0.40074401, 0.40905147, 0.4133554 , 0.41705866,\n",
       "        0.41827903, 0.41145363, 0.42946925, 0.44167976, 0.44037876,\n",
       "        0.42629981, 0.42023258, 0.41665835, 0.41615791, 0.41435614,\n",
       "        0.4226635 , 0.45118814, 0.74333892, 0.45669279, 0.42146244,\n",
       "        0.4187602 , 0.41916051, 0.41996117, 0.42916913, 0.42506561,\n",
       "        0.54987297, 1.35396452, 0.44338121, 0.42296333, 0.42336373,\n",
       "        0.4205616 , 0.42306418, 0.4234642 , 0.56398506, 1.44344144,\n",
       "        1.61548929, 0.4573935 , 0.42466526, 0.42166276, 0.43757648,\n",
       "        0.43637519, 0.52675309, 0.85503497, 2.13673782, 1.63210373,\n",
       "        0.44668403, 0.41996117, 0.42856851, 0.44538307, 0.42336373,\n",
       "        1.22555389, 2.11411815, 2.25143614, 2.11822143, 0.45409012,\n",
       "        0.48521748, 0.56438603, 0.93388033, 1.94717412, 2.04283051,\n",
       "        2.26825056, 2.9799633 , 2.08889651, 0.51614399, 0.62643876,\n",
       "        0.8098968 , 1.39209728, 1.93686562, 2.25774179, 3.08315115,\n",
       "        3.05092392, 2.09269981, 0.52955556, 0.68819189, 0.86834655,\n",
       "        1.3222373 , 2.13553658, 3.07334328, 3.19785008, 3.04782124,\n",
       "        2.10230761, 0.38563151, 0.39704118, 0.40514827, 0.3963407 ,\n",
       "        0.40164547, 0.39423923, 0.39153438, 0.39263768, 0.72262077,\n",
       "        0.39523988, 0.4043478 , 0.39013557, 0.3832294 , 0.38662958,\n",
       "        0.39834261, 0.40234637, 0.4341733 , 0.71291327, 0.39634061,\n",
       "        0.42646694, 0.38713341, 0.38573146, 0.38533144, 0.38953505,\n",
       "        0.3819283 , 0.63044209, 0.70450578, 0.38603225, 0.39123659,\n",
       "        0.38613214, 0.38012638, 0.38993545, 0.39243722, 0.38813376,\n",
       "        0.64045091, 0.6515604 , 0.3826292 , 0.37722421, 0.39263759,\n",
       "        0.38382993, 0.38683243, 0.38653255, 0.59280958, 0.65506301,\n",
       "        0.63904953, 0.37702441, 0.37772498, 0.38703275, 0.39093599,\n",
       "        0.39533982, 0.38513098, 1.99531612, 0.6485817 , 0.62053361,\n",
       "        0.37922597, 0.38262911, 0.38202853, 0.38112793, 0.39123664,\n",
       "        0.38873467, 1.95227871, 0.63064194, 0.61442833, 0.37532263,\n",
       "        0.39093657, 0.39033599, 0.39043565, 0.38242912, 0.68719072,\n",
       "        2.25483904, 0.63094268, 0.62083402, 0.39093623, 0.39013548,\n",
       "        0.38713255, 0.38613195, 0.5085371 , 2.42518554, 2.36123042,\n",
       "        0.61763172, 0.67307882, 0.31086717, 0.28974895, 0.28724713,\n",
       "        0.29275174, 0.29105043, 0.29355226, 0.29065013, 0.28914876,\n",
       "        0.54326725, 0.28894844, 0.30085874, 0.3075644 , 0.30496225,\n",
       "        0.31557169, 0.29074998, 0.29895706, 0.29475393, 1.0526051 ,\n",
       "        0.29685545, 0.29665518, 0.29225097, 0.30055842, 0.28834791,\n",
       "        0.29415293, 0.28964906, 0.33458786, 1.71347365, 0.28784719,\n",
       "        0.29785624, 0.29305205, 0.29215107, 0.28544521, 0.29195118,\n",
       "        0.28964977, 0.54757099, 1.96879296, 0.29095011, 0.30416131,\n",
       "        0.30115914, 0.28834867, 0.28834815, 0.29275174, 0.29595442,\n",
       "        1.04970264, 2.38725319, 0.29055009, 0.29295201, 0.28524504,\n",
       "        0.29355245, 0.29675517, 0.28954911, 0.33438787, 1.69956155,\n",
       "        2.34962077, 0.2947535 , 0.29215145, 0.2880477 , 0.29074979,\n",
       "        0.28884878, 0.28734713, 0.5296556 , 1.95257916, 2.19729013,\n",
       "        0.29115057, 0.29245143, 0.29535413, 0.29004922, 0.28854804,\n",
       "        0.28954902, 1.05550809, 2.37324066, 2.17066693, 0.28564568,\n",
       "        0.28814769, 0.3007585 , 0.29175081, 0.28134193, 0.32377844,\n",
       "        1.79994798, 2.56540694, 2.57581539, 0.26462727, 0.23430185,\n",
       "        0.27413607, 0.27333565, 0.31487079, 0.28454499, 0.29335241,\n",
       "        0.28294315, 0.25371952, 0.25782156, 0.25251722, 0.25682039,\n",
       "        0.25001521, 0.25852227, 0.26002355, 0.27273402, 0.25401831,\n",
       "        0.27463617, 0.26993227, 0.27033243, 0.29875646, 0.27003241,\n",
       "        0.3423945 , 0.29535341, 0.27353454, 0.27183323, 0.2634263 ,\n",
       "        0.24120727, 0.25021553, 0.26162472, 0.25682049, 0.24611182,\n",
       "        0.2569211 , 0.25201721, 0.26432695, 0.2517159 , 0.33338618,\n",
       "        0.32427855, 0.33078475, 0.32157636, 0.32738185, 0.32197709,\n",
       "        0.32387872, 0.32668099, 0.32427859, 1.30562301, 1.32694139,\n",
       "        1.24447031, 1.22044945, 1.26558843, 1.22405262, 1.24457035,\n",
       "        1.29581418, 1.21124153, 2.09440098, 2.06327472, 2.04185624,\n",
       "        2.10040631, 1.9867085 , 2.00202203, 2.00472388, 2.02043767,\n",
       "        2.06857896, 1.99741797, 1.96358805, 2.00642538, 2.00492406,\n",
       "        2.05356541, 2.21510496, 2.29827671, 2.28086138, 2.24403024,\n",
       "        2.21090164, 2.25954313, 2.26184454, 2.14544463, 2.06937947,\n",
       "        2.03094649, 2.00832691, 1.91544785, 1.45555234]),\n",
       " 'std_fit_time': array([0.01078747, 0.00497828, 0.00891634, 0.01593556, 0.01078264,\n",
       "        0.01142775, 0.0066191 , 0.01013483, 0.00987588, 0.01116755,\n",
       "        0.01537194, 0.01096621, 0.00761301, 0.00474355, 0.00288309,\n",
       "        0.00748021, 0.01131271, 0.00858995, 0.00423001, 0.01076286,\n",
       "        0.00709404, 0.01332527, 0.01350003, 0.01030735, 0.00650651,\n",
       "        0.01634625, 0.02692553, 0.00799436, 0.00888151, 0.00904657,\n",
       "        0.00892174, 0.00913239, 0.0029926 , 0.01691707, 0.06009201,\n",
       "        0.02504047, 0.00993341, 0.01181536, 0.00546908, 0.01526607,\n",
       "        0.01515263, 0.01146694, 0.01180268, 0.02202436, 0.04832564,\n",
       "        0.01674035, 0.00497822, 0.01916465, 0.00808172, 0.0065016 ,\n",
       "        0.01792876, 0.01977205, 0.0601006 , 0.04696086, 0.00357516,\n",
       "        0.00444915, 0.01833929, 0.0197956 , 0.03249765, 0.02172013,\n",
       "        0.0373586 , 0.05487672, 0.04725763, 0.01684802, 0.00350166,\n",
       "        0.01244714, 0.05144042, 0.00838921, 0.01953739, 0.05054988,\n",
       "        0.017658  , 0.04089504, 0.02696449, 0.02807315, 0.01742001,\n",
       "        0.02298135, 0.05160581, 0.01777644, 0.04576629, 0.02897751,\n",
       "        0.04701193, 0.01074052, 0.02540414, 0.01043278, 0.01573291,\n",
       "        0.01442644, 0.01672188, 0.01183429, 0.02044452, 0.03071193,\n",
       "        0.01581033, 0.02976099, 0.02393863, 0.01242601, 0.00837446,\n",
       "        0.0066164 , 0.01977308, 0.02246187, 0.0138705 , 0.02556795,\n",
       "        0.03540643, 0.01031699, 0.01058467, 0.0056799 , 0.00658269,\n",
       "        0.0070942 , 0.0285701 , 0.0166828 , 0.00477535, 0.00755892,\n",
       "        0.00620706, 0.00744051, 0.009087  , 0.01733945, 0.01075477,\n",
       "        0.02043414, 0.0159261 , 0.00518699, 0.00497808, 0.01407149,\n",
       "        0.0033942 , 0.00674405, 0.00502047, 0.00731081, 0.02407696,\n",
       "        0.02324722, 0.00563228, 0.00459069, 0.00401085, 0.00463461,\n",
       "        0.00597165, 0.00620679, 0.03940205, 0.01867677, 0.0193995 ,\n",
       "        0.00852446, 0.00518714, 0.00559615, 0.00656777, 0.00670199,\n",
       "        0.01023309, 0.04453603, 0.02970102, 0.02148333, 0.00577577,\n",
       "        0.00233449, 0.00697011, 0.00263646, 0.00861815, 0.01855085,\n",
       "        0.03912259, 0.04104193, 0.01180697, 0.00628548, 0.00829929,\n",
       "        0.00914896, 0.0052254 , 0.01072103, 0.05498221, 0.0468556 ,\n",
       "        0.04469356, 0.04822653, 0.02481134, 0.00547266, 0.00577549,\n",
       "        0.00784248, 0.00413435, 0.00431202, 0.00255958, 0.00459061,\n",
       "        0.01128628, 0.00242288, 0.0069296 , 0.00896637, 0.02024499,\n",
       "        0.0089605 , 0.00805064, 0.00766584, 0.00803811, 0.04516798,\n",
       "        0.00860623, 0.00729576, 0.00419894, 0.00967596, 0.00652769,\n",
       "        0.00705155, 0.00789619, 0.00402356, 0.03573924, 0.00649708,\n",
       "        0.00299226, 0.00759338, 0.0071855 , 0.00570219, 0.00418207,\n",
       "        0.00560267, 0.02075043, 0.02377177, 0.01782132, 0.01277597,\n",
       "        0.01218979, 0.00698816, 0.00493819, 0.01379595, 0.00778241,\n",
       "        0.04560551, 0.01067042, 0.01040396, 0.00743319, 0.00518113,\n",
       "        0.00415808, 0.00369097, 0.00861311, 0.00850698, 0.04656911,\n",
       "        0.03853929, 0.00547263, 0.00584798, 0.00742642, 0.00903545,\n",
       "        0.00807782, 0.00252038, 0.00477538, 0.00593268, 0.028159  ,\n",
       "        0.00600857, 0.00838339, 0.01321139, 0.00614202, 0.00552379,\n",
       "        0.01037064, 0.04231497, 0.01126402, 0.02117144, 0.00466667,\n",
       "        0.00491765, 0.01501613, 0.00170443, 0.00408259, 0.01310728,\n",
       "        0.06477122, 0.17880219, 0.02360089, 0.03307919, 0.00622164,\n",
       "        0.02099735, 0.02081124, 0.0247694 , 0.03032115, 0.0115703 ,\n",
       "        0.01827684, 0.01284338, 0.01197009, 0.008763  , 0.00980328,\n",
       "        0.01072165, 0.01230939, 0.01390279, 0.01615687, 0.01077798,\n",
       "        0.01403178, 0.01088443, 0.00295886, 0.02164515, 0.00909924,\n",
       "        0.04784313, 0.05375634, 0.02224189, 0.00612418, 0.01582028,\n",
       "        0.00493365, 0.00606354, 0.01750043, 0.01999996, 0.01145339,\n",
       "        0.0089717 , 0.00994038, 0.00773573, 0.00678092, 0.00636482,\n",
       "        0.00834398, 0.00823549, 0.00836546, 0.01140915, 0.01411777,\n",
       "        0.01017417, 0.00449157, 0.00234661, 0.07791979, 0.06709132,\n",
       "        0.06311456, 0.0646895 , 0.14423148, 0.0456551 , 0.08085609,\n",
       "        0.08790422, 0.08913082, 0.06127579, 0.09169381, 0.05037879,\n",
       "        0.08518018, 0.04732065, 0.0309662 , 0.03904752, 0.07713786,\n",
       "        0.02922337, 0.06105097, 0.04185864, 0.04779881, 0.06044607,\n",
       "        0.09894272, 0.12339156, 0.16324425, 0.0512686 , 0.08991601,\n",
       "        0.12415964, 0.17485723, 0.16369778, 0.16440975, 0.07702091,\n",
       "        0.0981436 , 0.07351001, 0.11293428, 0.1036732 ]),\n",
       " 'mean_score_time': array([0.03885646, 0.03693213, 0.03713222, 0.03793263, 0.03803287,\n",
       "        0.03841362, 0.0403348 , 0.04023428, 0.03863325, 0.04083529,\n",
       "        0.03940053, 0.03913364, 0.0385334 , 0.03923383, 0.04063501,\n",
       "        0.04043446, 0.03933372, 0.05774984, 0.03913393, 0.03853312,\n",
       "        0.03993425, 0.03943396, 0.04183578, 0.03953395, 0.04183621,\n",
       "        0.04603963, 0.0714612 , 0.04003496, 0.04003453, 0.04043503,\n",
       "        0.04043489, 0.0387331 , 0.03993454, 0.05054345, 0.0674582 ,\n",
       "        0.07166157, 0.0425365 , 0.04533892, 0.03853292, 0.04243665,\n",
       "        0.04183593, 0.05815005, 0.06355481, 0.06915917, 0.07786684,\n",
       "        0.04103556, 0.03943448, 0.04023466, 0.04003453, 0.04033484,\n",
       "        0.07506452, 0.08687487, 0.08547363, 0.0793684 , 0.04073553,\n",
       "        0.04253654, 0.04193544, 0.04664025, 0.0607523 , 0.08317151,\n",
       "        0.10238848, 0.15893621, 0.08297143, 0.04093533, 0.03983436,\n",
       "        0.03953404, 0.0464395 , 0.06555643, 0.10208774, 0.17384987,\n",
       "        0.16193933, 0.08627419, 0.0412353 , 0.0407352 , 0.04053507,\n",
       "        0.04263625, 0.07436399, 0.16934566, 0.16924572, 0.16904511,\n",
       "        0.08737535, 0.04093509, 0.03943429, 0.04113579, 0.03623123,\n",
       "        0.03753233, 0.03933411, 0.03603396, 0.03533039, 0.05965166,\n",
       "        0.03553042, 0.03603086, 0.03873305, 0.03803277, 0.03683167,\n",
       "        0.03673158, 0.03563042, 0.03673158, 0.05975127, 0.03743229,\n",
       "        0.0357306 , 0.03633099, 0.03713217, 0.0378325 , 0.03563061,\n",
       "        0.0403347 , 0.03563051, 0.0590508 , 0.03533001, 0.03613114,\n",
       "        0.03653135, 0.03633132, 0.03543043, 0.03753228, 0.03633127,\n",
       "        0.03683171, 0.05614853, 0.03603086, 0.03653193, 0.03733244,\n",
       "        0.03573089, 0.03583088, 0.03675103, 0.0424365 , 0.04053502,\n",
       "        0.05294566, 0.03533006, 0.03753209, 0.03623118, 0.03763251,\n",
       "        0.03653145, 0.03843312, 0.04283676, 0.03520627, 0.054247  ,\n",
       "        0.03623142, 0.03723192, 0.03633118, 0.03633103, 0.03653126,\n",
       "        0.03683162, 0.04533901, 0.03523035, 0.05304551, 0.03623114,\n",
       "        0.03723173, 0.03583055, 0.03803287, 0.03693166, 0.04874229,\n",
       "        0.04964275, 0.03432951, 0.05304608, 0.03993506, 0.03623109,\n",
       "        0.03603115, 0.0378324 , 0.04984312, 0.0768661 , 0.04864221,\n",
       "        0.03663087, 0.05604825, 0.02582235, 0.02522211, 0.02562208,\n",
       "        0.02522154, 0.02552166, 0.02552204, 0.02542148, 0.02502136,\n",
       "        0.03442988, 0.02812467, 0.0259223 , 0.02592216, 0.02492132,\n",
       "        0.0270227 , 0.02542205, 0.02572227, 0.02882442, 0.03673167,\n",
       "        0.0255219 , 0.02492123, 0.02602267, 0.02602234, 0.02572222,\n",
       "        0.02522168, 0.02562218, 0.0276237 , 0.041536  , 0.02562222,\n",
       "        0.02572212, 0.02662272, 0.02572212, 0.02612262, 0.02622237,\n",
       "        0.02562132, 0.03442969, 0.05164428, 0.02542191, 0.02612267,\n",
       "        0.02572198, 0.02622209, 0.02642288, 0.02642288, 0.02592201,\n",
       "        0.03753242, 0.07126098, 0.02682309, 0.02602229, 0.02572217,\n",
       "        0.02532187, 0.02602253, 0.02842445, 0.02722321, 0.04053488,\n",
       "        0.0674582 , 0.02532191, 0.02522168, 0.02522178, 0.02542195,\n",
       "        0.02632227, 0.02482123, 0.03432946, 0.05885072, 0.05494676,\n",
       "        0.02512121, 0.02592268, 0.02542205, 0.02592254, 0.02572227,\n",
       "        0.02582216, 0.03693142, 0.07156157, 0.05214472, 0.0255218 ,\n",
       "        0.02552199, 0.02542219, 0.02502165, 0.02532229, 0.02752371,\n",
       "        0.04283648, 0.08046913, 0.06715827, 0.02352061, 0.02241907,\n",
       "        0.02332034, 0.02662277, 0.02251959, 0.02241926, 0.02572241,\n",
       "        0.02311988, 0.02141762, 0.02121806, 0.02201862, 0.02221928,\n",
       "        0.022019  , 0.02512188, 0.02281971, 0.02402096, 0.0221199 ,\n",
       "        0.02332001, 0.02962527, 0.02362056, 0.02802429, 0.02412086,\n",
       "        0.03102674, 0.02552195, 0.02161903, 0.02201886, 0.02111869,\n",
       "        0.02422047, 0.02221889, 0.02291999, 0.02221909, 0.02251916,\n",
       "        0.02301993, 0.02602215, 0.02141871, 0.02271981, 0.02692318,\n",
       "        0.02682304, 0.0281239 , 0.02672305, 0.02712312, 0.02732348,\n",
       "        0.0289248 , 0.02792449, 0.02732387, 0.04483838, 0.0451385 ,\n",
       "        0.04804177, 0.04633989, 0.04343801, 0.05574799, 0.05644875,\n",
       "        0.04273705, 0.04063482, 0.03743248, 0.04914231, 0.03773241,\n",
       "        0.03753209, 0.04133563, 0.04493842, 0.03853312, 0.04283681,\n",
       "        0.04253664, 0.04043508, 0.03713207, 0.04914222, 0.0399343 ,\n",
       "        0.05024323, 0.04674034, 0.04363756, 0.04944282, 0.0565486 ,\n",
       "        0.04543891, 0.05614824, 0.04033504, 0.04303699, 0.03803263,\n",
       "        0.04023466, 0.03983531, 0.02622204, 0.02221847]),\n",
       " 'std_score_time': array([0.00136629, 0.00037427, 0.00111462, 0.00086068, 0.0008376 ,\n",
       "        0.00099903, 0.00196642, 0.00340292, 0.00131995, 0.002381  ,\n",
       "        0.00150795, 0.00272996, 0.00207525, 0.00120951, 0.00203638,\n",
       "        0.00086116, 0.0008725 , 0.00294533, 0.00080056, 0.00089527,\n",
       "        0.00124205, 0.00226919, 0.00412199, 0.00054825, 0.00188818,\n",
       "        0.00232585, 0.00324959, 0.00130493, 0.00100081, 0.00185653,\n",
       "        0.00203625, 0.00051042, 0.00182923, 0.00122575, 0.00422762,\n",
       "        0.00393273, 0.00219277, 0.00908349, 0.00083711, 0.00309113,\n",
       "        0.002806  , 0.00182912, 0.00219295, 0.00337033, 0.00814098,\n",
       "        0.00164459, 0.00139448, 0.00169275, 0.00137941, 0.00163245,\n",
       "        0.00137929, 0.00439252, 0.00257892, 0.00337327, 0.00128919,\n",
       "        0.00251189, 0.00280249, 0.00091723, 0.00216027, 0.00245982,\n",
       "        0.00825128, 0.00514923, 0.00300946, 0.00106921, 0.00191499,\n",
       "        0.00170482, 0.0086353 , 0.00212295, 0.00230429, 0.0077178 ,\n",
       "        0.00688041, 0.00924181, 0.00227355, 0.0022734 , 0.0007077 ,\n",
       "        0.00124168, 0.00291117, 0.00213764, 0.00248024, 0.01081875,\n",
       "        0.0077563 , 0.00965908, 0.00656613, 0.00698702, 0.00166244,\n",
       "        0.00179039, 0.0096132 , 0.00114122, 0.00081312, 0.00243938,\n",
       "        0.00167482, 0.00176223, 0.00396063, 0.00161386, 0.00166294,\n",
       "        0.00180698, 0.00132004, 0.00140134, 0.00291112, 0.00287327,\n",
       "        0.00160164, 0.00120964, 0.00168658, 0.00143607, 0.00080071,\n",
       "        0.00845459, 0.00139421, 0.00197667, 0.00074889, 0.00106871,\n",
       "        0.00104964, 0.00196627, 0.00111459, 0.0030193 , 0.00175103,\n",
       "        0.00169262, 0.0055762 , 0.0008374 , 0.0012258 , 0.00103006,\n",
       "        0.00067907, 0.00081298, 0.00139079, 0.00156307, 0.00927084,\n",
       "        0.0005834 , 0.00112315, 0.00170461, 0.00124985, 0.00115857,\n",
       "        0.0015181 , 0.00097044, 0.00128932, 0.00094777, 0.00194056,\n",
       "        0.00242268, 0.00128953, 0.00098074, 0.00132768, 0.00189899,\n",
       "        0.00180754, 0.00120948, 0.00112339, 0.00255163, 0.00147121,\n",
       "        0.00092851, 0.00153762, 0.00170436, 0.00185629, 0.0026596 ,\n",
       "        0.00124214, 0.00067883, 0.00209928, 0.00198677, 0.000679  ,\n",
       "        0.00114114, 0.00067867, 0.00545066, 0.00271522, 0.00198617,\n",
       "        0.00198605, 0.00469439, 0.00169261, 0.00098085, 0.00139415,\n",
       "        0.00074923, 0.00044723, 0.00089524, 0.0011146 , 0.00031651,\n",
       "        0.00196131, 0.00476206, 0.0023343 , 0.00086105, 0.000664  ,\n",
       "        0.00083791, 0.00058367, 0.00051031, 0.00408522, 0.00081325,\n",
       "        0.00054834, 0.00058361, 0.00155074, 0.00114124, 0.00147072,\n",
       "        0.00067877, 0.00058367, 0.00149812, 0.00192518, 0.00115845,\n",
       "        0.0012894 , 0.001498  , 0.0006005 , 0.00073535, 0.0010304 ,\n",
       "        0.00091691, 0.00313952, 0.00124185, 0.00073549, 0.00159528,\n",
       "        0.00060067, 0.00112318, 0.00162597, 0.00213244, 0.00097023,\n",
       "        0.00114105, 0.0015697 , 0.00262162, 0.00184561, 0.00098071,\n",
       "        0.0004005 , 0.00094952, 0.0041435 , 0.0008136 , 0.00189921,\n",
       "        0.0027302 , 0.00074924, 0.00051056, 0.00103067, 0.00066395,\n",
       "        0.00136499, 0.00024515, 0.00273387, 0.00819015, 0.00171618,\n",
       "        0.00019991, 0.0015309 , 0.00058396, 0.00066387, 0.00040031,\n",
       "        0.00092829, 0.00096983, 0.00141548, 0.00229077, 0.0015179 ,\n",
       "        0.0007077 , 0.00020044, 0.00031643, 0.00103056, 0.00109632,\n",
       "        0.00262144, 0.00735057, 0.00761866, 0.00259058, 0.00338541,\n",
       "        0.00273334, 0.00975741, 0.00192517, 0.00124191, 0.00169257,\n",
       "        0.00159508, 0.00111462, 0.00051027, 0.00089527, 0.00060039,\n",
       "        0.00100093, 0.00153147, 0.00218347, 0.00212363, 0.0014981 ,\n",
       "        0.00172198, 0.00805954, 0.00404555, 0.01252897, 0.00159517,\n",
       "        0.01365368, 0.00126591, 0.00111473, 0.00094954, 0.00058412,\n",
       "        0.00276991, 0.00143671, 0.00135742, 0.00128951, 0.00155   ,\n",
       "        0.00205117, 0.00184551, 0.00102104, 0.00081337, 0.00159506,\n",
       "        0.00092821, 0.00115761, 0.00112368, 0.00097037, 0.00107788,\n",
       "        0.00312351, 0.00217899, 0.00180718, 0.00388407, 0.00360026,\n",
       "        0.00583587, 0.00495015, 0.0053838 , 0.01546205, 0.01022868,\n",
       "        0.00418156, 0.00257902, 0.0028559 , 0.0093433 , 0.00124941,\n",
       "        0.00426968, 0.0072353 , 0.00419151, 0.00319643, 0.00683689,\n",
       "        0.00192517, 0.00630944, 0.00115845, 0.0096748 , 0.00297547,\n",
       "        0.00859008, 0.00426551, 0.01106544, 0.00326456, 0.01301955,\n",
       "        0.00794712, 0.01178921, 0.00304577, 0.0115468 , 0.00137941,\n",
       "        0.00314296, 0.00472124, 0.0031111 , 0.00169273]),\n",
       " 'param_classifier': masked_array(data=[SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__gamma': masked_array(data=[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'}],\n",
       " 'split0_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.927,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.773, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.781, 0.757, 0.874,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.67 , 0.839, 0.757, 0.874,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.884,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.884, 0.878,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.864, 0.878,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.928, 0.863, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.837, 0.862, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.568, 0.862, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.79 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.579,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.609,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.69 , 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.733, 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624,\n",
       "        0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624,\n",
       "        0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624]),\n",
       " 'split1_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.927,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.884,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.761, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.817, 0.691, 0.875,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.641, 0.711, 0.691, 0.875,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.927,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.893,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.893, 0.884,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.875, 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.928, 0.871, 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.85 , 0.87 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.602, 0.87 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.785,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.736,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.672,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.843, 0.665,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.695, 0.665,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ]),\n",
       " 'split2_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.931,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.897,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.804, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.826, 0.812, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.765, 0.8  , 0.812, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.928,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.895, 0.878,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.869, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.865, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.824, 0.865, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.615, 0.865, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.785,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.695,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.666, 0.555,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.625, 0.555,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618,\n",
       "        0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618,\n",
       "        0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618]),\n",
       " 'split3_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.932,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.902,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.772, 0.905,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.665, 0.844, 0.892,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.709, 0.645, 0.844, 0.892,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.895,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.888, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.86 , 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.859, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.802, 0.86 , 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.603, 0.859, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.619,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.617,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.492,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.733, 0.679,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.607, 0.679,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712,\n",
       "        0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712,\n",
       "        0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712]),\n",
       " 'split4_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.893,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.826, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.721, 0.76 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.677, 0.682, 0.66 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.866,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.892, 0.855,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.873, 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.871, 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.802, 0.87 , 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.624, 0.87 , 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.73 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.546,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.641, 0.466,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.713, 0.466,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689,\n",
       "        0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689,\n",
       "        0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689]),\n",
       " 'mean_test_recall_micro': array([0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.9292, 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.8924, 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.7872, 0.8856, 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.762 , 0.7728, 0.882 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.6924, 0.7354, 0.7528,\n",
       "        0.882 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.9284, 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.8838, 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.8904, 0.8752, 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.8682, 0.8746, 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.9286, 0.8658, 0.875 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.823 , 0.8654,\n",
       "        0.875 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.6024,\n",
       "        0.8652, 0.875 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.7418, 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.6528,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.5912, 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.7146, 0.6004, 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.6746, 0.6004, 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786,\n",
       "        0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786,\n",
       "        0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786,\n",
       "        0.6786, 0.6786, 0.6786, 0.6786]),\n",
       " 'std_test_recall_micro': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00203961,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00671118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02411141, 0.01013114, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06094588,\n",
       "        0.05236564, 0.00678233, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04225447, 0.07283571, 0.0696718 ,\n",
       "        0.00678233, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0008    , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01034215, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392938,\n",
       "        0.01034215, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00556417, 0.01051856,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0004899 , 0.00466476, 0.01067708, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01901578, 0.00407922, 0.01067708, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01902209,\n",
       "        0.00435431, 0.01067708, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06523005, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05600143, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0645396 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07100592, 0.07976867, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04966125, 0.07976867, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154]),\n",
       " 'rank_test_recall_micro': array([  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   1,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2, 268,   2,   2,   2,   2,   2,   2,   2, 284, 270,   2,   2,\n",
       "          2,   2,   2,   2, 286, 285, 272,   2,   2,   2,   2,   2, 291,\n",
       "        289, 287, 272,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2, 267,   2,   2,   2,   2,   2,   2,   2,   2, 271,\n",
       "          2,   2,   2,   2,   2,   2,   2, 269, 274,   2,   2,   2,   2,\n",
       "          2,   2,   2, 279, 278,   2,   2,   2,   2,   2,   2, 266, 280,\n",
       "        275,   2,   2,   2,   2,   2,   2, 283, 281, 275,   2,   2,   2,\n",
       "          2,   2,   2, 321, 282, 275,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2, 288,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2, 320,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2, 324,   2,   2,   2,   2,   2,   2,   2, 290, 322,\n",
       "          2,   2,   2,   2,   2,   2,   2, 319, 322,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2, 292, 292,\n",
       "        292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292,\n",
       "        292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292]),\n",
       " 'split0_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.927,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.773, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.781, 0.757, 0.874,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.67 , 0.839, 0.757, 0.874,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.884,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.884, 0.878,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.864, 0.878,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.928, 0.863, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.837, 0.862, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.568, 0.862, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.79 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.579,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.609,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.69 , 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.733, 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624,\n",
       "        0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624,\n",
       "        0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624]),\n",
       " 'split1_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.927,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.884,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.761, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.817, 0.691, 0.875,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.641, 0.711, 0.691, 0.875,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.927,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.893,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.893, 0.884,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.875, 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.928, 0.871, 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.85 , 0.87 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.602, 0.87 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.785,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.736,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.672,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.843, 0.665,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.695, 0.665,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ]),\n",
       " 'split2_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.931,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.897,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.804, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.826, 0.812, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.765, 0.8  , 0.812, 0.886,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.928,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.895, 0.878,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.869, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.865, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.824, 0.865, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.615, 0.865, 0.877,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.785,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.695,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.666, 0.555,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.625, 0.555,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618,\n",
       "        0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618,\n",
       "        0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618]),\n",
       " 'split3_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.932,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.902,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.772, 0.905,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.665, 0.844, 0.892,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.709, 0.645, 0.844, 0.892,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.895,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.888, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.86 , 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.859, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.802, 0.86 , 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.603, 0.859, 0.881,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.619,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.617,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.492,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.733, 0.679,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.607, 0.679,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712,\n",
       "        0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712,\n",
       "        0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712]),\n",
       " 'split4_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.893,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.826, 0.88 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.721, 0.76 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.677, 0.682, 0.66 , 0.883,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.866,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.892, 0.855,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.873, 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.871, 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.802, 0.87 , 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.624, 0.87 , 0.854,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.73 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.637,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.546,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.641, 0.466,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.713, 0.466,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689,\n",
       "        0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689,\n",
       "        0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689]),\n",
       " 'mean_test_f1_micro': array([0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.9292, 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.8924, 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.7872, 0.8856, 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.762 , 0.7728, 0.882 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.6924, 0.7354, 0.7528,\n",
       "        0.882 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.9284, 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.8838, 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.8904, 0.8752, 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.8682, 0.8746, 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.9286, 0.8658, 0.875 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.823 , 0.8654,\n",
       "        0.875 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.6024,\n",
       "        0.8652, 0.875 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.7418, 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.6528,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.5912, 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.7146, 0.6004, 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.6746, 0.6004, 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 , 0.929 ,\n",
       "        0.929 , 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786,\n",
       "        0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786,\n",
       "        0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786, 0.6786,\n",
       "        0.6786, 0.6786, 0.6786, 0.6786]),\n",
       " 'std_test_f1_micro': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00203961,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00671118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02411141, 0.01013114, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06094588,\n",
       "        0.05236564, 0.00678233, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04225447, 0.07283571, 0.0696718 ,\n",
       "        0.00678233, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0008    , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01034215, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392938,\n",
       "        0.01034215, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00556417, 0.01051856,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0004899 , 0.00466476, 0.01067708, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01901578, 0.00407922, 0.01067708, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01902209,\n",
       "        0.00435431, 0.01067708, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06523005, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05600143, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0645396 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07100592, 0.07976867, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04966125, 0.07976867, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154, 0.05094154,\n",
       "        0.05094154, 0.05094154, 0.05094154, 0.05094154]),\n",
       " 'rank_test_f1_micro': array([  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   1,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2, 268,   2,   2,   2,   2,   2,   2,   2, 284, 270,   2,   2,\n",
       "          2,   2,   2,   2, 286, 285, 272,   2,   2,   2,   2,   2, 291,\n",
       "        289, 287, 272,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2, 267,   2,   2,   2,   2,   2,   2,   2,   2, 271,\n",
       "          2,   2,   2,   2,   2,   2,   2, 269, 274,   2,   2,   2,   2,\n",
       "          2,   2,   2, 279, 278,   2,   2,   2,   2,   2,   2, 266, 280,\n",
       "        275,   2,   2,   2,   2,   2,   2, 283, 281, 275,   2,   2,   2,\n",
       "          2,   2,   2, 321, 282, 275,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2, 288,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2, 320,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2, 324,   2,   2,   2,   2,   2,   2,   2, 290, 322,\n",
       "          2,   2,   2,   2,   2,   2,   2, 319, 322,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2, 292, 292,\n",
       "        292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292,\n",
       "        292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292]),\n",
       " 'split0_test_roc_auc_ovo': array([0.54811322, 0.53161055, 0.43977319, 0.5       , 0.49191164,\n",
       "        0.48481633, 0.55968101, 0.53696994, 0.5578617 , 0.4518792 ,\n",
       "        0.51212875, 0.53897118, 0.44506436, 0.49191164, 0.48481633,\n",
       "        0.55968101, 0.55563304, 0.61877833, 0.54806774, 0.5       ,\n",
       "        0.52262769, 0.50237269, 0.49191164, 0.48481633, 0.52435604,\n",
       "        0.53797056, 0.64735669, 0.54806774, 0.49841568, 0.59148865,\n",
       "        0.47684167, 0.49191164, 0.480829  , 0.53774314, 0.52552343,\n",
       "        0.64270228, 0.54814354, 0.49841568, 0.59148865, 0.47684167,\n",
       "        0.57229491, 0.56310738, 0.5633348 , 0.56507831, 0.63910914,\n",
       "        0.45187162, 0.49862794, 0.40851135, 0.49136585, 0.49236647,\n",
       "        0.5179278 , 0.54462621, 0.51551722, 0.64326324, 0.53369517,\n",
       "        0.55200958, 0.53214876, 0.4396519 , 0.48358829, 0.58328659,\n",
       "        0.52121773, 0.48387635, 0.63642566, 0.54867418, 0.51460756,\n",
       "        0.51607817, 0.52846465, 0.51072636, 0.59553662, 0.48126867,\n",
       "        0.54499007, 0.64343001, 0.45373641, 0.57447808, 0.53327067,\n",
       "        0.53227005, 0.5767219 , 0.55843782, 0.59355054, 0.54499007,\n",
       "        0.64151973, 0.5220819 , 0.50539729, 0.44985521, 0.5       ,\n",
       "        0.521809  , 0.54881062, 0.50599615, 0.55946876, 0.56092421,\n",
       "        0.48351249, 0.58615958, 0.5       , 0.5289877 , 0.48633242,\n",
       "        0.56002972, 0.50599615, 0.47637169, 0.43760518, 0.55771009,\n",
       "        0.57163541, 0.49846117, 0.48797738, 0.49823375, 0.56002972,\n",
       "        0.44852105, 0.47571977, 0.56013584, 0.5       , 0.40615382,\n",
       "        0.49858245, 0.49915857, 0.48646887, 0.48989524, 0.50737579,\n",
       "        0.47658394, 0.43972771, 0.4957701 , 0.46344699, 0.43904547,\n",
       "        0.53625737, 0.51022605, 0.5026001 , 0.50570809, 0.47935839,\n",
       "        0.43995512, 0.45321336, 0.51755636, 0.43899998, 0.5161843 ,\n",
       "        0.51178763, 0.46210525, 0.45197774, 0.47482527, 0.56424445,\n",
       "        0.45876226, 0.51749572, 0.40879941, 0.47239952, 0.53850119,\n",
       "        0.51387983, 0.55200958, 0.47335466, 0.56521475, 0.45882291,\n",
       "        0.45114389, 0.50047757, 0.50545036, 0.56056035, 0.54276141,\n",
       "        0.45601055, 0.47421883, 0.55745236, 0.49412514, 0.501554  ,\n",
       "        0.56518443, 0.50020467, 0.4581634 , 0.5045407 , 0.52908625,\n",
       "        0.47393078, 0.44115284, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.51310663, 0.43392107, 0.50598099, 0.50917995,\n",
       "        0.59533953, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.51644961, 0.50598099, 0.5136979 , 0.50999864, 0.56645795,\n",
       "        0.5       , 0.5       , 0.5       , 0.51987598, 0.43392107,\n",
       "        0.5       , 0.50676936, 0.57049076, 0.55974166, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5119923 , 0.43392107, 0.50598099,\n",
       "        0.49082005, 0.59580952, 0.59050319, 0.5       , 0.5       ,\n",
       "        0.49784715, 0.51644961, 0.49401901, 0.50598099, 0.50999864,\n",
       "        0.55811944, 0.59214057, 0.5       , 0.5       , 0.46008126,\n",
       "        0.43392107, 0.5       , 0.50308525, 0.571173  , 0.57776801,\n",
       "        0.59168574, 0.5       , 0.5       , 0.51330372, 0.43392107,\n",
       "        0.50598099, 0.5130005 , 0.57663094, 0.55558756, 0.58653103,\n",
       "        0.5       , 0.50053821, 0.48355797, 0.50598099, 0.51427402,\n",
       "        0.50999864, 0.57258297, 0.57946603, 0.60463318, 0.5       ,\n",
       "        0.46334086, 0.43392865, 0.5       , 0.50598099, 0.5697782 ,\n",
       "        0.56338028, 0.3635137 , 0.60495156, 0.54588456, 0.45402447,\n",
       "        0.45405479, 0.45405479, 0.54594521, 0.45405479, 0.45405479,\n",
       "        0.45405479, 0.54594521, 0.46697191, 0.47155051, 0.46885186,\n",
       "        0.52844949, 0.52844949, 0.52844949, 0.47159599, 0.52844949,\n",
       "        0.47155051, 0.43745357, 0.43745357, 0.43745357, 0.43745357,\n",
       "        0.43745357, 0.43745357, 0.43745357, 0.43745357, 0.56254643,\n",
       "        0.586152  , 0.41343865, 0.586152  , 0.586152  , 0.586152  ,\n",
       "        0.413848  , 0.413848  , 0.586152  , 0.413848  , 0.56386543,\n",
       "        0.43613457, 0.43613457, 0.56386543, 0.56386543, 0.43613457,\n",
       "        0.56386543, 0.43613457, 0.43655907, 0.53701542, 0.54082081,\n",
       "        0.46268136, 0.53889537, 0.53895602, 0.53895602, 0.53889537,\n",
       "        0.53878925, 0.53850119, 0.44973393, 0.55026607, 0.44789945,\n",
       "        0.55026607, 0.54791613, 0.44973393, 0.44973393, 0.55026607,\n",
       "        0.4492791 , 0.55026607, 0.55153959, 0.44973393, 0.44973393,\n",
       "        0.55026607, 0.55108476, 0.44973393, 0.55011447, 0.44973393,\n",
       "        0.44973393, 0.44973393, 0.44973393, 0.44973393, 0.55026607,\n",
       "        0.55081187, 0.55026607, 0.55026607, 0.55026607]),\n",
       " 'split1_test_roc_auc_ovo': array([0.53226247, 0.52322655, 0.48832608, 0.5       , 0.46125623,\n",
       "        0.45446414, 0.4824209 , 0.55423824, 0.57573644, 0.53728832,\n",
       "        0.48011644, 0.5       , 0.43931836, 0.4763262 , 0.45446414,\n",
       "        0.4824209 , 0.5197926 , 0.57309844, 0.46288604, 0.5       ,\n",
       "        0.4619688 , 0.54326172, 0.49172971, 0.45446414, 0.52741855,\n",
       "        0.49138101, 0.57535742, 0.53724283, 0.53048106, 0.51201504,\n",
       "        0.4327082 , 0.51119635, 0.47130793, 0.53931988, 0.55056929,\n",
       "        0.57426583, 0.53730348, 0.46145333, 0.5120302 , 0.4327082 ,\n",
       "        0.49708152, 0.46568323, 0.53111782, 0.58081535, 0.58536363,\n",
       "        0.53724283, 0.46604709, 0.51365242, 0.5230522 , 0.49382192,\n",
       "        0.53293713, 0.51585076, 0.52872239, 0.59881138, 0.52089935,\n",
       "        0.50444973, 0.55510241, 0.44094058, 0.44077381, 0.55989327,\n",
       "        0.50167528, 0.46357586, 0.58845647, 0.52264285, 0.53527191,\n",
       "        0.52426507, 0.51691202, 0.5120302 , 0.57267393, 0.51788232,\n",
       "        0.48343668, 0.58477236, 0.52196061, 0.49959824, 0.45232645,\n",
       "        0.51716976, 0.48631726, 0.52532634, 0.48514987, 0.48286056,\n",
       "        0.58562137, 0.44965812, 0.48313346, 0.46318167, 0.5       ,\n",
       "        0.5331797 , 0.49107779, 0.44366955, 0.54791613, 0.54359526,\n",
       "        0.52193787, 0.52562198, 0.5       , 0.43643779, 0.5331797 ,\n",
       "        0.47914614, 0.46286329, 0.51213633, 0.55000834, 0.45902758,\n",
       "        0.5       , 0.4581255 , 0.43643021, 0.48261799, 0.52300672,\n",
       "        0.57737382, 0.50686032, 0.45294804, 0.5       , 0.58856259,\n",
       "        0.45819373, 0.43639988, 0.50496521, 0.47767553, 0.44732334,\n",
       "        0.50905866, 0.55334374, 0.59716642, 0.50922543, 0.45485832,\n",
       "        0.4363923 , 0.59236799, 0.49726345, 0.54232175, 0.50645098,\n",
       "        0.45601055, 0.59718158, 0.51174214, 0.45487348, 0.49394321,\n",
       "        0.50669355, 0.46283297, 0.51451659, 0.50828545, 0.54383784,\n",
       "        0.5564669 , 0.51181037, 0.463212  , 0.51112054, 0.50314589,\n",
       "        0.55261602, 0.53042041, 0.50864931, 0.54148789, 0.55645932,\n",
       "        0.43403478, 0.5344987 , 0.50469231, 0.46757834, 0.56442639,\n",
       "        0.49059264, 0.50808836, 0.45634409, 0.48962234, 0.4678664 ,\n",
       "        0.48851559, 0.48283024, 0.53067815, 0.49771828, 0.50228172,\n",
       "        0.50776998, 0.54383784, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.46758592, 0.50209979, 0.50209979, 0.46531937,\n",
       "        0.54427751, 0.5       , 0.5       , 0.5       , 0.52982156,\n",
       "        0.54470959, 0.50209979, 0.54682454, 0.50264558, 0.5653512 ,\n",
       "        0.5       , 0.5       , 0.5       , 0.53928198, 0.50209221,\n",
       "        0.5       , 0.56454767, 0.56566958, 0.51002896, 0.5       ,\n",
       "        0.5       , 0.5       , 0.53254294, 0.50209979, 0.50209979,\n",
       "        0.49348838, 0.54345882, 0.51745781, 0.5       , 0.5       ,\n",
       "        0.50103094, 0.54470959, 0.50209979, 0.50209979, 0.49735442,\n",
       "        0.57049076, 0.47582589, 0.5       , 0.5       , 0.44334359,\n",
       "        0.50209221, 0.5       , 0.48334571, 0.43461848, 0.53251262,\n",
       "        0.46143817, 0.5       , 0.5       , 0.53241408, 0.50209979,\n",
       "        0.50209979, 0.50216043, 0.55379857, 0.53014752, 0.50047757,\n",
       "        0.5       , 0.50053821, 0.54481572, 0.50209979, 0.458785  ,\n",
       "        0.49717249, 0.55069058, 0.54409557, 0.52475022, 0.5       ,\n",
       "        0.55764945, 0.50209221, 0.5       , 0.50209979, 0.56538152,\n",
       "        0.52699404, 0.45884565, 0.52475022, 0.49689959, 0.50310041,\n",
       "        0.50310041, 0.49689959, 0.50272139, 0.49689959, 0.50310041,\n",
       "        0.50310041, 0.49689959, 0.52174836, 0.52503828, 0.47496172,\n",
       "        0.47406722, 0.52503828, 0.47496172, 0.52503828, 0.47496172,\n",
       "        0.52503828, 0.47030731, 0.53411968, 0.53411968, 0.53466547,\n",
       "        0.46588032, 0.53411968, 0.53411968, 0.46588032, 0.53411968,\n",
       "        0.4976728 , 0.5023272 , 0.50284267, 0.5023272 , 0.5023272 ,\n",
       "        0.4976728 , 0.49974984, 0.4976728 , 0.5023272 , 0.53249746,\n",
       "        0.46750254, 0.46750254, 0.53249746, 0.53249746, 0.46750254,\n",
       "        0.53249746, 0.53249746, 0.53249746, 0.54823451, 0.545172  ,\n",
       "        0.45450962, 0.54680938, 0.54741582, 0.54859837, 0.45334223,\n",
       "        0.45026456, 0.45314514, 0.46951894, 0.46951894, 0.53048106,\n",
       "        0.53048106, 0.53048106, 0.53048106, 0.53048106, 0.46951894,\n",
       "        0.53048106, 0.5304659 , 0.46951894, 0.46951894, 0.46951894,\n",
       "        0.46951894, 0.53048106, 0.46951894, 0.46951894, 0.46951894,\n",
       "        0.46951894, 0.46951894, 0.46951894, 0.46951894, 0.46951894,\n",
       "        0.53048106, 0.46951894, 0.46951894, 0.46951894]),\n",
       " 'split2_test_roc_auc_ovo': array([0.47608363, 0.49629315, 0.51804909, 0.5       , 0.49438287,\n",
       "        0.47843357, 0.50202398, 0.52890432, 0.52023227, 0.51417547,\n",
       "        0.43473976, 0.5       , 0.44780849, 0.51149957, 0.52156643,\n",
       "        0.49797602, 0.52632696, 0.62375112, 0.5       , 0.5       ,\n",
       "        0.53651511, 0.48584727, 0.53904698, 0.47843357, 0.52440152,\n",
       "        0.55381373, 0.60724086, 0.48589275, 0.48988008, 0.51169666,\n",
       "        0.53210328, 0.49797602, 0.50596583, 0.54153338, 0.50749708,\n",
       "        0.60984854, 0.48583211, 0.51033218, 0.51169666, 0.53210328,\n",
       "        0.49374612, 0.50804288, 0.47168696, 0.5419882 , 0.61210752,\n",
       "        0.48578663, 0.51005928, 0.51172698, 0.52435604, 0.4869995 ,\n",
       "        0.53051138, 0.57940539, 0.56477509, 0.64624994, 0.51942874,\n",
       "        0.4948377 , 0.4954593 , 0.45742052, 0.54908352, 0.54950803,\n",
       "        0.55346503, 0.53105717, 0.67178095, 0.5091193 , 0.48461923,\n",
       "        0.51099926, 0.48114738, 0.49445868, 0.46569839, 0.47502236,\n",
       "        0.55022059, 0.67137161, 0.51102958, 0.48334571, 0.48460407,\n",
       "        0.54627875, 0.5159114 , 0.43809033, 0.51387983, 0.55138798,\n",
       "        0.67123516, 0.51780652, 0.49165391, 0.50995315, 0.44827848,\n",
       "        0.48853833, 0.54781   , 0.46534969, 0.40209827, 0.48125351,\n",
       "        0.43883321, 0.48605194, 0.45017359, 0.5513046 , 0.48854591,\n",
       "        0.52183932, 0.43581619, 0.61171334, 0.51817038, 0.52967753,\n",
       "        0.5       , 0.54981883, 0.46188541, 0.48011644, 0.52183932,\n",
       "        0.52556891, 0.60340515, 0.51835231, 0.46053609, 0.50810352,\n",
       "        0.5178899 , 0.5088085 , 0.51988356, 0.46087721, 0.47973741,\n",
       "        0.60728634, 0.48098061, 0.46053609, 0.51408451, 0.48201155,\n",
       "        0.49118392, 0.50111433, 0.53040525, 0.62789005, 0.60661926,\n",
       "        0.48283024, 0.47489349, 0.4973999 , 0.51795055, 0.51250019,\n",
       "        0.52816143, 0.45140163, 0.57124881, 0.61189527, 0.51814006,\n",
       "        0.47040586, 0.49727861, 0.50684516, 0.53281584, 0.47653846,\n",
       "        0.44642884, 0.57264361, 0.61074304, 0.51809457, 0.47032247,\n",
       "        0.46810898, 0.49727861, 0.52042936, 0.48190543, 0.52834336,\n",
       "        0.60472415, 0.61043982, 0.51868585, 0.47435528, 0.46703255,\n",
       "        0.5136221 , 0.5509938 , 0.50504101, 0.54730969, 0.54235207,\n",
       "        0.61051562, 0.51874649, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5155627 , 0.47543929, 0.4913052 , 0.5369851 , 0.44812687,\n",
       "        0.54098758, 0.5       , 0.5       , 0.5       , 0.49457239,\n",
       "        0.50189512, 0.4913052 , 0.45761761, 0.46401552, 0.51034734,\n",
       "        0.5       , 0.5       , 0.5       , 0.5266984 , 0.49129762,\n",
       "        0.5       , 0.4913052 , 0.50952865, 0.54133628, 0.5       ,\n",
       "        0.5       , 0.5       , 0.47634894, 0.4913052 , 0.49016813,\n",
       "        0.48225413, 0.54157886, 0.54881062, 0.5       , 0.5       ,\n",
       "        0.42184539, 0.47631862, 0.4913052 , 0.49124456, 0.53598448,\n",
       "        0.53522643, 0.48146576, 0.5       , 0.5       , 0.47016328,\n",
       "        0.49129762, 0.5       , 0.47944935, 0.50940736, 0.54109371,\n",
       "        0.53261875, 0.5       , 0.5       , 0.47452963, 0.4913052 ,\n",
       "        0.51083249, 0.49089586, 0.54133628, 0.49855213, 0.5340742 ,\n",
       "        0.5       , 0.5       , 0.47634136, 0.4913052 , 0.48834882,\n",
       "        0.53598448, 0.51513819, 0.49498931, 0.52487151, 0.5       ,\n",
       "        0.45267515, 0.49129762, 0.5       , 0.44001577, 0.50952865,\n",
       "        0.53430161, 0.51538077, 0.47517397, 0.46512227, 0.53487773,\n",
       "        0.53487773, 0.53487773, 0.46512227, 0.53501418, 0.53487773,\n",
       "        0.53487773, 0.53458967, 0.53004139, 0.53004139, 0.53004139,\n",
       "        0.46995861, 0.46995861, 0.46995861, 0.53004139, 0.46995861,\n",
       "        0.46995861, 0.47514365, 0.52485635, 0.47514365, 0.47514365,\n",
       "        0.52485635, 0.52449249, 0.52485635, 0.47514365, 0.52485635,\n",
       "        0.55505693, 0.44494307, 0.55505693, 0.55540563, 0.55505693,\n",
       "        0.55505693, 0.55505693, 0.44494307, 0.55505693, 0.48064707,\n",
       "        0.48061675, 0.51938325, 0.48061675, 0.51938325, 0.48061675,\n",
       "        0.48061675, 0.48061675, 0.51938325, 0.47030731, 0.46968571,\n",
       "        0.52969269, 0.46959475, 0.52969269, 0.52969269, 0.47030731,\n",
       "        0.47030731, 0.52969269, 0.4977486 , 0.5022514 , 0.5022514 ,\n",
       "        0.4977486 , 0.5022514 , 0.4977486 , 0.5022514 , 0.5022514 ,\n",
       "        0.49597477, 0.50153883, 0.5022514 , 0.50076563, 0.50214527,\n",
       "        0.5022514 , 0.4977486 , 0.4977486 , 0.5022514 , 0.4977486 ,\n",
       "        0.4977486 , 0.4977486 , 0.5022514 , 0.5022514 , 0.5022514 ,\n",
       "        0.5022514 , 0.5022514 , 0.4977486 , 0.50243333]),\n",
       " 'split3_test_roc_auc_ovo': array([0.45303901, 0.51760184, 0.51366758, 0.51694234, 0.58716779,\n",
       "        0.48154156, 0.46360618, 0.55698237, 0.58957837, 0.54695341,\n",
       "        0.51325066, 0.57336376, 0.47285435, 0.52299156, 0.48154156,\n",
       "        0.46360618, 0.54006277, 0.71847663, 0.54699889, 0.5       ,\n",
       "        0.49800634, 0.4386058 , 0.50952865, 0.48154156, 0.47485559,\n",
       "        0.51562334, 0.73477463, 0.45297837, 0.5435043 , 0.48445246,\n",
       "        0.49488319, 0.54045695, 0.46518292, 0.58583362, 0.67476766,\n",
       "        0.73015055, 0.54688519, 0.54335269, 0.4844373 , 0.50707258,\n",
       "        0.49213906, 0.49438287, 0.58422656, 0.62769296, 0.73107536,\n",
       "        0.4529632 , 0.45672312, 0.51554754, 0.4798587 , 0.50194818,\n",
       "        0.57205234, 0.56046938, 0.63169545, 0.73760973, 0.45572249,\n",
       "        0.58330175, 0.42935763, 0.51497142, 0.48073803, 0.56460832,\n",
       "        0.5819221 , 0.58092148, 0.7286951 , 0.42597674, 0.51961067,\n",
       "        0.57550903, 0.56780727, 0.4499765 , 0.5577859 , 0.46601677,\n",
       "        0.58800164, 0.72487454, 0.56906563, 0.50960445, 0.41706211,\n",
       "        0.48751497, 0.48198123, 0.48980427, 0.51921648, 0.58800164,\n",
       "        0.72428327, 0.54417896, 0.46323474, 0.53543868, 0.5       ,\n",
       "        0.45802696, 0.46096818, 0.59382344, 0.43419397, 0.55846814,\n",
       "        0.54761291, 0.42670447, 0.51282615, 0.56258433, 0.54197304,\n",
       "        0.55416243, 0.59382344, 0.54812838, 0.44313892, 0.51258357,\n",
       "        0.5       , 0.48724966, 0.56258433, 0.57017238, 0.55416243,\n",
       "        0.45034036, 0.55149411, 0.44332085, 0.5       , 0.46454616,\n",
       "        0.52775967, 0.47723586, 0.42982762, 0.44453373, 0.49582316,\n",
       "        0.54309495, 0.55287375, 0.45395625, 0.46454616, 0.53443048,\n",
       "        0.52276414, 0.47584105, 0.46615322, 0.57273458, 0.54212465,\n",
       "        0.44559499, 0.52719871, 0.55905184, 0.46556952, 0.50279719,\n",
       "        0.53508998, 0.45928531, 0.56124259, 0.54837096, 0.4450492 ,\n",
       "        0.5509559 , 0.44087994, 0.50062918, 0.46827575, 0.49562607,\n",
       "        0.57156719, 0.55678528, 0.54714292, 0.55485984, 0.48786367,\n",
       "        0.52381025, 0.44999166, 0.51289437, 0.55570885, 0.56106066,\n",
       "        0.51123425, 0.55257054, 0.55091799, 0.52616019, 0.49639928,\n",
       "        0.46022529, 0.44805106, 0.50895253, 0.58543944, 0.55677011,\n",
       "        0.55269182, 0.44514016, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.48813657, 0.52067193, 0.52067193, 0.52067193,\n",
       "        0.61744417, 0.5       , 0.5       , 0.5       , 0.53960036,\n",
       "        0.51390258, 0.52067193, 0.52067193, 0.44239603, 0.6617141 ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5695432 , 0.59801543,\n",
       "        0.52067193, 0.52067193, 0.5946118 , 0.65881836, 0.5       ,\n",
       "        0.5       , 0.5       , 0.48642338, 0.52067193, 0.52067193,\n",
       "        0.52067193, 0.62428175, 0.4009612 , 0.5       , 0.5       ,\n",
       "        0.50053821, 0.48616565, 0.52067193, 0.52067193, 0.55760397,\n",
       "        0.62114344, 0.54632423, 0.5       , 0.5       , 0.56355463,\n",
       "        0.59801543, 0.52067193, 0.50701193, 0.5946118 , 0.65123789,\n",
       "        0.45890629, 0.5       , 0.5       , 0.48752255, 0.52067193,\n",
       "        0.52067193, 0.49191164, 0.61742901, 0.59756819, 0.54009309,\n",
       "        0.5       , 0.50739854, 0.51403902, 0.52067193, 0.52067193,\n",
       "        0.45311481, 0.60912082, 0.54213981, 0.50354008, 0.5       ,\n",
       "        0.5695432 , 0.59801543, 0.5       , 0.52067193, 0.5946118 ,\n",
       "        0.62854197, 0.48897042, 0.49645992, 0.49967404, 0.50032596,\n",
       "        0.49967404, 0.49967404, 0.50032596, 0.50026532, 0.50291848,\n",
       "        0.49967404, 0.49967404, 0.53025364, 0.53063267, 0.46936733,\n",
       "        0.46936733, 0.53063267, 0.46936733, 0.46936733, 0.46936733,\n",
       "        0.53063267, 0.42961537, 0.57073333, 0.57038463, 0.42961537,\n",
       "        0.42961537, 0.57038463, 0.42961537, 0.42961537, 0.5710972 ,\n",
       "        0.44080414, 0.44080414, 0.44080414, 0.44080414, 0.44080414,\n",
       "        0.55971134, 0.55919586, 0.44097091, 0.44125896, 0.49879471,\n",
       "        0.50120529, 0.49548962, 0.49509544, 0.50132658, 0.49879471,\n",
       "        0.49944663, 0.50240301, 0.49879471, 0.4171076 , 0.58231629,\n",
       "        0.58231629, 0.58199791, 0.41653148, 0.58187662, 0.41709244,\n",
       "        0.58237693, 0.58136115, 0.55090283, 0.55090283, 0.44909717,\n",
       "        0.44909717, 0.44909717, 0.44909717, 0.44909717, 0.55090283,\n",
       "        0.44905168, 0.44909717, 0.55090283, 0.55090283, 0.55090283,\n",
       "        0.44909717, 0.44909717, 0.44909717, 0.55090283, 0.55090283,\n",
       "        0.55090283, 0.44909717, 0.44686851, 0.44909717, 0.55090283,\n",
       "        0.55090283, 0.55090283, 0.44909717, 0.55090283]),\n",
       " 'split4_test_roc_auc_ovo': array([0.48491487, 0.50397216, 0.49241195, 0.5       , 0.46795737,\n",
       "        0.48228445, 0.47665974, 0.51575979, 0.52531118, 0.51508513,\n",
       "        0.49592929, 0.5       , 0.49903728, 0.48286056, 0.48228445,\n",
       "        0.47665974, 0.53649995, 0.61189527, 0.51443321, 0.5       ,\n",
       "        0.50334299, 0.5129247 , 0.46334844, 0.48228445, 0.49741506,\n",
       "        0.48809109, 0.61827802, 0.48489213, 0.48625661, 0.48909171,\n",
       "        0.47987386, 0.52462894, 0.52299156, 0.54953835, 0.5533589 ,\n",
       "        0.61959702, 0.48492245, 0.49353386, 0.48906139, 0.47987386,\n",
       "        0.46527388, 0.48010128, 0.55959005, 0.54265529, 0.61880865,\n",
       "        0.48490729, 0.48322443, 0.48909171, 0.52564472, 0.48023772,\n",
       "        0.56366834, 0.48889462, 0.58042117, 0.61768674, 0.49135069,\n",
       "        0.50164496, 0.47843357, 0.51575979, 0.49320032, 0.51782168,\n",
       "        0.55426856, 0.4964296 , 0.6078473 , 0.47141406, 0.51871617,\n",
       "        0.48924332, 0.4720963 , 0.52368896, 0.48551373, 0.45895177,\n",
       "        0.51304598, 0.61007596, 0.47755424, 0.51953486, 0.48687821,\n",
       "        0.51830683, 0.54732485, 0.53458967, 0.51650268, 0.49598993,\n",
       "        0.61109174, 0.53047348, 0.49528495, 0.49928744, 0.5       ,\n",
       "        0.46535727, 0.49808214, 0.49799118, 0.43592232, 0.48452827,\n",
       "        0.55275247, 0.45749632, 0.5       , 0.49405691, 0.55252505,\n",
       "        0.49808214, 0.49799118, 0.60279871, 0.48369442, 0.51500932,\n",
       "        0.5       , 0.47305144, 0.49394321, 0.51700299, 0.46001304,\n",
       "        0.52878303, 0.59908428, 0.51515335, 0.5       , 0.52016404,\n",
       "        0.47280887, 0.55103928, 0.51700299, 0.52855562, 0.46428842,\n",
       "        0.60031232, 0.5123031 , 0.49158568, 0.52020194, 0.51018815,\n",
       "        0.55103928, 0.52857078, 0.50948316, 0.60581573, 0.59662821,\n",
       "        0.48387635, 0.49158568, 0.50958929, 0.51018815, 0.50948316,\n",
       "        0.46880638, 0.48809109, 0.57156719, 0.59978168, 0.52039904,\n",
       "        0.51148441, 0.50960445, 0.54016889, 0.53508998, 0.49685411,\n",
       "        0.46213557, 0.58612926, 0.60305644, 0.51721524, 0.48624145,\n",
       "        0.44949135, 0.46121075, 0.53322519, 0.50463167, 0.58222532,\n",
       "        0.50658743, 0.60601283, 0.48261799, 0.46860929, 0.52358283,\n",
       "        0.5578617 , 0.50132658, 0.48369442, 0.47741779, 0.53035977,\n",
       "        0.60589154, 0.48237542, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.52053548, 0.49006201, 0.50507133, 0.48922816,\n",
       "        0.5523128 , 0.5       , 0.5       , 0.5       , 0.49479222,\n",
       "        0.49326855, 0.49006201, 0.49006201, 0.55745236, 0.53630285,\n",
       "        0.5       , 0.5       , 0.5       , 0.496043  , 0.48306524,\n",
       "        0.5       , 0.49006201, 0.55825589, 0.516533  , 0.5       ,\n",
       "        0.5       , 0.5       , 0.47940387, 0.49006201, 0.49006201,\n",
       "        0.49006201, 0.60117649, 0.51991389, 0.5       , 0.5       ,\n",
       "        0.5       , 0.49326855, 0.49006201, 0.49006201, 0.55745236,\n",
       "        0.56109098, 0.51184827, 0.5       , 0.5       , 0.4996892 ,\n",
       "        0.48306524, 0.5       , 0.49006201, 0.55822556, 0.52484119,\n",
       "        0.48361861, 0.5       , 0.5       , 0.49970436, 0.50993799,\n",
       "        0.5       , 0.49006201, 0.60141906, 0.53727315, 0.51844328,\n",
       "        0.5       , 0.5       , 0.49325338, 0.49006201, 0.49515608,\n",
       "        0.44254764, 0.55226732, 0.5256144 , 0.49274549, 0.5       ,\n",
       "        0.50359314, 0.51693476, 0.5       , 0.49006201, 0.55830137,\n",
       "        0.52343122, 0.5480071 , 0.48988008, 0.49830198, 0.49663427,\n",
       "        0.49713458, 0.49619461, 0.49229825, 0.50286542, 0.49499689,\n",
       "        0.49134311, 0.49713458, 0.52133901, 0.47866099, 0.47866099,\n",
       "        0.52133901, 0.47866099, 0.52512925, 0.47866099, 0.52147546,\n",
       "        0.52133901, 0.45256902, 0.45256902, 0.5460665 , 0.45147743,\n",
       "        0.45256902, 0.45255386, 0.45273579, 0.54723389, 0.45695053,\n",
       "        0.48740884, 0.51259116, 0.48740884, 0.48740884, 0.51259116,\n",
       "        0.51259116, 0.51259116, 0.48740884, 0.51412241, 0.48395215,\n",
       "        0.51600237, 0.48399763, 0.48399763, 0.48399763, 0.51600237,\n",
       "        0.51600237, 0.48399763, 0.51583559, 0.47309692, 0.47211146,\n",
       "        0.52714565, 0.52716081, 0.47317273, 0.52716081, 0.52750951,\n",
       "        0.52716081, 0.52572052, 0.48010128, 0.51989872, 0.48010128,\n",
       "        0.48010128, 0.51989872, 0.48010128, 0.52094483, 0.48010128,\n",
       "        0.48010128, 0.48010128, 0.48010128, 0.51989872, 0.48010128,\n",
       "        0.48010128, 0.48010128, 0.48010128, 0.51989872, 0.48010128,\n",
       "        0.48010128, 0.51989872, 0.48010128, 0.51989872, 0.51989872,\n",
       "        0.51989872, 0.48010128, 0.48010128, 0.51950454]),\n",
       " 'mean_test_roc_auc_ovo': array([0.49888264, 0.51454085, 0.49044558, 0.50338847, 0.50053518,\n",
       "        0.47630801, 0.49687836, 0.53857093, 0.55374399, 0.5130763 ,\n",
       "        0.48723298, 0.52246699, 0.46081657, 0.49711791, 0.48493458,\n",
       "        0.49606877, 0.53566306, 0.62919996, 0.51447718, 0.5       ,\n",
       "        0.50449218, 0.49660243, 0.49911309, 0.47630801, 0.50968935,\n",
       "        0.51737595, 0.63660153, 0.50181476, 0.50970755, 0.5177489 ,\n",
       "        0.48328204, 0.51323398, 0.48925545, 0.55079367, 0.56234327,\n",
       "        0.63531285, 0.52061735, 0.50141755, 0.51774284, 0.48571992,\n",
       "        0.5041071 , 0.50226353, 0.54199124, 0.57164602, 0.63729286,\n",
       "        0.48255431, 0.48293637, 0.487706  , 0.5088555 , 0.49107476,\n",
       "        0.5434194 , 0.53784927, 0.56422626, 0.64872421, 0.50421929,\n",
       "        0.52724875, 0.49810034, 0.47374884, 0.4894768 , 0.55502358,\n",
       "        0.54250974, 0.51117209, 0.6466411 , 0.49556543, 0.51456511,\n",
       "        0.52321897, 0.51328553, 0.49817614, 0.53544171, 0.47982838,\n",
       "        0.53593899, 0.6469049 , 0.50666929, 0.51731227, 0.4748283 ,\n",
       "        0.52030807, 0.52165133, 0.50924969, 0.52565988, 0.53264604,\n",
       "        0.64675025, 0.51283979, 0.48774087, 0.49154323, 0.4896557 ,\n",
       "        0.49338225, 0.50934975, 0.501366  , 0.47591989, 0.52575388,\n",
       "        0.50892979, 0.49640686, 0.49259995, 0.51467427, 0.52051123,\n",
       "        0.52265195, 0.49929805, 0.55022969, 0.48652345, 0.51480162,\n",
       "        0.51432708, 0.49334132, 0.48856411, 0.50962871, 0.52381025,\n",
       "        0.50611744, 0.54731272, 0.49798208, 0.49210722, 0.49750603,\n",
       "        0.49504692, 0.49452842, 0.49162965, 0.48030746, 0.47890963,\n",
       "        0.54726724, 0.50784578, 0.49980291, 0.49430101, 0.48410679,\n",
       "        0.5075274 , 0.52162404, 0.50118104, 0.57089404, 0.5462363 ,\n",
       "        0.46165345, 0.50881457, 0.51906791, 0.47751634, 0.50698161,\n",
       "        0.51010779, 0.46474325, 0.53411058, 0.54863173, 0.51833412,\n",
       "        0.50961506, 0.49541382, 0.48393093, 0.50394033, 0.50213314,\n",
       "        0.50932549, 0.55959763, 0.54858928, 0.53937446, 0.49194196,\n",
       "        0.46531785, 0.48869146, 0.51533832, 0.51407693, 0.55576343,\n",
       "        0.5138298 , 0.55026607, 0.51320366, 0.49057445, 0.49128701,\n",
       "        0.51708182, 0.49668127, 0.4973059 , 0.52248518, 0.53216998,\n",
       "        0.55015995, 0.48625055, 0.5       , 0.5       , 0.5       ,\n",
       "        0.50311254, 0.49296078, 0.487612  , 0.51416183, 0.48650525,\n",
       "        0.57007232, 0.5       , 0.5       , 0.5       , 0.5117573 ,\n",
       "        0.51404509, 0.50202398, 0.5057748 , 0.49530163, 0.56803469,\n",
       "        0.5       , 0.5       , 0.5       , 0.53028851, 0.50167832,\n",
       "        0.50413439, 0.51467124, 0.55971134, 0.55729165, 0.5       ,\n",
       "        0.5       , 0.5       , 0.49734229, 0.487612  , 0.50179657,\n",
       "        0.4954593 , 0.58126109, 0.51552934, 0.5       , 0.5       ,\n",
       "        0.48425234, 0.5033824 , 0.49963159, 0.50201186, 0.53167877,\n",
       "        0.56921421, 0.52152094, 0.5       , 0.5       , 0.48736639,\n",
       "        0.50167832, 0.50413439, 0.49259085, 0.53360724, 0.56549068,\n",
       "        0.50565351, 0.5       , 0.5       , 0.50149487, 0.4915872 ,\n",
       "        0.50791704, 0.49760609, 0.57812277, 0.54382571, 0.53592383,\n",
       "        0.5       , 0.50169499, 0.50240149, 0.50202398, 0.49544717,\n",
       "        0.48776361, 0.55995998, 0.53726103, 0.5301081 , 0.5       ,\n",
       "        0.50936036, 0.50845374, 0.5       , 0.4917661 , 0.55952031,\n",
       "        0.55532983, 0.47494353, 0.51824315, 0.50117649, 0.49779257,\n",
       "        0.49776831, 0.49634015, 0.50128261, 0.49781986, 0.49798966,\n",
       "        0.49661002, 0.51484862, 0.51407086, 0.50718477, 0.48437666,\n",
       "        0.49263633, 0.50654801, 0.49357328, 0.4949408 , 0.49284252,\n",
       "        0.50370382, 0.45301778, 0.50394639, 0.51263361, 0.4656711 ,\n",
       "        0.46207493, 0.50380085, 0.47575615, 0.47106536, 0.52991404,\n",
       "        0.51341894, 0.46282084, 0.51445292, 0.51441956, 0.51938629,\n",
       "        0.50777604, 0.50808836, 0.49142952, 0.4853227 , 0.51195136,\n",
       "        0.4802923 , 0.48050152, 0.51121454, 0.52021407, 0.47981019,\n",
       "        0.51848573, 0.48712988, 0.50061402, 0.48915235, 0.52202126,\n",
       "        0.51126912, 0.53289164, 0.50115375, 0.5452569 , 0.48142937,\n",
       "        0.51377977, 0.52568414, 0.48960112, 0.5185676 , 0.48196607,\n",
       "        0.50153883, 0.5099289 , 0.4814324 , 0.49050168, 0.51060811,\n",
       "        0.48097758, 0.50229385, 0.51086281, 0.49816401, 0.49048045,\n",
       "        0.49024697, 0.50170257, 0.46923998, 0.51853727, 0.48960112,\n",
       "        0.48960112, 0.47719947, 0.46969481, 0.47810003, 0.5185676 ,\n",
       "        0.53086918, 0.51060811, 0.48934641, 0.51852514]),\n",
       " 'std_test_roc_auc_ovo': array([0.03564939, 0.01281297, 0.02784696, 0.00677694, 0.0452141 ,\n",
       "        0.0111101 , 0.03375055, 0.0154971 , 0.02726238, 0.0331186 ,\n",
       "        0.02890857, 0.02958772, 0.0222946 , 0.01754394, 0.02139575,\n",
       "        0.03366586, 0.01231172, 0.04807381, 0.03180322, 0.        ,\n",
       "        0.02532189, 0.03451401, 0.02485431, 0.0111101 , 0.02054231,\n",
       "        0.02564473, 0.05422596, 0.03555099, 0.02299713, 0.03856668,\n",
       "        0.03202782, 0.01767787, 0.02186306, 0.01798383, 0.05868968,\n",
       "        0.05228948, 0.02901812, 0.02648142, 0.03857336, 0.03325836,\n",
       "        0.03593755, 0.03354628, 0.03901285, 0.03158645, 0.0499421 ,\n",
       "        0.03106084, 0.0197704 , 0.04074086, 0.01934111, 0.00723182,\n",
       "        0.02076623, 0.03214032, 0.04110417, 0.0477309 , 0.02791387,\n",
       "        0.03458573, 0.04365283, 0.03455378, 0.03478462, 0.02158139,\n",
       "        0.02804434, 0.04120241, 0.04971848, 0.0428096 , 0.01654218,\n",
       "        0.02860071, 0.03448359, 0.02583552, 0.05070273, 0.02049326,\n",
       "        0.03543159, 0.04879915, 0.03948599, 0.0309832 , 0.03872865,\n",
       "        0.01952847, 0.03618579, 0.04186126, 0.03609527, 0.03844513,\n",
       "        0.04826284, 0.03284844, 0.01418276, 0.03120249, 0.02068861,\n",
       "        0.02983547, 0.03417002, 0.05139506, 0.06473695, 0.03551148,\n",
       "        0.04276819, 0.05547748, 0.02178705, 0.04558081, 0.02769822,\n",
       "        0.03126372, 0.05355195, 0.05187343, 0.04316266, 0.03218116,\n",
       "        0.02865416, 0.03132048, 0.04227995, 0.0330161 , 0.03551822,\n",
       "        0.04979556, 0.05021172, 0.04379224, 0.01578556, 0.06057816,\n",
       "        0.02629492, 0.03767438, 0.03306373, 0.02857982, 0.02148743,\n",
       "        0.05077304, 0.04354138, 0.05139502, 0.02498922, 0.03493736,\n",
       "        0.04068947, 0.03924183, 0.02081965, 0.04367389, 0.04951339,\n",
       "        0.01845453, 0.05036998, 0.02104287, 0.0311169 , 0.00786017,\n",
       "        0.02310986, 0.01235733, 0.04614785, 0.05233331, 0.04033158,\n",
       "        0.04007748, 0.02805442, 0.0448121 , 0.02871389, 0.02024331,\n",
       "        0.04889114, 0.01892577, 0.05307976, 0.01926577, 0.03398791,\n",
       "        0.03117422, 0.03021198, 0.01061076, 0.03789528, 0.01857015,\n",
       "        0.04940446, 0.05347155, 0.03893293, 0.02012654, 0.02150056,\n",
       "        0.0400937 , 0.03328841, 0.02460321, 0.03884834, 0.01797184,\n",
       "        0.05359669, 0.04027696, 0.        , 0.        , 0.        ,\n",
       "        0.00622508, 0.02068999, 0.02900074, 0.01310221, 0.02687251,\n",
       "        0.03068947, 0.        , 0.        , 0.        , 0.0190941 ,\n",
       "        0.01746654, 0.01114801, 0.03011906, 0.03977555, 0.0512255 ,\n",
       "        0.        , 0.        , 0.        , 0.02414903, 0.05352805,\n",
       "        0.00826877, 0.02734115, 0.02789323, 0.05378341, 0.        ,\n",
       "        0.        , 0.        , 0.02161221, 0.02900074, 0.01137366,\n",
       "        0.01314984, 0.03305374, 0.0630516 , 0.        , 0.        ,\n",
       "        0.03122238, 0.02453505, 0.01132426, 0.01115969, 0.02450764,\n",
       "        0.02843422, 0.04333209, 0.        , 0.        , 0.04227276,\n",
       "        0.05352805, 0.00826877, 0.01079506, 0.05678594, 0.04655848,\n",
       "        0.05050645, 0.        , 0.        , 0.02010473, 0.03039293,\n",
       "        0.00736825, 0.00885547, 0.02840717, 0.03257705, 0.02878854,\n",
       "        0.        , 0.00286191, 0.02470747, 0.01114801, 0.02184182,\n",
       "        0.03508047, 0.03075783, 0.02747478, 0.03927325, 0.        ,\n",
       "        0.04757747, 0.05288103, 0.        , 0.02766007, 0.02782676,\n",
       "        0.03921084, 0.06300152, 0.0462485 , 0.02579741, 0.02579492,\n",
       "        0.02576993, 0.02563063, 0.02602315, 0.02581117, 0.02588579,\n",
       "        0.0259022 , 0.02108521, 0.02386219, 0.02636051, 0.02312089,\n",
       "        0.02648382, 0.02652586, 0.02721066, 0.02683999, 0.02639008,\n",
       "        0.0270699 , 0.01776852, 0.05073279, 0.04893286, 0.03780915,\n",
       "        0.0337822 , 0.05061421, 0.04459401, 0.04169656, 0.0403184 ,\n",
       "        0.05142217, 0.03815963, 0.05114639, 0.05122584, 0.04948211,\n",
       "        0.0526887 , 0.0525149 , 0.05241098, 0.0510523 , 0.03179379,\n",
       "        0.02766279, 0.0278785 , 0.03213064, 0.02729608, 0.02731291,\n",
       "        0.02848986, 0.03144595, 0.03378426, 0.04813509, 0.04416983,\n",
       "        0.04737426, 0.03655274, 0.04965386, 0.01980699, 0.04577674,\n",
       "        0.04782078, 0.04133324, 0.03437213, 0.03073799, 0.03165304,\n",
       "        0.03587774, 0.03383567, 0.03073799, 0.03475496, 0.03430813,\n",
       "        0.03066051, 0.03582727, 0.03460505, 0.03585126, 0.03462463,\n",
       "        0.03456094, 0.03610092, 0.01853109, 0.03070677, 0.03437213,\n",
       "        0.03437213, 0.02774375, 0.02043396, 0.02845999, 0.03073799,\n",
       "        0.01864691, 0.03430813, 0.03429404, 0.03071584]),\n",
       " 'rank_test_roc_auc_ovo': array([211,  98, 261, 159, 184, 307, 225,  43,  27, 113, 279,  68, 323,\n",
       "        224, 286, 231,  48,   8,  99, 185, 150, 228, 210, 307, 127,  88,\n",
       "          6, 169, 126,  86, 291, 111, 269,  28,  18,   7,  73, 177,  87,\n",
       "        284, 154, 164,  41,  11,   5, 293, 292, 275, 135, 257,  39,  44,\n",
       "         17,   1, 151,  60, 214, 313, 267,  26,  40, 120,   4, 232,  97,\n",
       "         65, 110, 212,  49, 301,  46,   2, 145,  89, 312,  75,  70, 133,\n",
       "         63,  53,   3, 114, 274, 254, 263, 242, 131, 178, 309,  61, 134,\n",
       "        229, 247,  95,  74,  66, 209,  30, 281,  94, 102, 243, 272, 128,\n",
       "         64, 147,  34, 216, 249, 221, 237, 239, 252, 299, 303,  35, 140,\n",
       "        207, 240, 289, 142,  71, 180,  12,  36, 322, 136,  78, 305, 144,\n",
       "        124, 319,  50,  32,  84, 129, 235, 290, 156, 165, 132,  21,  33,\n",
       "         42, 250, 318, 271,  92, 104,  24, 107,  29, 112, 258, 256,  90,\n",
       "        226, 223,  67,  54,  31, 283, 185, 185, 185, 161, 244, 276, 103,\n",
       "        282,  13, 185, 185, 185, 117, 106, 166, 148, 236,  15, 185, 185,\n",
       "        185,  57, 173, 152,  96,  20,  23, 185, 185, 185, 222, 276, 170,\n",
       "        233,   9,  91, 185, 185, 288, 160, 208, 168,  55,  14,  72, 185,\n",
       "        185, 278, 173, 152, 248,  51,  16, 149, 185, 185, 176, 253, 139,\n",
       "        220,  10,  38,  47, 185, 172, 162, 166, 234, 273,  19,  45,  58,\n",
       "        185, 130, 137, 185, 251,  22,  25, 311,  85, 181, 218, 219, 230,\n",
       "        179, 217, 215, 227,  93, 105, 143, 287, 246, 146, 241, 238, 245,\n",
       "        158, 324, 155, 115, 317, 321, 157, 310, 314,  59, 109, 320, 100,\n",
       "        101,  77, 141, 138, 255, 285, 116, 300, 298, 119,  76, 302,  83,\n",
       "        280, 183, 270,  69, 118,  52, 182,  37, 296, 108,  62, 264,  79,\n",
       "        294, 175, 125, 295, 259, 122, 297, 163, 121, 213, 260, 262, 171,\n",
       "        316,  81, 264, 264, 306, 315, 304,  79,  56, 122, 268,  82]),\n",
       " 'split0_test_neg_log_loss': array([-0.25621799, -0.25621799, -0.25621812, -0.25621834, -0.25626862,\n",
       "        -0.2562706 , -0.25590328, -0.25596091, -0.25358201, -0.25621806,\n",
       "        -0.25621767, -0.2562045 , -0.25643247, -0.25626638, -0.25627968,\n",
       "        -0.2557427 , -0.25482883, -0.2502434 , -0.25621735, -0.25621834,\n",
       "        -0.25610567, -0.25622134, -0.25624474, -0.25654503, -0.2560498 ,\n",
       "        -0.25476685, -0.24673449, -0.25612716, -0.25624691, -0.25524794,\n",
       "        -0.25624095, -0.256323  , -0.25628659, -0.2554258 , -0.25627516,\n",
       "        -0.24766599, -0.25617287, -0.25630597, -0.25531784, -0.25635193,\n",
       "        -0.25541907, -0.25478615, -0.25498672, -0.25455101, -0.24820419,\n",
       "        -0.2562718 , -0.25623272, -0.25683218, -0.25630847, -0.25686006,\n",
       "        -0.25607913, -0.25485859, -0.25730744, -0.24835256, -0.2566029 ,\n",
       "        -0.25601715, -0.25621119, -0.25692381, -0.25656507, -0.25372714,\n",
       "        -0.25621551, -0.26005247, -0.24918332, -0.25764841, -0.25625469,\n",
       "        -0.25623815, -0.25582263, -0.25657967, -0.25502209, -0.25927828,\n",
       "        -0.25586589, -0.24925551, -0.2587246 , -0.25596296, -0.25600683,\n",
       "        -0.25569271, -0.25480719, -0.25484448, -0.25611582, -0.25608154,\n",
       "        -0.24817365, -0.25621799, -0.25621799, -0.256218  , -0.25621834,\n",
       "        -0.25615227, -0.25607271, -0.25620637, -0.25545971, -0.25507888,\n",
       "        -0.25621799, -0.25621779, -0.25621834, -0.25613478, -0.25624697,\n",
       "        -0.25576255, -0.25620874, -0.30950586, -0.25815101, -0.25621798,\n",
       "        -0.25618677, -0.25625306, -0.25625399, -0.25625878, -0.25606025,\n",
       "        -0.25677467, -0.26218938, -0.25499063, -0.25621834, -0.25636979,\n",
       "        -0.25622252, -0.25623797, -0.25639929, -0.25627202, -0.25621143,\n",
       "        -0.26281626, -0.25918726, -0.25628822, -0.25638138, -0.25636428,\n",
       "        -0.25618679, -0.25621604, -0.2562536 , -0.29839539, -0.26090282,\n",
       "        -0.25848719, -0.25631672, -0.25621402, -0.25662713, -0.25613045,\n",
       "        -0.25626033, -0.25655446, -0.29273248, -0.26219028, -0.25481625,\n",
       "        -0.25641813, -0.25628145, -0.2575002 , -0.25641884, -0.2560557 ,\n",
       "        -0.25620943, -0.31642786, -0.2621949 , -0.25438254, -0.25664956,\n",
       "        -0.25631459, -0.25633991, -0.25620034, -0.25613622, -0.2556886 ,\n",
       "        -0.35577381, -0.26163685, -0.25491804, -0.25621976, -0.2565256 ,\n",
       "        -0.2561029 , -0.25623508, -0.25660317, -0.2639108 , -0.25726549,\n",
       "        -0.26216921, -0.25658033, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25655865, -0.25690421,\n",
       "        -0.25384467, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621802, -0.25684616, -0.25645397, -0.25458242,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621834, -0.2568085 , -0.25543446, -0.25434459, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25660665,\n",
       "        -0.25709011, -0.2537357 , -0.25506357, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621798, -0.25668482, -0.25641134,\n",
       "        -0.25490498, -0.25473995, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621834, -0.25702205, -0.25427148, -0.25453417,\n",
       "        -0.25495989, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25662049, -0.25685712, -0.25309177, -0.25598909, -0.2560494 ,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621807, -0.25688595,\n",
       "        -0.25625043, -0.2552581 , -0.25534085, -0.2547938 , -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621834, -0.25652698, -0.25393753,\n",
       "        -0.254306  , -0.25708035, -0.25563578, -0.25557256, -0.25724968,\n",
       "        -0.25664033, -0.2563353 , -0.25600177, -0.25636488, -0.25623921,\n",
       "        -0.25667069, -0.25598608, -0.25741248, -0.25673946, -0.25842388,\n",
       "        -0.25617355, -0.25586008, -0.25603307, -0.25692592, -0.25597615,\n",
       "        -0.25672487, -0.25628937, -0.25644315, -0.25732153, -0.2565696 ,\n",
       "        -0.25671567, -0.25623667, -0.25633241, -0.25635581, -0.2557612 ,\n",
       "        -0.25596517, -0.25784468, -0.25614171, -0.25604584, -0.25539053,\n",
       "        -0.25637167, -0.25689147, -0.25570286, -0.25702152, -0.2558151 ,\n",
       "        -0.25623666, -0.25661529, -0.25548615, -0.2561671 , -0.25624837,\n",
       "        -0.25595535, -0.25726341, -0.25751113, -0.25791646, -0.25909382,\n",
       "        -0.25817419, -0.28015976, -0.25814023, -0.26353356, -0.25604092,\n",
       "        -0.25585991, -0.26198287, -0.25675919, -0.25600478, -0.25818668,\n",
       "        -0.25605615, -0.25562982, -0.25669487, -0.25637071, -0.25616373,\n",
       "        -0.2576382 , -0.25611055, -0.25559199, -0.25641324, -0.25631162,\n",
       "        -0.25600901, -0.25555819, -0.25634335, -0.25569411, -0.2567149 ,\n",
       "        -0.25637406, -0.25624057, -0.25631067, -0.2563434 , -0.25596705,\n",
       "        -0.25559157, -0.25602021, -0.25601076, -0.25585577]),\n",
       " 'split1_test_neg_log_loss': array([-0.25621799, -0.25621798, -0.25621818, -0.25621834, -0.2563404 ,\n",
       "        -0.25661397, -0.25625638, -0.25567585, -0.25481495, -0.25621761,\n",
       "        -0.25621841, -0.25621834, -0.2565617 , -0.25644456, -0.25640732,\n",
       "        -0.25675438, -0.25623669, -0.25450984, -0.25621834, -0.25621834,\n",
       "        -0.25724828, -0.25612515, -0.25625374, -0.25766405, -0.25590518,\n",
       "        -0.25766233, -0.25415087, -0.25605469, -0.25619509, -0.25615114,\n",
       "        -0.25658901, -0.25636941, -0.25640078, -0.25572404, -0.25478728,\n",
       "        -0.25422946, -0.25586889, -0.25710953, -0.25612471, -0.25778869,\n",
       "        -0.25622398, -0.2575522 , -0.25575244, -0.25290699, -0.25307867,\n",
       "        -0.25600618, -0.25809434, -0.2559641 , -0.25615305, -0.25633963,\n",
       "        -0.25574142, -0.25574733, -0.25776734, -0.25188787, -0.25659377,\n",
       "        -0.25623446, -0.25547845, -0.25644305, -0.25818229, -0.25436347,\n",
       "        -0.25655584, -0.27226645, -0.25279402, -0.26005146, -0.25610505,\n",
       "        -0.25641653, -0.25623733, -0.25613813, -0.25532414, -0.33319249,\n",
       "        -0.25668903, -0.25297474, -0.26043052, -0.25633128, -0.25720942,\n",
       "        -0.25655208, -0.25667261, -0.28611396, -0.2562375 , -0.25718314,\n",
       "        -0.25252274, -0.25621799, -0.25621799, -0.25621825, -0.25621834,\n",
       "        -0.25620089, -0.25622014, -0.25634814, -0.25607804, -0.25528939,\n",
       "        -0.25621799, -0.25621787, -0.25621834, -0.25654145, -0.25612908,\n",
       "        -0.25629958, -0.2564132 , -0.5087216 , -0.25469306, -0.25621801,\n",
       "        -0.25621834, -0.25633655, -0.25637936, -0.25623641, -0.25615508,\n",
       "        -0.25606875, -0.25710901, -0.25869041, -0.25621834, -0.25586968,\n",
       "        -0.25626705, -0.25651906, -0.25620825, -0.25935887, -0.2562629 ,\n",
       "        -0.25759252, -0.2550124 , -0.25582955, -0.256223  , -0.25625554,\n",
       "        -0.25697242, -0.25529272, -0.25633082, -0.27406754, -0.25798244,\n",
       "        -0.25924969, -0.25603264, -0.25614608, -0.25677758, -0.25644261,\n",
       "        -0.2563188 , -0.25663561, -0.27841217, -0.25716352, -0.25592902,\n",
       "        -0.25602505, -0.25618186, -0.25642357, -0.25617834, -0.25619899,\n",
       "        -0.25603485, -0.3505296 , -0.25731722, -0.25500122, -0.25588465,\n",
       "        -0.25639937, -0.255993  , -0.25621661, -0.25689694, -0.25555402,\n",
       "        -0.35820468, -0.25694406, -0.25897288, -0.25642721, -0.25697193,\n",
       "        -0.2571977 , -0.25639435, -0.25599265, -0.25664245, -0.25855096,\n",
       "        -0.25746883, -0.25615408, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25695919, -0.25719835,\n",
       "        -0.25530035, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25693691, -0.2562383 , -0.25390163,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621834, -0.25686983, -0.25509642, -0.25629323, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25808728,\n",
       "        -0.2571844 , -0.25518841, -0.25648664, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.256218  , -0.25685301, -0.25627507,\n",
       "        -0.25510308, -0.25667393, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621834, -0.25714752, -0.25649739, -0.25598496,\n",
       "        -0.25632106, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25764701, -0.25761043, -0.25503608, -0.25720739, -0.25618121,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.256218  , -0.25731748,\n",
       "        -0.25666721, -0.25514379, -0.25583064, -0.25617751, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621834, -0.25673467, -0.25546913,\n",
       "        -0.25591583, -0.25733137, -0.25611278, -0.25622667, -0.25624592,\n",
       "        -0.25625293, -0.25620498, -0.25679805, -0.25627272, -0.25629745,\n",
       "        -0.25625353, -0.25620355, -0.25646717, -0.25607982, -0.2564167 ,\n",
       "        -0.25822872, -0.25609457, -0.25629966, -0.25613689, -0.25656441,\n",
       "        -0.25607063, -0.25741626, -0.2561862 , -0.25618921, -0.25566378,\n",
       "        -0.25656358, -0.2557437 , -0.25586366, -0.25681372, -0.25582692,\n",
       "        -0.25631921, -0.25631832, -0.25679709, -0.25623725, -0.25621989,\n",
       "        -0.25629309, -0.25658178, -0.25625548, -0.25622705, -0.25621544,\n",
       "        -0.2565103 , -0.25624597, -0.25613437, -0.25609642, -0.25632302,\n",
       "        -0.25610396, -0.25596034, -0.25618475, -0.25546097, -0.25541822,\n",
       "        -0.25807285, -0.25549459, -0.25565552, -0.2570449 , -0.25712172,\n",
       "        -0.25937193, -0.25769899, -0.25624456, -0.25666724, -0.25602482,\n",
       "        -0.2561358 , -0.25617622, -0.25608035, -0.25598554, -0.25627295,\n",
       "        -0.25620039, -0.25591077, -0.25628449, -0.25622715, -0.25645908,\n",
       "        -0.2563894 , -0.25601861, -0.25644808, -0.2562599 , -0.25666393,\n",
       "        -0.2564582 , -0.25642773, -0.25675815, -0.25624285, -0.25637355,\n",
       "        -0.25621752, -0.25625122, -0.25633993, -0.25657961]),\n",
       " 'split2_test_neg_log_loss': array([-0.25621799, -0.25621799, -0.25621751, -0.25621834, -0.25625986,\n",
       "        -0.2563059 , -0.25621492, -0.25606832, -0.25509172, -0.25621796,\n",
       "        -0.25622198, -0.25621834, -0.25624029, -0.25627042, -0.25620378,\n",
       "        -0.25628583, -0.25640573, -0.24795301, -0.25621834, -0.25621834,\n",
       "        -0.25616116, -0.25623411, -0.25619308, -0.25653711, -0.25635501,\n",
       "        -0.25549981, -0.24785959, -0.25627061, -0.25624069, -0.25635147,\n",
       "        -0.25619864, -0.25628709, -0.25620924, -0.25556113, -0.2557594 ,\n",
       "        -0.24772615, -0.25625466, -0.25623987, -0.25630834, -0.25607753,\n",
       "        -0.25643456, -0.25708336, -0.25707763, -0.25487571, -0.24774878,\n",
       "        -0.2562584 , -0.25640334, -0.2562079 , -0.25608496, -0.25701805,\n",
       "        -0.25635465, -0.25469871, -0.25428326, -0.24543666, -0.26110026,\n",
       "        -0.25667454, -0.25622461, -0.25645051, -0.25553963, -0.25564639,\n",
       "        -0.25530384, -0.27274846, -0.24591493, -0.25630855, -0.2580818 ,\n",
       "        -0.25674689, -0.25660218, -0.25735718, -0.26056192, -0.25813222,\n",
       "        -0.25559341, -0.24544707, -0.25804624, -0.25623108, -0.25663751,\n",
       "        -0.25584512, -0.25618292, -0.25985788, -0.25617826, -0.25543703,\n",
       "        -0.2450375 , -0.25621799, -0.25621799, -0.25621797, -0.25621847,\n",
       "        -0.25627935, -0.25606093, -0.25657315, -0.25749865, -0.25637004,\n",
       "        -0.25621799, -0.25621821, -0.25625143, -0.25593814, -0.2562218 ,\n",
       "        -0.25606611, -0.25625344, -0.90015433, -0.25794998, -0.25621794,\n",
       "        -0.25621834, -0.25603061, -0.256233  , -0.25626475, -0.25606541,\n",
       "        -0.25600576, -0.25307733, -0.25779487, -0.25623144, -0.25621119,\n",
       "        -0.25620936, -0.25620989, -0.25621021, -0.25642962, -0.25650667,\n",
       "        -0.25327375, -0.25628792, -0.25646132, -0.25625377, -0.25650354,\n",
       "        -0.25624905, -0.25638316, -0.25603883, -0.70689434, -0.25361072,\n",
       "        -0.25855768, -0.25635709, -0.25627354, -0.25619038, -0.25654384,\n",
       "        -0.25600382, -0.25749733, -0.27904448, -0.25267031, -0.25794701,\n",
       "        -0.25627266, -0.25626587, -0.25659002, -0.25620315, -0.25641239,\n",
       "        -0.25858015, -0.33721139, -0.25301598, -0.25802713, -0.25629159,\n",
       "        -0.25640856, -0.25621498, -0.25608416, -0.2563838 , -0.25735105,\n",
       "        -0.27299808, -0.25282846, -0.25690484, -0.25697663, -0.25672107,\n",
       "        -0.25619356, -0.25592487, -0.256208  , -0.25515121, -0.26578248,\n",
       "        -0.25326337, -0.25816894, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25695425, -0.2571941 ,\n",
       "        -0.25619727, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621796, -0.25730466, -0.25650659, -0.25664074,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621834, -0.25655563, -0.25639929, -0.25699135, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25685267,\n",
       "        -0.25691247, -0.25595784, -0.25549657, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621796, -0.25661717, -0.25616572,\n",
       "        -0.25561509, -0.2567235 , -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621834, -0.25713615, -0.25734112, -0.25619844,\n",
       "        -0.25614773, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25703796, -0.256645  , -0.2574916 , -0.25732719, -0.25614587,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621796, -0.25683037,\n",
       "        -0.2559034 , -0.25670837, -0.25644103, -0.2561869 , -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621834, -0.25722915, -0.25637734,\n",
       "        -0.25606161, -0.2560144 , -0.25673568, -0.25658876, -0.25613851,\n",
       "        -0.25583403, -0.25586575, -0.25625873, -0.25565507, -0.25618928,\n",
       "        -0.25591578, -0.25562818, -0.25608009, -0.2560227 , -0.25609948,\n",
       "        -0.25623034, -0.25648658, -0.25629269, -0.25610276, -0.25624516,\n",
       "        -0.2565295 , -0.25651806, -0.25619469, -0.25634993, -0.25622315,\n",
       "        -0.2561337 , -0.25607588, -0.25612099, -0.25633297, -0.25615626,\n",
       "        -0.25617716, -0.25630595, -0.25607137, -0.25551918, -0.25583169,\n",
       "        -0.25604921, -0.2559502 , -0.2563037 , -0.2559564 , -0.25696275,\n",
       "        -0.25628599, -0.25619001, -0.25626361, -0.25623246, -0.25623176,\n",
       "        -0.25625307, -0.25629347, -0.2562088 , -0.25641548, -0.25713675,\n",
       "        -0.2560337 , -0.25713791, -0.25601078, -0.2561332 , -0.25683162,\n",
       "        -0.25642606, -0.25603011, -0.25621696, -0.25630791, -0.25623305,\n",
       "        -0.25623159, -0.25624215, -0.25625547, -0.25643823, -0.25623594,\n",
       "        -0.256691  , -0.25712319, -0.25636916, -0.25679587, -0.25652227,\n",
       "        -0.2562915 , -0.25621618, -0.25622086, -0.25627393, -0.2562181 ,\n",
       "        -0.25628831, -0.25623437, -0.25624921, -0.25623611, -0.25632657,\n",
       "        -0.2563549 , -0.2562579 , -0.25621595, -0.25655953]),\n",
       " 'split3_test_neg_log_loss': array([-0.25621799, -0.25621799, -0.2562179 , -0.25621344, -0.25607662,\n",
       "        -0.25645367, -0.25634434, -0.25585094, -0.25298002, -0.25621794,\n",
       "        -0.25621792, -0.25620858, -0.25634879, -0.25618672, -0.25637868,\n",
       "        -0.2564908 , -0.25563872, -0.24337842, -0.25617095, -0.25621834,\n",
       "        -0.25632071, -0.25653708, -0.25621655, -0.25669306, -0.25644699,\n",
       "        -0.25602416, -0.24282588, -0.25696536, -0.25621278, -0.25639343,\n",
       "        -0.2562162 , -0.25613402, -0.2562423 , -0.25408267, -0.25415913,\n",
       "        -0.24226326, -0.25603186, -0.25603754, -0.25625169, -0.25671443,\n",
       "        -0.25632297, -0.25666585, -0.25412014, -0.25415203, -0.24043542,\n",
       "        -0.25669733, -0.25649742, -0.2561757 , -0.25635472, -0.25630899,\n",
       "        -0.25438704, -0.25563261, -0.25463644, -0.24255234, -0.25991259,\n",
       "        -0.25512754, -0.25665739, -0.25611182, -0.25684543, -0.25498277,\n",
       "        -0.25439859, -0.25379545, -0.24499757, -0.25714055, -0.25622059,\n",
       "        -0.2560066 , -0.25578496, -0.25822187, -0.25513905, -0.40680638,\n",
       "        -0.25531667, -0.2438064 , -0.25666705, -0.25631604, -0.25832313,\n",
       "        -0.25636959, -0.25666615, -0.27553851, -0.25613486, -0.25575217,\n",
       "        -0.24218889, -0.25621799, -0.25621799, -0.25621796, -0.25621834,\n",
       "        -0.25622836, -0.25625071, -0.25601317, -0.25697322, -0.25479677,\n",
       "        -0.25621799, -0.25621834, -0.25621059, -0.25616636, -0.2561028 ,\n",
       "        -0.25613694, -0.25618175, -0.37087989, -0.25725637, -0.25621788,\n",
       "        -0.25621834, -0.25621964, -0.25579597, -0.25592309, -0.25605731,\n",
       "        -0.25842059, -0.25451461, -0.25698428, -0.25621834, -0.2564106 ,\n",
       "        -0.25604714, -0.25626957, -0.25656266, -0.25630305, -0.25625039,\n",
       "        -0.25489941, -0.25541817, -0.25633217, -0.2565574 , -0.25618986,\n",
       "        -0.25620912, -0.25708209, -0.25634138, -0.83533184, -0.25502121,\n",
       "        -0.25970654, -0.25616314, -0.25594572, -0.25624673, -0.25645015,\n",
       "        -0.25600966, -0.25694344, -0.26310292, -0.25455715, -0.25989561,\n",
       "        -0.25592252, -0.25637184, -0.25635259, -0.25708271, -0.25622145,\n",
       "        -0.25553752, -0.2954617 , -0.25479806, -0.25618534, -0.25623468,\n",
       "        -0.25607498, -0.25634664, -0.25610785, -0.25583375, -0.25558726,\n",
       "        -0.34222736, -0.254469  , -0.25502571, -0.2560248 , -0.25622055,\n",
       "        -0.25648481, -0.25703588, -0.25634535, -0.25359852, -0.27623232,\n",
       "        -0.25441847, -0.25896454, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25679347, -0.25647416,\n",
       "        -0.25450554, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25688118, -0.25635832, -0.25338602,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25632118, -0.25664209, -0.2554884 , -0.25367953, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25643903,\n",
       "        -0.25660823, -0.25275568, -0.2562661 , -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621798, -0.25635995, -0.2560738 ,\n",
       "        -0.25458465, -0.25536257, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25710432, -0.25596611, -0.25313843,\n",
       "        -0.25658156, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25667728, -0.25717268, -0.25461571, -0.25577963, -0.2553249 ,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25641984,\n",
       "        -0.2576017 , -0.25419747, -0.25615841, -0.25610876, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621834, -0.25644634, -0.25509489,\n",
       "        -0.25467329, -0.25638302, -0.25630039, -0.256255  , -0.2562306 ,\n",
       "        -0.25622201, -0.25627436, -0.25631994, -0.25638463, -0.25661444,\n",
       "        -0.25621957, -0.25623253, -0.25613487, -0.2561094 , -0.25637349,\n",
       "        -0.25875281, -0.25614199, -0.25630671, -0.25623691, -0.2567245 ,\n",
       "        -0.25612634, -0.25651707, -0.25460794, -0.25587214, -0.25726303,\n",
       "        -0.25649724, -0.25519708, -0.25650338, -0.25670506, -0.25411929,\n",
       "        -0.25637468, -0.25632282, -0.25622348, -0.25713   , -0.25651224,\n",
       "        -0.25539052, -0.25603281, -0.25757703, -0.25751669, -0.25635408,\n",
       "        -0.25621729, -0.25714519, -0.25719372, -0.25639086, -0.25623282,\n",
       "        -0.25667765, -0.25647454, -0.25633633, -0.25946053, -0.25575521,\n",
       "        -0.25502474, -0.25438926, -0.2651829 , -0.25470397, -0.25847366,\n",
       "        -0.25414276, -0.25372523, -0.25576728, -0.25577609, -0.25630505,\n",
       "        -0.25657545, -0.25639088, -0.2567497 , -0.25686378, -0.25574327,\n",
       "        -0.25709963, -0.25666355, -0.25583848, -0.25608874, -0.25591753,\n",
       "        -0.25627578, -0.25658148, -0.25634949, -0.25591787, -0.25599871,\n",
       "        -0.25596857, -0.25680337, -0.25768064, -0.25652821, -0.25579256,\n",
       "        -0.25564732, -0.2560356 , -0.25664095, -0.25597249]),\n",
       " 'split4_test_neg_log_loss': array([-0.25621799, -0.25621799, -0.25621761, -0.25621834, -0.25651294,\n",
       "        -0.25634015, -0.25667268, -0.25628254, -0.25612734, -0.25621796,\n",
       "        -0.25621705, -0.25621834, -0.25617814, -0.25648099, -0.25632395,\n",
       "        -0.25721445, -0.25572082, -0.24990528, -0.25621834, -0.25621834,\n",
       "        -0.25628637, -0.2562048 , -0.25650015, -0.25667423, -0.2565966 ,\n",
       "        -0.25715514, -0.2501107 , -0.25623533, -0.25666815, -0.25634177,\n",
       "        -0.25632073, -0.25596481, -0.25618842, -0.25666863, -0.25498665,\n",
       "        -0.24959348, -0.2563173 , -0.2568706 , -0.25647594, -0.25682252,\n",
       "        -0.25643338, -0.25633684, -0.25488391, -0.2553142 , -0.24977905,\n",
       "        -0.25663935, -0.25652868, -0.25667349, -0.25606809, -0.25671423,\n",
       "        -0.25617024, -0.25623089, -0.2532988 , -0.25025603, -0.25817375,\n",
       "        -0.25621334, -0.25676987, -0.25620201, -0.25672941, -0.25625466,\n",
       "        -0.25490744, -0.25901509, -0.25122624, -0.25696027, -0.25682557,\n",
       "        -0.25872759, -0.25686346, -0.2563329 , -0.25770574, -0.28059736,\n",
       "        -0.25618563, -0.25146779, -0.25854472, -0.25618504, -0.25728055,\n",
       "        -0.25637157, -0.25607291, -0.2561818 , -0.25616541, -0.25662889,\n",
       "        -0.25135443, -0.25621799, -0.25621799, -0.25621834, -0.25621834,\n",
       "        -0.25640372, -0.25628021, -0.25632355, -0.25900505, -0.25664585,\n",
       "        -0.25621799, -0.25621882, -0.25621834, -0.25624171, -0.25567363,\n",
       "        -0.25622242, -0.25670137, -0.42544184, -0.25812303, -0.25621797,\n",
       "        -0.25621834, -0.25628518, -0.2561963 , -0.25614859, -0.25656526,\n",
       "        -0.25626128, -0.25377782, -0.2570388 , -0.25621834, -0.2562045 ,\n",
       "        -0.25632045, -0.25590917, -0.25618928, -0.25606906, -0.25713291,\n",
       "        -0.25379167, -0.25650261, -0.25636646, -0.25618201, -0.25624829,\n",
       "        -0.25584324, -0.25600229, -0.2564056 , -1.21316994, -0.25371405,\n",
       "        -0.25850108, -0.25632185, -0.25617642, -0.25636978, -0.25623879,\n",
       "        -0.25692489, -0.25657428, -0.26561479, -0.25393838, -0.25724518,\n",
       "        -0.25619532, -0.25620684, -0.25583527, -0.25597469, -0.25622363,\n",
       "        -0.25661395, -0.41206848, -0.25356647, -0.25678071, -0.25664249,\n",
       "        -0.25644428, -0.25622967, -0.25611891, -0.2561904 , -0.25406287,\n",
       "        -0.42202454, -0.25324725, -0.25622081, -0.25710579, -0.2560203 ,\n",
       "        -0.2560835 , -0.25652112, -0.25629305, -0.25964633, -0.25964969,\n",
       "        -0.25349392, -0.25828145, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25692736, -0.25690766,\n",
       "        -0.25521304, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621801, -0.25681272, -0.25606325, -0.25600722,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621834, -0.25651173, -0.25596376, -0.25606286, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25662892,\n",
       "        -0.2565371 , -0.25437252, -0.25611177, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.256218  , -0.2563534 , -0.25606789,\n",
       "        -0.2554609 , -0.25618472, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621834, -0.25631163, -0.25567747, -0.25591848,\n",
       "        -0.2563351 , -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621834, -0.25668396, -0.25444203, -0.255699  , -0.25606706,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621802, -0.25709717,\n",
       "        -0.25622029, -0.2556541 , -0.255866  , -0.25652241, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621834, -0.25637435, -0.25557952,\n",
       "        -0.25618271, -0.25601776, -0.2571964 , -0.25670431, -0.26042429,\n",
       "        -0.25631865, -0.26051734, -0.25693998, -0.25621671, -0.25787726,\n",
       "        -0.25726711, -0.25623138, -0.25619073, -0.25646224, -0.25666643,\n",
       "        -0.25614204, -0.25628294, -0.25633813, -0.25629057, -0.25615198,\n",
       "        -0.2561652 , -0.25622387, -0.25678541, -0.2555009 , -0.2579576 ,\n",
       "        -0.2567807 , -0.25709789, -0.25750917, -0.25673913, -0.25786671,\n",
       "        -0.25656358, -0.2561713 , -0.25625355, -0.25625965, -0.25617225,\n",
       "        -0.25621198, -0.25617478, -0.25652998, -0.25682165, -0.25675056,\n",
       "        -0.25621273, -0.25632502, -0.25637126, -0.25647525, -0.25609517,\n",
       "        -0.25609261, -0.25629775, -0.25614744, -0.26591055, -0.25902164,\n",
       "        -0.25573307, -0.25594274, -0.26096127, -0.25614598, -0.2644093 ,\n",
       "        -0.25588715, -0.25591629, -0.25640751, -0.2560993 , -0.25625067,\n",
       "        -0.25640628, -0.25610773, -0.25632371, -0.25599866, -0.25623323,\n",
       "        -0.25658752, -0.25667736, -0.25634393, -0.2561946 , -0.25652296,\n",
       "        -0.25655028, -0.25650948, -0.25642889, -0.25612062, -0.25627976,\n",
       "        -0.25667333, -0.25621084, -0.25629008, -0.2560469 , -0.25620435,\n",
       "        -0.25603822, -0.25645076, -0.25626289, -0.25603727]),\n",
       " 'mean_test_neg_log_loss': array([-0.25621799, -0.25621799, -0.25621787, -0.25621736, -0.25629169,\n",
       "        -0.25639686, -0.25627832, -0.25596771, -0.25451921, -0.25621791,\n",
       "        -0.25621861, -0.25621362, -0.25635228, -0.25632982, -0.25631868,\n",
       "        -0.25649763, -0.25576616, -0.24919799, -0.25620866, -0.25621834,\n",
       "        -0.25642444, -0.25626449, -0.25628165, -0.2568227 , -0.25627072,\n",
       "        -0.25622166, -0.24833631, -0.25633063, -0.25631273, -0.25609715,\n",
       "        -0.25631311, -0.25621566, -0.25626547, -0.25549245, -0.25519352,\n",
       "        -0.24829567, -0.25612912, -0.2565127 , -0.2560957 , -0.25675102,\n",
       "        -0.25616679, -0.25648488, -0.25536417, -0.25435999, -0.24784922,\n",
       "        -0.25637461, -0.2567513 , -0.25637067, -0.25619386, -0.25664819,\n",
       "        -0.2557465 , -0.25543363, -0.25545866, -0.24769709, -0.25847666,\n",
       "        -0.25605341, -0.2562683 , -0.25642624, -0.25677237, -0.25499488,\n",
       "        -0.25547624, -0.26357558, -0.24882322, -0.25762185, -0.25669754,\n",
       "        -0.25682715, -0.25626211, -0.25692595, -0.25675059, -0.30760135,\n",
       "        -0.25593013, -0.2485903 , -0.25848263, -0.25620528, -0.25709149,\n",
       "        -0.25616621, -0.25608036, -0.26650732, -0.25616637, -0.25621655,\n",
       "        -0.24785544, -0.25621799, -0.25621799, -0.2562181 , -0.25621836,\n",
       "        -0.25625292, -0.25617694, -0.25629288, -0.25700294, -0.25563619,\n",
       "        -0.25621799, -0.2562182 , -0.25622341, -0.25620449, -0.25607486,\n",
       "        -0.25609752, -0.2563517 , -0.5029407 , -0.25723469, -0.25621796,\n",
       "        -0.25621202, -0.25622501, -0.25617172, -0.25616633, -0.25618066,\n",
       "        -0.25670621, -0.25613363, -0.2570998 , -0.25622096, -0.25621315,\n",
       "        -0.2562133 , -0.25622913, -0.25631394, -0.25688652, -0.25647286,\n",
       "        -0.25647472, -0.25648167, -0.25625555, -0.25631951, -0.2563123 ,\n",
       "        -0.25629212, -0.25619526, -0.25627405, -0.66557181, -0.25624625,\n",
       "        -0.25890043, -0.25623829, -0.25615116, -0.25644232, -0.25636117,\n",
       "        -0.2563035 , -0.25684103, -0.27578137, -0.25610393, -0.25716661,\n",
       "        -0.25616673, -0.25626157, -0.25654033, -0.25637155, -0.25622243,\n",
       "        -0.25659518, -0.3423398 , -0.25617853, -0.25607539, -0.25634059,\n",
       "        -0.25632835, -0.25622484, -0.25614558, -0.25628822, -0.25564876,\n",
       "        -0.35024569, -0.25582512, -0.25640846, -0.25655084, -0.25649189,\n",
       "        -0.25641249, -0.25642226, -0.25628844, -0.25778986, -0.26349619,\n",
       "        -0.25616276, -0.25762987, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25683858, -0.25693569,\n",
       "        -0.25501218, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25695633, -0.25632409, -0.25490361,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25623891, -0.25667756, -0.25567646, -0.25547431, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621799, -0.25692291,\n",
       "        -0.25686646, -0.25440203, -0.25588493, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621798, -0.25657367, -0.25619876,\n",
       "        -0.25513374, -0.25593693, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25621799, -0.25621827, -0.25694434, -0.25595071, -0.2551549 ,\n",
       "        -0.25606907, -0.25621799, -0.25621799, -0.25621799, -0.25621799,\n",
       "        -0.25684022, -0.25699384, -0.25493544, -0.25640046, -0.25595369,\n",
       "        -0.25621799, -0.25621799, -0.25621799, -0.25621801, -0.25691016,\n",
       "        -0.25652861, -0.25539237, -0.25592738, -0.25595788, -0.25621799,\n",
       "        -0.25621799, -0.25621799, -0.25621834, -0.2566623 , -0.25529168,\n",
       "        -0.25542789, -0.25656538, -0.2563962 , -0.25626946, -0.2572578 ,\n",
       "        -0.25625359, -0.25703955, -0.25646369, -0.2561788 , -0.25664353,\n",
       "        -0.25646534, -0.25605634, -0.25645707, -0.25628273, -0.256796  ,\n",
       "        -0.25710549, -0.25617323, -0.25625405, -0.25633861, -0.25633244,\n",
       "        -0.25632331, -0.25659293, -0.25604348, -0.25624674, -0.25673543,\n",
       "        -0.25653818, -0.25607024, -0.25646592, -0.25658934, -0.25594608,\n",
       "        -0.25627996, -0.25659261, -0.25629744, -0.25623838, -0.25602532,\n",
       "        -0.2560633 , -0.25632621, -0.25647381, -0.25670866, -0.25641958,\n",
       "        -0.25629259, -0.2565043 , -0.25628982, -0.25627242, -0.25622623,\n",
       "        -0.25621653, -0.2564579 , -0.25647769, -0.2590328 , -0.25728513,\n",
       "        -0.25660771, -0.26062485, -0.25919014, -0.25751232, -0.25857545,\n",
       "        -0.25633756, -0.2570707 , -0.2562791 , -0.25617106, -0.25660005,\n",
       "        -0.25628105, -0.25610936, -0.25642082, -0.25633139, -0.25612983,\n",
       "        -0.25684335, -0.25649708, -0.25608561, -0.25634392, -0.25634669,\n",
       "        -0.25630319, -0.25617679, -0.25635813, -0.25605329, -0.25637508,\n",
       "        -0.25635249, -0.25638338, -0.25665775, -0.25627949, -0.25613282,\n",
       "        -0.25596991, -0.25620314, -0.25629409, -0.25620093]),\n",
       " 'std_test_neg_log_loss': array([7.27571006e-10, 2.80500511e-09, 2.65257220e-07, 1.95926023e-06,\n",
       "        1.40800121e-04, 1.24737319e-04, 2.46994059e-04, 2.04012813e-04,\n",
       "        1.11792425e-03, 1.55752571e-07, 1.74499637e-06, 5.92358133e-06,\n",
       "        1.36504351e-04, 1.13179710e-04, 7.23967223e-05, 4.88788837e-04,\n",
       "        5.52689125e-04, 3.61182233e-03, 1.88609981e-05, 2.48253415e-17,\n",
       "        4.19397637e-04, 1.41470083e-04, 1.11323440e-04, 4.25532508e-04,\n",
       "        2.55656505e-04, 1.06051178e-03, 3.74474376e-03, 3.26527192e-04,\n",
       "        1.78703910e-04, 4.32750058e-04, 1.44140352e-04, 1.48225315e-04,\n",
       "        7.53524902e-05, 8.28694142e-04, 7.44038267e-04, 3.84720698e-03,\n",
       "        1.61407578e-04, 4.06753573e-04, 4.04977847e-04, 5.82419689e-04,\n",
       "        3.81973125e-04, 9.42095952e-04, 1.00074248e-03, 8.20661694e-04,\n",
       "        4.15143344e-03, 2.58473246e-04, 6.79379716e-04, 3.26955578e-04,\n",
       "        1.16921927e-04, 2.81535260e-04, 7.08265123e-04, 5.73481674e-04,\n",
       "        1.75901206e-03, 3.35017544e-03, 1.79405632e-03, 5.10434851e-04,\n",
       "        4.54312433e-04, 2.81986407e-04, 8.43525322e-04, 8.96380689e-04,\n",
       "        8.03321870e-04, 7.59650109e-03, 2.99216272e-03, 1.28824031e-03,\n",
       "        7.35828583e-04, 9.80502192e-04, 4.23957711e-04, 7.69111711e-04,\n",
       "        2.14746761e-03, 5.65828144e-02, 4.76453436e-04, 3.48457710e-03,\n",
       "        1.21189531e-03, 1.32618694e-04, 7.68007751e-04, 3.34585101e-04,\n",
       "        6.81973893e-04, 1.22705842e-02, 4.18345348e-05, 6.23832973e-04,\n",
       "        3.85171268e-03, 1.00404531e-11, 8.55423674e-10, 1.57007651e-07,\n",
       "        5.11693101e-08, 8.58844157e-05, 9.19732476e-05, 1.83450069e-04,\n",
       "        1.22409809e-03, 7.33953799e-04, 2.16785847e-09, 3.68314034e-07,\n",
       "        1.43301886e-05, 1.96050413e-04, 2.07809830e-04, 1.85023605e-04,\n",
       "        1.92365019e-04, 2.09129268e-01, 1.31154755e-03, 4.51744485e-08,\n",
       "        1.26266454e-05, 1.04562777e-04, 1.97703560e-04, 1.28549029e-04,\n",
       "        1.95737735e-04, 8.98745205e-04, 3.32070744e-03, 1.22301694e-03,\n",
       "        5.24141669e-06, 1.90563959e-04, 9.17407251e-05, 1.94174852e-04,\n",
       "        1.46025328e-04, 1.24157553e-03, 3.46042886e-04, 3.50403429e-03,\n",
       "        1.45931340e-03, 2.20479909e-04, 1.36353110e-04, 1.10981520e-04,\n",
       "        3.69901572e-04, 5.78623727e-04, 1.27128136e-04, 3.51705517e-01,\n",
       "        2.81271204e-03, 4.93865459e-04, 1.22626137e-04, 1.11172050e-04,\n",
       "        2.25187909e-04, 1.52397323e-04, 3.35969067e-04, 3.56845199e-04,\n",
       "        1.06678165e-02, 3.37752133e-03, 1.73887824e-03, 1.76041157e-04,\n",
       "        6.62151821e-05, 5.42184207e-04, 3.82406152e-04, 1.13519149e-04,\n",
       "        1.05089173e-03, 3.95586835e-02, 3.35331451e-03, 1.29138908e-03,\n",
       "        2.85694282e-04, 1.33641470e-04, 1.28020870e-04, 5.28228292e-05,\n",
       "        3.51820377e-04, 1.04184193e-03, 4.74923055e-02, 3.24014238e-03,\n",
       "        1.48264652e-03, 4.22110305e-04, 3.40624900e-04, 4.18043269e-04,\n",
       "        3.65928438e-04, 1.98129176e-04, 3.65400491e-03, 7.00725949e-03,\n",
       "        3.35723128e-03, 1.07480225e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.67787082e-14, 2.32431759e-14, 8.85470130e-10,\n",
       "        1.52448747e-04, 2.64783684e-04, 7.93421674e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00459848e-14, 2.78496519e-14,\n",
       "        1.81340926e-08, 1.78952733e-04, 1.59213642e-04, 1.23659135e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.86216271e-14, 2.97193349e-14,\n",
       "        5.74726220e-12, 4.11357876e-05, 1.39813595e-04, 4.55060520e-04,\n",
       "        1.25027684e-03, 0.00000000e+00, 0.00000000e+00, 1.00109248e-14,\n",
       "        3.56016518e-15, 1.24879435e-09, 5.96873023e-04, 2.56274222e-04,\n",
       "        1.11303804e-03, 5.26167547e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        9.16815021e-15, 2.86694971e-14, 1.61088315e-08, 1.93116120e-04,\n",
       "        1.30267112e-04, 3.72425208e-04, 7.72775330e-04, 0.00000000e+00,\n",
       "        3.50541031e-14, 3.72147437e-14, 9.44469846e-12, 1.40507289e-07,\n",
       "        3.19382038e-04, 1.01260009e-03, 1.16725908e-03, 5.71556683e-04,\n",
       "        0.00000000e+00, 2.46590756e-14, 1.95946973e-14, 3.03450029e-10,\n",
       "        4.79913937e-04, 3.60159893e-04, 1.43449449e-03, 7.15076355e-04,\n",
       "        3.18146509e-04, 0.00000000e+00, 1.90334616e-14, 3.92787272e-14,\n",
       "        3.56593331e-08, 2.99416408e-04, 5.88907575e-04, 8.13380976e-04,\n",
       "        3.67249576e-04, 5.99537879e-04, 0.00000000e+00, 1.20857618e-11,\n",
       "        9.65807210e-12, 2.48253415e-17, 3.08031285e-04, 7.95670730e-04,\n",
       "        7.79423477e-04, 5.45648734e-04, 5.33537796e-04, 3.94652697e-04,\n",
       "        1.63454068e-03, 2.57229949e-04, 1.74647404e-03, 3.50624726e-04,\n",
       "        2.68903121e-04, 6.34431693e-04, 4.67393693e-04, 2.33070454e-04,\n",
       "        4.95939115e-04, 2.75556892e-04, 8.33583733e-04, 1.14349786e-03,\n",
       "        2.07583946e-04, 1.11575096e-04, 3.01298595e-04, 2.73732747e-04,\n",
       "        2.57452549e-04, 4.28391210e-04, 7.50227489e-04, 6.10858572e-04,\n",
       "        8.01302843e-04, 2.26382970e-04, 6.24955205e-04, 5.63789100e-04,\n",
       "        2.03193210e-04, 1.19319017e-03, 2.00304894e-04, 6.28549835e-04,\n",
       "        2.57840460e-04, 5.19567854e-04, 3.83925097e-04, 3.52941746e-04,\n",
       "        3.56437966e-04, 6.15014703e-04, 5.58822580e-04, 4.03965314e-04,\n",
       "        1.11907409e-04, 3.52341130e-04, 5.46698203e-04, 1.40593993e-04,\n",
       "        7.36333862e-05, 2.49082501e-04, 4.35746364e-04, 5.20607091e-04,\n",
       "        3.69705051e-03, 1.55787269e-03, 1.28068368e-03, 9.80709829e-03,\n",
       "        3.54271803e-03, 3.10256401e-03, 3.02067292e-03, 1.70078989e-03,\n",
       "        2.76158626e-03, 3.20622263e-04, 3.01240282e-04, 7.99005911e-04,\n",
       "        1.87870035e-04, 2.57419618e-04, 2.59214160e-04, 3.24569783e-04,\n",
       "        1.96474769e-04, 4.89800511e-04, 4.34832957e-04, 3.13503899e-04,\n",
       "        2.49045069e-04, 2.28009488e-04, 1.76585910e-04, 3.69783870e-04,\n",
       "        8.02938867e-05, 2.20570249e-04, 2.73606724e-04, 2.30692893e-04,\n",
       "        2.23930145e-04, 5.43862283e-04, 1.57014364e-04, 2.20844000e-04,\n",
       "        3.03778115e-04, 1.60099362e-04, 2.04827136e-04, 3.06624870e-04]),\n",
       " 'rank_test_neg_log_loss': array([104, 102,  97,  96, 190, 228, 180,  42,  11,  98, 153,  92, 218,\n",
       "        208, 202, 251,  32,   8,  88, 150, 235, 173, 185, 280, 177, 155,\n",
       "          5, 209, 199,  57, 200,  93, 174,  27,  18,   4,  61, 253,  56,\n",
       "        276,  72, 248,  20,   9,   2, 224, 277, 222,  81, 267,  31,  23,\n",
       "         24,   1, 309,  47, 175, 236, 278,  14,  26, 317,   7, 306, 271,\n",
       "        281, 172, 290, 275, 320,  36,   6, 310,  87, 298,  68,  54, 318,\n",
       "         70,  95,   3, 105, 143, 147, 152, 167,  77, 193, 295,  28, 101,\n",
       "        148, 157,  86,  52,  58, 217, 323, 302,  99,  89, 159,  74,  69,\n",
       "         80, 272,  64, 299, 154,  90,  91, 161, 201, 287, 243, 245, 247,\n",
       "        170, 203, 198, 191,  82, 179, 324, 165, 312, 162,  66, 237, 221,\n",
       "        197, 284, 319,  59, 301,  71, 171, 256, 223, 156, 263, 321,  78,\n",
       "         53, 214, 207, 158,  65, 187,  29, 322,  33, 230, 257, 249, 231,\n",
       "        234, 188, 308, 316,  67, 307, 125, 125, 125, 121, 122, 144, 282,\n",
       "        291,  15, 125, 125, 125, 111, 112, 145, 293, 205,  12, 125, 125,\n",
       "        118, 109, 140, 164, 270,  30,  25, 125, 125, 117, 114, 103, 289,\n",
       "        286,  10,  34, 125, 125, 115, 116, 100, 259,  83,  16,  37, 125,\n",
       "        124, 119, 107, 149, 292,  39,  17,  50, 125, 123, 108, 142, 283,\n",
       "        294,  13, 229,  40, 125, 110, 120, 146, 288, 254,  21,  35,  41,\n",
       "        113, 141, 106, 150, 269,  19,  22, 258, 227, 176, 303, 168, 296,\n",
       "        240,  79, 266, 241,  48, 238, 186, 279, 300,  75, 169, 213, 211,\n",
       "        204, 262,  45, 166, 274, 255,  51, 242, 260,  38, 183, 261, 195,\n",
       "        163,  44,  49, 206, 244, 273, 232, 192, 252, 189, 178, 160,  94,\n",
       "        239, 246, 313, 304, 265, 315, 314, 305, 311, 212, 297, 181,  73,\n",
       "        264, 184,  60, 233, 210,  62, 285, 250,  55, 215, 216, 196,  76,\n",
       "        220,  46, 225, 219, 226, 268, 182,  63,  43,  85, 194,  84])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIAL_2_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL TWO NEG LOG LOSS RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 100,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL TWO NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_2_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL TWO F1 RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL TWO F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_2_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL TWO ROC AUC RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 100,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL TWO ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_2_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 2 svm using best NEG LOG LOSS hyperparameters :0.88845\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 2 svm using best F1 hyperparameters :0.93125\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 2 svm using best ROC_AUC hyperparameters :0.88845\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 2 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 2 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 2 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL THREE ON POKER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL THREE RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = pokerData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_3_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL THREE RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.44318109, 0.44868493, 0.47250614, 0.43557396, 0.42116179,\n",
       "        0.4294693 , 0.44758525, 0.48751907, 0.56288409, 0.44868593,\n",
       "        0.43267207, 0.44838557, 0.43957825, 0.43587465, 0.43907766,\n",
       "        0.46329846, 0.70630713, 1.98430681, 0.43687549, 0.42706718,\n",
       "        0.43557467, 0.42886863, 0.43354287, 0.46600084, 0.64485502,\n",
       "        1.73699417, 3.32786169, 0.50553498, 0.49682755, 0.52895432,\n",
       "        0.48291507, 0.45859413, 0.58069925, 1.41631784, 1.64211206,\n",
       "        3.5151228 , 0.49602652, 0.45358987, 0.45168839, 0.4650001 ,\n",
       "        0.53636141, 0.94731483, 2.1688653 , 1.74700241, 3.67686238,\n",
       "        0.49932947, 0.48811936, 0.46219697, 0.44948664, 1.22685499,\n",
       "        1.69896126, 2.39936395, 2.41587744, 3.63212342, 0.50913806,\n",
       "        0.57359319, 0.93400311, 2.00359025, 2.08128986, 2.32820234,\n",
       "        2.9614471 , 2.4317915 , 3.58648434, 0.68258686, 0.81950455,\n",
       "        1.35866904, 1.96909332, 2.29577427, 3.10987439, 3.20946021,\n",
       "        2.38875446, 3.65063939, 0.70160332, 0.88426061, 1.33294635,\n",
       "        2.13883929, 3.13669724, 3.2768177 , 3.188342  , 2.36213174,\n",
       "        3.55495682, 0.50203152, 0.48481679, 0.48131366, 0.49462533,\n",
       "        0.48261523, 0.48231478, 0.48291535, 0.66687336, 1.23896508,\n",
       "        0.48731923, 0.47480841, 0.47490835, 0.47767334, 0.46822505,\n",
       "        0.47400818, 0.47510862, 0.76345615, 1.24527078, 0.48351588,\n",
       "        0.47310696, 0.46269784, 0.48902049, 0.49232354, 0.47931218,\n",
       "        0.49092197, 0.7998878 , 1.25377841, 0.47110496, 0.47120552,\n",
       "        0.46249771, 0.47370753, 0.48451691, 0.48401623, 2.00592523,\n",
       "        0.80259056, 1.22355266, 0.50173154, 0.48381581, 0.52655296,\n",
       "        0.57859764, 0.52134848, 0.55267549, 2.100106  , 0.72622466,\n",
       "        1.33875122, 0.52324986, 0.52715325, 0.51284122, 0.54296689,\n",
       "        0.51944675, 0.51414232, 2.15595384, 0.71371341, 1.28230267,\n",
       "        0.54401803, 0.54171209, 0.49314137, 0.5051342 , 0.48852024,\n",
       "        1.9813036 , 2.44330111, 0.62814002, 1.13007178, 0.47450809,\n",
       "        0.47751074, 0.47520871, 0.49712729, 0.59707012, 2.59763384,\n",
       "        2.17326918, 0.68999372, 1.14138179, 0.48912034, 0.47931175,\n",
       "        0.48751903, 0.5784976 , 1.51720476, 2.69311628, 2.14144149,\n",
       "        0.66517191, 1.16910563, 0.28944874, 0.29955807, 0.31116805,\n",
       "        0.31346951, 0.31617208, 0.31427045, 0.32578034, 0.34919982,\n",
       "        0.70700798, 0.3039618 , 0.30976648, 0.31116772, 0.31537156,\n",
       "        0.31917462, 0.31917415, 0.31336985, 0.42706723, 0.98574781,\n",
       "        0.31387014, 0.31787329, 0.31867404, 0.30706401, 0.31557126,\n",
       "        0.30182686, 0.31547146, 0.55787969, 2.35652647, 0.30015917,\n",
       "        0.31447053, 0.31326942, 0.31607194, 0.33228583, 0.31236849,\n",
       "        0.33799081, 0.70200324, 2.32129598, 0.31016679, 0.29915719,\n",
       "        0.30736551, 0.31537108, 0.33158526, 0.33679032, 0.46630101,\n",
       "        1.00166135, 2.29451418, 0.32177672, 0.327882  , 0.31376972,\n",
       "        0.30726466, 0.30976648, 0.3112679 , 0.55868049, 2.31048708,\n",
       "        2.32069635, 0.29955759, 0.30866556, 0.30686412, 0.31817374,\n",
       "        0.31547136, 0.34940085, 0.80208983, 2.35412488, 2.31549139,\n",
       "        0.32578001, 0.31406989, 0.33148484, 0.31316915, 0.30396171,\n",
       "        0.41735878, 0.98614807, 2.30728388, 2.28616557, 0.31136761,\n",
       "        0.31026683, 0.31286898, 0.31917458, 0.33498802, 0.57759686,\n",
       "        2.52717328, 2.54268656, 2.54518833, 0.32417922, 0.27043247,\n",
       "        0.30145936, 0.27703834, 0.29305234, 0.27313542, 0.26612973,\n",
       "        0.26432757, 0.26342635, 0.26712976, 0.26212549, 0.26552811,\n",
       "        0.26602898, 0.25271769, 0.25071568, 0.25151649, 0.25632057,\n",
       "        0.25491934, 0.25541978, 0.25041556, 0.24971485, 0.26372733,\n",
       "        0.25441871, 0.25051537, 0.24971476, 0.24951463, 0.25131598,\n",
       "        0.31577172, 0.30846505, 0.30986633, 0.31236844, 0.3169724 ,\n",
       "        0.31376972, 0.31417065, 0.30856562, 0.31577144, 1.02848434,\n",
       "        0.99925923, 1.01677418, 1.04880176, 1.06111236, 1.0490026 ,\n",
       "        1.04830122, 1.03949337, 1.08673449, 2.10030608, 2.06167293,\n",
       "        2.09950542, 2.17887397, 2.19608836, 2.12612839, 2.11882238,\n",
       "        1.95498075, 1.94477253, 1.96819363, 2.0562685 , 2.03815293,\n",
       "        2.19188499, 2.20019207, 2.10571074, 2.15084929, 1.96909337,\n",
       "        1.9454761 , 1.96128669, 1.94467244, 1.93526435, 1.96889286,\n",
       "        1.9653903 , 1.9582839 , 1.9911128 , 1.97529864, 1.92115197,\n",
       "        1.94647427, 1.94527292, 2.00222192, 2.1365375 , 2.10991445,\n",
       "        2.01253052, 1.89993372, 1.8579978 , 1.42172265]),\n",
       " 'std_fit_time': array([0.01098483, 0.01132626, 0.01695116, 0.0171393 , 0.00797942,\n",
       "        0.00998541, 0.02265654, 0.03206407, 0.037862  , 0.03541092,\n",
       "        0.00627118, 0.01199786, 0.0060928 , 0.0186171 , 0.0099463 ,\n",
       "        0.01348916, 0.00393517, 0.05918266, 0.00855139, 0.00398582,\n",
       "        0.00717277, 0.00430478, 0.00882606, 0.04983799, 0.06866331,\n",
       "        0.22675376, 0.11093665, 0.0535722 , 0.01478603, 0.07019763,\n",
       "        0.038088  , 0.02711139, 0.042202  , 0.08132353, 0.04975946,\n",
       "        0.09952986, 0.06263135, 0.01481348, 0.01499155, 0.02066093,\n",
       "        0.03656267, 0.07589501, 0.08288627, 0.05700662, 0.10584682,\n",
       "        0.03811336, 0.02262645, 0.01932123, 0.01505748, 0.04967609,\n",
       "        0.07104923, 0.08013828, 0.07378572, 0.076175  , 0.01778455,\n",
       "        0.01678419, 0.02629359, 0.06548593, 0.05668538, 0.09158881,\n",
       "        0.09331342, 0.01307506, 0.0503341 , 0.0111181 , 0.01675831,\n",
       "        0.05277525, 0.03515636, 0.05481627, 0.07705235, 0.16425897,\n",
       "        0.08069337, 0.08917442, 0.01544043, 0.01737237, 0.03988141,\n",
       "        0.04156883, 0.07657894, 0.11562178, 0.09935939, 0.02813181,\n",
       "        0.06623238, 0.02227728, 0.0149739 , 0.00853026, 0.01413536,\n",
       "        0.01328033, 0.00612425, 0.01098664, 0.01636221, 0.02569793,\n",
       "        0.01199542, 0.01733947, 0.01152087, 0.00742169, 0.00757427,\n",
       "        0.00736456, 0.01020973, 0.01936243, 0.04220944, 0.01531803,\n",
       "        0.0076261 , 0.00926306, 0.02803028, 0.01952182, 0.01727595,\n",
       "        0.02177155, 0.02259941, 0.02568672, 0.0083289 , 0.01114851,\n",
       "        0.01025804, 0.00922005, 0.00994567, 0.013819  , 0.07622211,\n",
       "        0.01432804, 0.03293563, 0.01800888, 0.01392019, 0.05149361,\n",
       "        0.05671225, 0.02215395, 0.01864593, 0.09055632, 0.06654594,\n",
       "        0.08550856, 0.05208001, 0.04342484, 0.02017031, 0.01603577,\n",
       "        0.02470346, 0.01933926, 0.0722399 , 0.02959208, 0.03472092,\n",
       "        0.07319278, 0.07205203, 0.01385312, 0.0214067 , 0.01157456,\n",
       "        0.06641552, 0.02867344, 0.01552893, 0.03353614, 0.00839412,\n",
       "        0.00541219, 0.00623918, 0.01930559, 0.01822981, 0.06476399,\n",
       "        0.04925578, 0.01468023, 0.02880389, 0.01868873, 0.01003071,\n",
       "        0.00869316, 0.01159013, 0.04809474, 0.05661693, 0.03494895,\n",
       "        0.02509218, 0.02989449, 0.00546927, 0.00652113, 0.00707338,\n",
       "        0.00853148, 0.0089037 , 0.0125009 , 0.01517868, 0.01879234,\n",
       "        0.01266927, 0.00373954, 0.00779747, 0.00979329, 0.0055766 ,\n",
       "        0.00549472, 0.00573554, 0.00598332, 0.00894987, 0.0192996 ,\n",
       "        0.00943394, 0.01970266, 0.0100707 , 0.0069024 , 0.01149718,\n",
       "        0.00437128, 0.0081103 , 0.01402088, 0.04008308, 0.00936573,\n",
       "        0.00780805, 0.0134093 , 0.01294437, 0.01154685, 0.00791522,\n",
       "        0.00304612, 0.01556479, 0.03898674, 0.01483328, 0.00840603,\n",
       "        0.010169  , 0.01397798, 0.02324429, 0.03506121, 0.02658313,\n",
       "        0.02678988, 0.03964072, 0.01663057, 0.00935933, 0.00750988,\n",
       "        0.00697035, 0.01038185, 0.00473659, 0.01992352, 0.03671797,\n",
       "        0.0727335 , 0.00668846, 0.00348704, 0.00467713, 0.01757758,\n",
       "        0.00851914, 0.01953971, 0.06078965, 0.03444354, 0.0556068 ,\n",
       "        0.01167204, 0.01858078, 0.01853255, 0.01278746, 0.00478539,\n",
       "        0.01509628, 0.03379529, 0.05463525, 0.0699786 , 0.00981392,\n",
       "        0.0083798 , 0.01535411, 0.02490806, 0.01792214, 0.02367034,\n",
       "        0.06624015, 0.09746795, 0.12843939, 0.03489699, 0.0211783 ,\n",
       "        0.0234054 , 0.01557153, 0.02670373, 0.0163767 , 0.01017506,\n",
       "        0.01030682, 0.01685944, 0.01191541, 0.00589053, 0.01067486,\n",
       "        0.01034162, 0.00706972, 0.00973983, 0.00774343, 0.00964376,\n",
       "        0.01308691, 0.00619082, 0.00510939, 0.00697741, 0.02079366,\n",
       "        0.00886502, 0.00156993, 0.00676607, 0.0077886 , 0.00647401,\n",
       "        0.00660874, 0.00163246, 0.00574377, 0.0084889 , 0.00521595,\n",
       "        0.005024  , 0.00819491, 0.00615854, 0.00969324, 0.02406693,\n",
       "        0.01528552, 0.02545298, 0.02460847, 0.0288317 , 0.03220135,\n",
       "        0.0295239 , 0.04312439, 0.04390305, 0.07016365, 0.02819772,\n",
       "        0.04169938, 0.06430552, 0.0769522 , 0.07221097, 0.1029499 ,\n",
       "        0.01861322, 0.02864887, 0.04444158, 0.09279533, 0.02835711,\n",
       "        0.10298853, 0.09432569, 0.08913287, 0.07867596, 0.05597792,\n",
       "        0.01930497, 0.03180538, 0.04589475, 0.03891464, 0.03841618,\n",
       "        0.02696529, 0.012928  , 0.03208944, 0.0307663 , 0.06812333,\n",
       "        0.03556296, 0.05031421, 0.07488611, 0.08569135, 0.11188742,\n",
       "        0.06239899, 0.01547476, 0.0698736 , 0.14855565]),\n",
       " 'mean_score_time': array([0.03893375, 0.03953428, 0.03993416, 0.04203625, 0.04033508,\n",
       "        0.04103537, 0.043537  , 0.04233651, 0.04483833, 0.03923354,\n",
       "        0.0428371 , 0.03923411, 0.04143562, 0.04013476, 0.0400342 ,\n",
       "        0.0403348 , 0.05424705, 0.16484218, 0.0424366 , 0.04083524,\n",
       "        0.04093518, 0.04073505, 0.03963399, 0.04794116, 0.054247  ,\n",
       "        0.08297148, 0.2130837 , 0.04513903, 0.04293647, 0.04383798,\n",
       "        0.04143577, 0.04283714, 0.05614839, 0.06885929, 0.07516489,\n",
       "        0.21118183, 0.04173584, 0.04143567, 0.04133554, 0.04964285,\n",
       "        0.05754943, 0.07306266, 0.074264  , 0.0814702 , 0.21738753,\n",
       "        0.04303727, 0.04253659, 0.04073486, 0.04273682, 0.07676587,\n",
       "        0.10158753, 0.09077725, 0.09688354, 0.20257425, 0.04523873,\n",
       "        0.04894218, 0.04874172, 0.06168547, 0.08427258, 0.09648299,\n",
       "        0.15893664, 0.09247975, 0.20237374, 0.04263678, 0.04133573,\n",
       "        0.04423757, 0.06655784, 0.09928546, 0.17414999, 0.16374059,\n",
       "        0.09338007, 0.20667796, 0.04744091, 0.04103532, 0.04543967,\n",
       "        0.0684588 , 0.17785301, 0.17795291, 0.17124791, 0.08977718,\n",
       "        0.20257411, 0.04834132, 0.04483857, 0.04403796, 0.04664049,\n",
       "        0.0434371 , 0.04533901, 0.04483862, 0.04363756, 0.06665754,\n",
       "        0.04764099, 0.0454391 , 0.04583936, 0.04423809, 0.04273481,\n",
       "        0.04456859, 0.04323707, 0.04303708, 0.0704608 , 0.04443803,\n",
       "        0.04313707, 0.04553938, 0.04313712, 0.04483857, 0.04393749,\n",
       "        0.04233627, 0.04323721, 0.06715775, 0.04433827, 0.04263639,\n",
       "        0.04443774, 0.04447622, 0.04613981, 0.04493861, 0.05514755,\n",
       "        0.04513917, 0.06515565, 0.04503875, 0.04994302, 0.04924231,\n",
       "        0.0466403 , 0.0543467 , 0.05754976, 0.05875082, 0.04343729,\n",
       "        0.0776669 , 0.0506556 , 0.04914227, 0.04523897, 0.04543934,\n",
       "        0.04814115, 0.05094399, 0.04886923, 0.04623957, 0.07456431,\n",
       "        0.0469902 , 0.04601483, 0.04492116, 0.04633999, 0.045439  ,\n",
       "        0.06135297, 0.04613972, 0.04373765, 0.0671577 , 0.04573936,\n",
       "        0.04573913, 0.04283662, 0.04403801, 0.05639215, 0.08747516,\n",
       "        0.04674053, 0.04523854, 0.06955972, 0.04684038, 0.04353743,\n",
       "        0.04583964, 0.0555479 , 0.09037771, 0.08317156, 0.04573946,\n",
       "        0.04133582, 0.06355462, 0.02652307, 0.02792344, 0.02682276,\n",
       "        0.02712355, 0.02882514, 0.02802401, 0.02772374, 0.02902522,\n",
       "        0.04103546, 0.02702246, 0.02732339, 0.02712326, 0.02822399,\n",
       "        0.02682366, 0.02742381, 0.02952528, 0.03583097, 0.04644012,\n",
       "        0.02752333, 0.02612252, 0.02832451, 0.02732377, 0.02735243,\n",
       "        0.02822437, 0.02862468, 0.04053483, 0.04433851, 0.02912421,\n",
       "        0.02662296, 0.02582216, 0.02712345, 0.02902493, 0.02852473,\n",
       "        0.02822404, 0.03863373, 0.04343739, 0.02672281, 0.02662287,\n",
       "        0.02812328, 0.02842455, 0.02982564, 0.02882452, 0.03182721,\n",
       "        0.04573951, 0.04369674, 0.02902479, 0.02922516, 0.02612267,\n",
       "        0.02672238, 0.02802448, 0.02812428, 0.03813295, 0.04233637,\n",
       "        0.05184441, 0.02902493, 0.0272233 , 0.02792401, 0.02702308,\n",
       "        0.02652278, 0.02932568, 0.044138  , 0.04423809, 0.04243631,\n",
       "        0.02632294, 0.02872491, 0.02752371, 0.02832479, 0.02782369,\n",
       "        0.03192749, 0.04553924, 0.0423367 , 0.04774132, 0.02632256,\n",
       "        0.02782378, 0.02702336, 0.03122673, 0.02732391, 0.04033456,\n",
       "        0.05174437, 0.05504732, 0.05194468, 0.02502108, 0.02131848,\n",
       "        0.02542176, 0.02582221, 0.02412052, 0.02291932, 0.02492108,\n",
       "        0.02241921, 0.02712345, 0.02532196, 0.02191887, 0.02271986,\n",
       "        0.02171865, 0.02161827, 0.02442102, 0.02352004, 0.02201886,\n",
       "        0.02221909, 0.02281966, 0.02221904, 0.02191892, 0.02281928,\n",
       "        0.02131815, 0.02532196, 0.02211895, 0.02502165, 0.02311983,\n",
       "        0.02832422, 0.02582245, 0.02532172, 0.02672329, 0.0267231 ,\n",
       "        0.02552209, 0.02662334, 0.02982545, 0.02942543, 0.04193606,\n",
       "        0.04023457, 0.03773274, 0.039534  , 0.03903384, 0.03793249,\n",
       "        0.03673158, 0.03693194, 0.03973422, 0.03753262, 0.04523902,\n",
       "        0.03823285, 0.0429368 , 0.03883362, 0.03803296, 0.03513131,\n",
       "        0.03553061, 0.03673158, 0.03783183, 0.05124397, 0.04473858,\n",
       "        0.04273667, 0.03963447, 0.03573041, 0.03623118, 0.03553052,\n",
       "        0.03672862, 0.03893361, 0.03553057, 0.03686209, 0.0365314 ,\n",
       "        0.03923354, 0.03693209, 0.03573027, 0.03613129, 0.03783245,\n",
       "        0.03793263, 0.04633975, 0.04704051, 0.0387331 , 0.03903351,\n",
       "        0.03603129, 0.0305263 , 0.02211938, 0.02061772]),\n",
       " 'std_score_time': array([0.00086093, 0.00243097, 0.00182915, 0.00581881, 0.00222915,\n",
       "        0.0025908 , 0.00438616, 0.00418211, 0.00289369, 0.00092819,\n",
       "        0.00387089, 0.00103053, 0.00459096, 0.00198661, 0.00216987,\n",
       "        0.00051035, 0.00074886, 0.02980533, 0.00485602, 0.00120925,\n",
       "        0.00037452, 0.00136507, 0.00086087, 0.00964376, 0.00814049,\n",
       "        0.00646688, 0.01737219, 0.00201133, 0.00168702, 0.0038841 ,\n",
       "        0.00217916, 0.00216082, 0.00551297, 0.00394816, 0.0078194 ,\n",
       "        0.01492302, 0.00278797, 0.00139403, 0.00284144, 0.01000535,\n",
       "        0.00259063, 0.01097781, 0.00899986, 0.00815238, 0.01021057,\n",
       "        0.00288355, 0.00234736, 0.00183462, 0.00194062, 0.00307885,\n",
       "        0.02941394, 0.00621544, 0.01633797, 0.00307505, 0.00430065,\n",
       "        0.00835829, 0.00387124, 0.00379987, 0.00644448, 0.00210919,\n",
       "        0.00443822, 0.00377726, 0.00304576, 0.00305905, 0.00128957,\n",
       "        0.00384526, 0.00972948, 0.00304572, 0.01017269, 0.00614065,\n",
       "        0.00220632, 0.00925988, 0.00973157, 0.00089538, 0.00215637,\n",
       "        0.00297581, 0.01869132, 0.00347575, 0.01331351, 0.00120962,\n",
       "        0.00850066, 0.00553253, 0.00276995, 0.00137976, 0.00434461,\n",
       "        0.00086089, 0.00222876, 0.00294526, 0.00168643, 0.00097053,\n",
       "        0.00313939, 0.00566519, 0.00564947, 0.0036718 , 0.00077802,\n",
       "        0.00093137, 0.00128952, 0.00094962, 0.00442413, 0.00229092,\n",
       "        0.00102058, 0.00255165, 0.00182917, 0.00204102, 0.00278453,\n",
       "        0.0009806 , 0.00132766, 0.00323392, 0.00186164, 0.00135806,\n",
       "        0.00182876, 0.00201492, 0.00329516, 0.00210887, 0.01120533,\n",
       "        0.00414366, 0.0019865 , 0.00230419, 0.00629358, 0.0048371 ,\n",
       "        0.00540303, 0.00703876, 0.01291072, 0.00545083, 0.00171599,\n",
       "        0.00585612, 0.00913762, 0.0018563 , 0.0022067 , 0.00239792,\n",
       "        0.00524281, 0.00362772, 0.00264486, 0.00396044, 0.00647113,\n",
       "        0.00391643, 0.00351963, 0.00175781, 0.00309466, 0.00282021,\n",
       "        0.00125022, 0.0025788 , 0.00250411, 0.00394555, 0.00128952,\n",
       "        0.00356116, 0.00103056, 0.0010968 , 0.0028778 , 0.00208512,\n",
       "        0.00209009, 0.00407315, 0.00754339, 0.00403555, 0.00130521,\n",
       "        0.00277006, 0.00122577, 0.0065906 , 0.00369653, 0.00267799,\n",
       "        0.00186172, 0.00230415, 0.00114116, 0.00132074, 0.0011235 ,\n",
       "        0.00073538, 0.00177914, 0.00184555, 0.00191449, 0.00259048,\n",
       "        0.00364961, 0.00100095, 0.00194047, 0.00185646, 0.00312663,\n",
       "        0.00143628, 0.00135778, 0.00251222, 0.00401116, 0.00171591,\n",
       "        0.00158225, 0.00049033, 0.00092842, 0.00051043, 0.00162368,\n",
       "        0.00250439, 0.00213251, 0.00425826, 0.00296228, 0.00360033,\n",
       "        0.0003745 , 0.0007489 , 0.00168654, 0.00207544, 0.00234704,\n",
       "        0.00120946, 0.00156325, 0.00174494, 0.00067894, 0.00102081,\n",
       "        0.00222556, 0.00385565, 0.00320565, 0.00335848, 0.00218369,\n",
       "        0.00258257, 0.00133641, 0.00532414, 0.00304569, 0.00086086,\n",
       "        0.0012096 , 0.00031681, 0.00193559, 0.00315548, 0.00194071,\n",
       "        0.01657257, 0.003438  , 0.00194089, 0.00135737, 0.00179039,\n",
       "        0.00083714, 0.00222893, 0.00417969, 0.00387158, 0.00162626,\n",
       "        0.00107772, 0.00317467, 0.00122604, 0.00311071, 0.00120939,\n",
       "        0.00263652, 0.00249203, 0.0019915 , 0.00482699, 0.00244345,\n",
       "        0.00410984, 0.00228223, 0.00830527, 0.00211352, 0.00417051,\n",
       "        0.00369907, 0.01418274, 0.01032115, 0.00455376, 0.00143701,\n",
       "        0.00389432, 0.00510919, 0.0029753 , 0.00208498, 0.00337126,\n",
       "        0.00159482, 0.00612406, 0.00785935, 0.00159525, 0.00116712,\n",
       "        0.00092856, 0.00102057, 0.00222451, 0.00230402, 0.00094949,\n",
       "        0.00067823, 0.00107788, 0.00163242, 0.00106861, 0.00081257,\n",
       "        0.00067882, 0.00408491, 0.00080068, 0.00305204, 0.00274812,\n",
       "        0.00537662, 0.00092817, 0.00103034, 0.00143655, 0.00087251,\n",
       "        0.00063305, 0.00132022, 0.00377958, 0.00320272, 0.00470944,\n",
       "        0.00353322, 0.00235995, 0.0033346 , 0.0020263 , 0.0025201 ,\n",
       "        0.00128977, 0.00177363, 0.00646006, 0.00345236, 0.00663583,\n",
       "        0.00396069, 0.00795272, 0.00555101, 0.00362263, 0.00115672,\n",
       "        0.00077522, 0.00260228, 0.00250262, 0.0093008 , 0.00484746,\n",
       "        0.00196614, 0.00472003, 0.001365  , 0.00246361, 0.00192515,\n",
       "        0.00132938, 0.00309121, 0.00356661, 0.0022874 , 0.00104964,\n",
       "        0.00418212, 0.00302569, 0.00120982, 0.0008008 , 0.00278819,\n",
       "        0.00475181, 0.01573117, 0.00719618, 0.00793519, 0.00328935,\n",
       "        0.00083728, 0.00431653, 0.00226894, 0.00102079]),\n",
       " 'param_classifier': masked_array(data=[SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__gamma': masked_array(data=[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'}],\n",
       " 'split0_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.929,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.907, 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.714, 0.88 , 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.757, 0.687, 0.88 , 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.807, 0.711, 0.687, 0.88 , 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.904, 0.874,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.888, 0.888,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.885, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.905, 0.879, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.881, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.706, 0.864, 0.886, 0.883,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.867, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667,\n",
       "        0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686,\n",
       "        0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686,\n",
       "        0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686]),\n",
       " 'split1_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.931,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.906, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.87 , 0.888, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.695, 0.676, 0.885, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.855, 0.725, 0.676, 0.885, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.902,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.914, 0.877,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.874, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.887, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.899, 0.874, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.873, 0.881, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.657, 0.826, 0.887, 0.884,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.87 , 0.833, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 ,\n",
       "        0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641,\n",
       "        0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641,\n",
       "        0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641]),\n",
       " 'split2_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.933,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.926, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.822, 0.896, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.845, 0.701, 0.89 , 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.798, 0.823, 0.701, 0.89 , 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.887,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.911, 0.864,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.882, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.875, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.905, 0.877, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.852, 0.874, 0.87 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.622, 0.833, 0.875, 0.864,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.856,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.856, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.856, 0.844, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 ,\n",
       "        0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672,\n",
       "        0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672,\n",
       "        0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672]),\n",
       " 'split3_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.929,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.909, 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.766, 0.89 , 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.806, 0.712, 0.89 , 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.811, 0.757, 0.712, 0.89 , 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.896,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.902, 0.869,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.881, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.876, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.904, 0.882, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.873, 0.877, 0.874,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.581, 0.865, 0.865, 0.871,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.847, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ,\n",
       "        0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742,\n",
       "        0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742,\n",
       "        0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742]),\n",
       " 'split4_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.926, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.744, 0.894, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.786, 0.73 , 0.894, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.777, 0.838, 0.73 , 0.894, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.888,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.915, 0.871,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.88 , 0.866,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.877, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.896, 0.874, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.82 , 0.869, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.678, 0.817, 0.877, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.884,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.884, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.884, 0.845, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675,\n",
       "        0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677,\n",
       "        0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677,\n",
       "        0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677]),\n",
       " 'mean_test_recall_micro': array([0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.9314, 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.9266, 0.9356, 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.9056, 0.9356, 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.7832, 0.8896, 0.9356, 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.7778, 0.7012, 0.8878, 0.9356,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.8096, 0.7708, 0.7012, 0.8878,\n",
       "        0.9356, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.8952, 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.9092, 0.871 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.881 , 0.8772, 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.88  , 0.8734, 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.9018, 0.8772, 0.8736,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8558, 0.8764,\n",
       "        0.8728, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.6488, 0.841 ,\n",
       "        0.878 , 0.8724, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.8638, 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8412, 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8412, 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8638, 0.8412,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8472,\n",
       "        0.8412, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.8472, 0.8412, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.8648, 0.8472, 0.8412, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.6744, 0.6744, 0.6744, 0.6744, 0.6744, 0.6744, 0.6744, 0.6744,\n",
       "        0.6744, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836,\n",
       "        0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836,\n",
       "        0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836,\n",
       "        0.6836, 0.6836, 0.6836, 0.6836]),\n",
       " 'std_test_recall_micro': array([1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 2.33238076e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 4.89897949e-04,\n",
       "        4.31740663e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        2.33238076e-03, 4.31740663e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        5.59657038e-02, 5.57135531e-03, 4.31740663e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        5.03324945e-02, 1.88827964e-02, 4.83321839e-03, 4.31740663e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        2.55624725e-02, 5.11953123e-02, 1.88827964e-02, 4.83321839e-03,\n",
       "        4.31740663e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 6.73498330e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 5.26877595e-03,\n",
       "        4.42718872e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        4.47213595e-03, 7.08237248e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 4.97995984e-03, 7.22772440e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 3.65513338e-03, 3.05941171e-03, 7.36478106e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.95693638e-02, 4.54312668e-03,\n",
       "        7.46726188e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 4.36045869e-02, 1.98494332e-02,\n",
       "        8.04984472e-03, 9.72830921e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.23515181e-02, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 5.30659966e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 5.30659966e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.23515181e-02, 5.30659966e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.10344914e-02,\n",
       "        5.30659966e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.10344914e-02, 5.30659966e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.26079340e-02, 1.10344914e-02, 5.30659966e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        3.01237448e-02, 3.01237448e-02, 3.01237448e-02, 3.01237448e-02,\n",
       "        3.01237448e-02, 3.01237448e-02, 3.01237448e-02, 3.01237448e-02,\n",
       "        3.01237448e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02]),\n",
       " 'rank_test_recall_micro': array([  7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   6,   7,   7,   7,\n",
       "          7,   7,   7,   7, 249,   1,   7,   7,   7,   7,   7,   7,   7,\n",
       "        251,   1,   7,   7,   7,   7,   7,   7, 283, 254,   1,   7,   7,\n",
       "          7,   7,   7, 284, 286, 255,   1,   7,   7,   7,   7, 282, 285,\n",
       "        286, 255,   1,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7, 253,   7,   7,   7,   7,   7,   7,   7, 250, 267,\n",
       "          7,   7,   7,   7,   7,   7,   7, 257, 260,   7,   7,   7,   7,\n",
       "          7,   7,   7, 258, 264,   7,   7,   7,   7,   7,   7, 252, 260,\n",
       "        263,   7,   7,   7,   7,   7,   7, 271, 262, 265,   7,   7,   7,\n",
       "          7,   7, 324, 281, 259, 266,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7, 269,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 275,   7,   7,   7,   7,   7,   7,   7,   7, 275,   7,\n",
       "          7,   7,   7,   7,   7,   7, 269, 275,   7,   7,   7,   7,   7,\n",
       "          7,   7, 272, 275,   7,   7,   7,   7,   7,   7,   7, 272, 275,\n",
       "          7,   7,   7,   7,   7,   7, 268, 272, 275,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 315, 315, 315, 315, 315, 315, 315, 315, 315, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288]),\n",
       " 'split0_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.929,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.907, 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.714, 0.88 , 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.757, 0.687, 0.88 , 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.807, 0.711, 0.687, 0.88 , 0.928,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.904, 0.874,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.888, 0.888,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.885, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.905, 0.879, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.881, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.706, 0.864, 0.886, 0.883,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.867, 0.837,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667,\n",
       "        0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686,\n",
       "        0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686,\n",
       "        0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686]),\n",
       " 'split1_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.931,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.906, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.87 , 0.888, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.695, 0.676, 0.885, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.855, 0.725, 0.676, 0.885, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.902,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.914, 0.877,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.874, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.887, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.899, 0.874, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.873, 0.881, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.657, 0.826, 0.887, 0.884,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.833, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.87 , 0.833, 0.833,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 , 0.73 ,\n",
       "        0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641,\n",
       "        0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641,\n",
       "        0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641, 0.641]),\n",
       " 'split2_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.933,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.926, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.822, 0.896, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.845, 0.701, 0.89 , 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.798, 0.823, 0.701, 0.89 , 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.887,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.911, 0.864,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.882, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.875, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.905, 0.877, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.852, 0.874, 0.87 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.622, 0.833, 0.875, 0.864,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.856,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.856, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.844, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.856, 0.844, 0.844,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 , 0.66 ,\n",
       "        0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672,\n",
       "        0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672,\n",
       "        0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672]),\n",
       " 'split3_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.929,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.909, 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.766, 0.89 , 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.806, 0.712, 0.89 , 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.811, 0.757, 0.712, 0.89 , 0.936,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.896,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.902, 0.869,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.881, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.876, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.904, 0.882, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.873, 0.877, 0.874,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.581, 0.865, 0.865, 0.871,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.867, 0.847, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 , 0.64 ,\n",
       "        0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742,\n",
       "        0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742,\n",
       "        0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742, 0.742]),\n",
       " 'split4_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.926, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.744, 0.894, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.786, 0.73 , 0.894, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.777, 0.838, 0.73 , 0.894, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.888,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.915, 0.871,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.88 , 0.866,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.877, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.896, 0.874, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.82 , 0.869, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.678, 0.817, 0.877, 0.86 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.884,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.884, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.845, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.884, 0.845, 0.845,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675,\n",
       "        0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677,\n",
       "        0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677,\n",
       "        0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677]),\n",
       " 'mean_test_f1_micro': array([0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.9314, 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.9266, 0.9356, 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.9056, 0.9356, 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.7832, 0.8896, 0.9356, 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.7778, 0.7012, 0.8878, 0.9356,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.8096, 0.7708, 0.7012, 0.8878,\n",
       "        0.9356, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.8952, 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.9092, 0.871 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.881 , 0.8772, 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.88  , 0.8734, 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.9018, 0.8772, 0.8736,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8558, 0.8764,\n",
       "        0.8728, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.6488, 0.841 ,\n",
       "        0.878 , 0.8724, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.8638, 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8412, 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8412, 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8638, 0.8412,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.8472,\n",
       "        0.8412, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.8472, 0.8412, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.8648, 0.8472, 0.8412, 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 , 0.927 ,\n",
       "        0.6744, 0.6744, 0.6744, 0.6744, 0.6744, 0.6744, 0.6744, 0.6744,\n",
       "        0.6744, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836,\n",
       "        0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836,\n",
       "        0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836,\n",
       "        0.6836, 0.6836, 0.6836, 0.6836]),\n",
       " 'std_test_f1_micro': array([1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 2.33238076e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 4.89897949e-04,\n",
       "        4.31740663e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        2.33238076e-03, 4.31740663e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        5.59657038e-02, 5.57135531e-03, 4.31740663e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        5.03324945e-02, 1.88827964e-02, 4.83321839e-03, 4.31740663e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        2.55624725e-02, 5.11953123e-02, 1.88827964e-02, 4.83321839e-03,\n",
       "        4.31740663e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 6.73498330e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 5.26877595e-03,\n",
       "        4.42718872e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        4.47213595e-03, 7.08237248e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 4.97995984e-03, 7.22772440e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 3.65513338e-03, 3.05941171e-03, 7.36478106e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.95693638e-02, 4.54312668e-03,\n",
       "        7.46726188e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 4.36045869e-02, 1.98494332e-02,\n",
       "        8.04984472e-03, 9.72830921e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.23515181e-02, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 5.30659966e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 5.30659966e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.23515181e-02, 5.30659966e-03,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.10344914e-02,\n",
       "        5.30659966e-03, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.10344914e-02, 5.30659966e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.26079340e-02, 1.10344914e-02, 5.30659966e-03, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        3.01237448e-02, 3.01237448e-02, 3.01237448e-02, 3.01237448e-02,\n",
       "        3.01237448e-02, 3.01237448e-02, 3.01237448e-02, 3.01237448e-02,\n",
       "        3.01237448e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02,\n",
       "        3.28913362e-02, 3.28913362e-02, 3.28913362e-02, 3.28913362e-02]),\n",
       " 'rank_test_f1_micro': array([  7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   6,   7,   7,   7,\n",
       "          7,   7,   7,   7, 249,   1,   7,   7,   7,   7,   7,   7,   7,\n",
       "        251,   1,   7,   7,   7,   7,   7,   7, 283, 254,   1,   7,   7,\n",
       "          7,   7,   7, 284, 286, 255,   1,   7,   7,   7,   7, 282, 285,\n",
       "        286, 255,   1,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7, 253,   7,   7,   7,   7,   7,   7,   7, 250, 267,\n",
       "          7,   7,   7,   7,   7,   7,   7, 257, 260,   7,   7,   7,   7,\n",
       "          7,   7,   7, 258, 264,   7,   7,   7,   7,   7,   7, 252, 260,\n",
       "        263,   7,   7,   7,   7,   7,   7, 271, 262, 265,   7,   7,   7,\n",
       "          7,   7, 324, 281, 259, 266,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7, 269,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 275,   7,   7,   7,   7,   7,   7,   7,   7, 275,   7,\n",
       "          7,   7,   7,   7,   7,   7, 269, 275,   7,   7,   7,   7,   7,\n",
       "          7,   7, 272, 275,   7,   7,   7,   7,   7,   7,   7, 272, 275,\n",
       "          7,   7,   7,   7,   7,   7, 268, 272, 275,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 315, 315, 315, 315, 315, 315, 315, 315, 315, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288]),\n",
       " 'split0_test_roc_auc_ovo': array([0.48914602, 0.45428618, 0.5       , 0.55313207, 0.5461867 ,\n",
       "        0.42498264, 0.58745992, 0.5230601 , 0.55571811, 0.46963988,\n",
       "        0.45078394, 0.5363893 , 0.51734125, 0.5461867 , 0.57501736,\n",
       "        0.49761345, 0.55486102, 0.63312202, 0.46813258, 0.56137784,\n",
       "        0.49711102, 0.44686793, 0.5461867 , 0.52752287, 0.51812446,\n",
       "        0.57269731, 0.64011172, 0.52617813, 0.54321644, 0.50795762,\n",
       "        0.55313207, 0.5280253 , 0.53300528, 0.49425899, 0.5683971 ,\n",
       "        0.63957973, 0.47382187, 0.54321644, 0.50795762, 0.40343722,\n",
       "        0.43262254, 0.47253624, 0.47023097, 0.57006694, 0.63742223,\n",
       "        0.52617813, 0.45678356, 0.46285706, 0.52917793, 0.47688079,\n",
       "        0.55820071, 0.43383429, 0.53553221, 0.63972751, 0.58584918,\n",
       "        0.5280253 , 0.55638309, 0.44224262, 0.44528676, 0.50642077,\n",
       "        0.45577869, 0.53219252, 0.63644693, 0.51865644, 0.45557181,\n",
       "        0.46173398, 0.47023097, 0.50746996, 0.41097368, 0.48647131,\n",
       "        0.53099555, 0.63941718, 0.47012753, 0.46807347, 0.48907213,\n",
       "        0.38931004, 0.4653101 , 0.43754341, 0.48647131, 0.53038968,\n",
       "        0.63666859, 0.3939797 , 0.51846433, 0.5       , 0.50448493,\n",
       "        0.47141316, 0.47590548, 0.49242659, 0.50925803, 0.52433095,\n",
       "        0.51846433, 0.5       , 0.47141316, 0.50448493, 0.52858684,\n",
       "        0.52409452, 0.49312113, 0.50504647, 0.51107565, 0.5       ,\n",
       "        0.50448493, 0.47141316, 0.49551507, 0.52858684, 0.46470423,\n",
       "        0.48437292, 0.48970756, 0.55159522, 0.41636742, 0.49551507,\n",
       "        0.52858684, 0.50448493, 0.40099895, 0.52709432, 0.49841143,\n",
       "        0.50178067, 0.52204046, 0.41636742, 0.49551507, 0.47141316,\n",
       "        0.46279795, 0.48128445, 0.43262254, 0.49674159, 0.50370173,\n",
       "        0.54258102, 0.58363258, 0.50448493, 0.40098417, 0.53149798,\n",
       "        0.56725924, 0.39035924, 0.43933147, 0.50922847, 0.53180831,\n",
       "        0.41636742, 0.53720205, 0.4812549 , 0.42724358, 0.56468798,\n",
       "        0.50918414, 0.49260392, 0.50387906, 0.53185264, 0.45184791,\n",
       "        0.46850202, 0.56733313, 0.55577722, 0.47806298, 0.50284465,\n",
       "        0.49838188, 0.49380089, 0.46829513, 0.54530005, 0.47998404,\n",
       "        0.51250905, 0.56700802, 0.54577293, 0.41517046, 0.49125918,\n",
       "        0.48225976, 0.52376941, 0.5       , 0.5       , 0.5       ,\n",
       "        0.47111761, 0.60024974, 0.5260008 , 0.5260008 , 0.48868792,\n",
       "        0.52721254, 0.5       , 0.5       , 0.5       , 0.49676375,\n",
       "        0.47401398, 0.5260008 , 0.5260008 , 0.45334043, 0.55158044,\n",
       "        0.5       , 0.5       , 0.5       , 0.50616217, 0.5260008 ,\n",
       "        0.5260008 , 0.5260008 , 0.47110284, 0.51209528, 0.5       ,\n",
       "        0.5       , 0.5       , 0.60019802, 0.5260008 , 0.5260008 ,\n",
       "        0.48862881, 0.54869885, 0.49179117, 0.5       , 0.5       ,\n",
       "        0.49583278, 0.4739992 , 0.5260008 , 0.4739992 , 0.45334043,\n",
       "        0.53408402, 0.49179117, 0.5       , 0.5       , 0.50599223,\n",
       "        0.4739992 , 0.5260008 , 0.4739992 , 0.53550265, 0.48788994,\n",
       "        0.49179117, 0.5       , 0.45692394, 0.39980198, 0.5260008 ,\n",
       "        0.5260008 , 0.51137119, 0.44599607, 0.53282795, 0.50820883,\n",
       "        0.5       , 0.5135878 , 0.5260008 , 0.5260008 , 0.4739992 ,\n",
       "        0.4533552 , 0.55774261, 0.53282795, 0.49179117, 0.5       ,\n",
       "        0.50648727, 0.4739992 , 0.5260008 , 0.5260008 , 0.52889716,\n",
       "        0.48790472, 0.53282795, 0.49179117, 0.54531483, 0.54531483,\n",
       "        0.54531483, 0.54531483, 0.54531483, 0.54531483, 0.45468517,\n",
       "        0.54531483, 0.54531483, 0.56325457, 0.43837094, 0.43837094,\n",
       "        0.5601661 , 0.43809017, 0.43837094, 0.43837094, 0.43751385,\n",
       "        0.56162906, 0.54002453, 0.54002453, 0.54002453, 0.54002453,\n",
       "        0.54002453, 0.45997547, 0.45997547, 0.45997547, 0.54002453,\n",
       "        0.539064  , 0.539064  , 0.539064  , 0.460936  , 0.539064  ,\n",
       "        0.460936  , 0.539064  , 0.460936  , 0.539064  , 0.51429711,\n",
       "        0.48570289, 0.51623295, 0.51429711, 0.48570289, 0.48614621,\n",
       "        0.51429711, 0.51508032, 0.48570289, 0.59142025, 0.59142025,\n",
       "        0.59142025, 0.59142025, 0.40857975, 0.59142025, 0.59142025,\n",
       "        0.4082842 , 0.59142025, 0.42665248, 0.42665248, 0.57334752,\n",
       "        0.57334752, 0.42665248, 0.57334752, 0.57334752, 0.42665248,\n",
       "        0.42665248, 0.57334752, 0.57334752, 0.42665248, 0.57334752,\n",
       "        0.57334752, 0.57334752, 0.57334752, 0.57334752, 0.42665248,\n",
       "        0.57334752, 0.57334752, 0.42665248, 0.57334752, 0.57334752,\n",
       "        0.42665248, 0.42665248, 0.57334752, 0.57334752]),\n",
       " 'split1_test_roc_auc_ovo': array([0.46349249, 0.47352633, 0.52096171, 0.43751385, 0.52224734,\n",
       "        0.502091  , 0.52957692, 0.51044022, 0.58225828, 0.47626014,\n",
       "        0.51252383, 0.49493875, 0.50763252, 0.52224734, 0.497909  ,\n",
       "        0.55852581, 0.59183402, 0.65344091, 0.53630063, 0.49749523,\n",
       "        0.50565235, 0.54029052, 0.47775266, 0.49214582, 0.59167147,\n",
       "        0.63149651, 0.65571663, 0.52684311, 0.4862792 , 0.54077818,\n",
       "        0.49236748, 0.49705191, 0.54280268, 0.5466448 , 0.63570806,\n",
       "        0.66130248, 0.47315689, 0.5137208 , 0.45922182, 0.46409836,\n",
       "        0.51222828, 0.57730786, 0.55992966, 0.6361366 , 0.65140163,\n",
       "        0.47315689, 0.4862792 , 0.54064518, 0.44986774, 0.54049741,\n",
       "        0.52161192, 0.52125726, 0.62765439, 0.65075143, 0.52669533,\n",
       "        0.52276455, 0.53242896, 0.5069232 , 0.54770877, 0.54764966,\n",
       "        0.55288085, 0.63270825, 0.65366257, 0.48039781, 0.4927517 ,\n",
       "        0.51103131, 0.47476763, 0.55095979, 0.51921798, 0.47617148,\n",
       "        0.61877318, 0.65193362, 0.47237369, 0.44181407, 0.52765586,\n",
       "        0.48118101, 0.53556176, 0.48602799, 0.47617148, 0.61943816,\n",
       "        0.65344091, 0.51148941, 0.5244344 , 0.50251954, 0.52447873,\n",
       "        0.53281317, 0.53276884, 0.53436479, 0.58261294, 0.5477531 ,\n",
       "        0.56554506, 0.5       , 0.50251954, 0.52447873, 0.53281317,\n",
       "        0.53276884, 0.48966322, 0.54145794, 0.52307488, 0.5       ,\n",
       "        0.46260584, 0.49748046, 0.52447873, 0.53281317, 0.51683882,\n",
       "        0.51190318, 0.52994636, 0.53293139, 0.55169866, 0.46260584,\n",
       "        0.50251954, 0.47552127, 0.4831464 , 0.51333658, 0.54776788,\n",
       "        0.49459887, 0.535148  , 0.55169866, 0.46260584, 0.49748046,\n",
       "        0.47261013, 0.48633831, 0.52085827, 0.5322073 , 0.48964845,\n",
       "        0.56575195, 0.44830134, 0.46260584, 0.49167295, 0.56686025,\n",
       "        0.44468088, 0.51244994, 0.54136927, 0.49487964, 0.51729692,\n",
       "        0.55169866, 0.48534823, 0.48744662, 0.45928093, 0.48927901,\n",
       "        0.43365696, 0.52264633, 0.49403733, 0.51737081, 0.53528099,\n",
       "        0.51357302, 0.48728407, 0.44293715, 0.48293952, 0.49737702,\n",
       "        0.46841335, 0.48786038, 0.54190126, 0.47414698, 0.53411358,\n",
       "        0.49613572, 0.47085162, 0.51537586, 0.51846433, 0.51738559,\n",
       "        0.48245186, 0.53805914, 0.5       , 0.5       , 0.5       ,\n",
       "        0.53033057, 0.5043741 , 0.53885712, 0.53885712, 0.44553797,\n",
       "        0.55867358, 0.5       , 0.5       , 0.5       , 0.52252811,\n",
       "        0.53027885, 0.53885712, 0.46114288, 0.46581253, 0.56355012,\n",
       "        0.5       , 0.5       , 0.5       , 0.50444799, 0.53885712,\n",
       "        0.53885712, 0.53885712, 0.45314832, 0.42820411, 0.5       ,\n",
       "        0.5       , 0.48220804, 0.50431499, 0.46114288, 0.46114288,\n",
       "        0.44553797, 0.40368843, 0.46579776, 0.5       , 0.5       ,\n",
       "        0.47839547, 0.53885712, 0.5       , 0.53885712, 0.46581253,\n",
       "        0.55834848, 0.46579776, 0.5       , 0.5       , 0.49831538,\n",
       "        0.53885712, 0.46114288, 0.53885712, 0.57049549, 0.43039116,\n",
       "        0.53420224, 0.5       , 0.5       , 0.50431499, 0.46114288,\n",
       "        0.4613941 , 0.55446203, 0.43102658, 0.46579776, 0.46579776,\n",
       "        0.5       , 0.46440129, 0.46114288, 0.46114288, 0.46114288,\n",
       "        0.53418747, 0.54430997, 0.46573865, 0.46579776, 0.5       ,\n",
       "        0.49860354, 0.46114288, 0.53885712, 0.53885712, 0.59161236,\n",
       "        0.50243088, 0.46579776, 0.46579776, 0.522735  , 0.522735  ,\n",
       "        0.522735  , 0.477265  , 0.522735  , 0.522735  , 0.477265  ,\n",
       "        0.522735  , 0.522735  , 0.473216  , 0.473216  , 0.473216  ,\n",
       "        0.526784  , 0.473216  , 0.473216  , 0.473216  , 0.526784  ,\n",
       "        0.526784  , 0.53953688, 0.46038924, 0.46046312, 0.53953688,\n",
       "        0.46038924, 0.46046312, 0.53934477, 0.53953688, 0.53953688,\n",
       "        0.49077153, 0.50922847, 0.50922847, 0.49077153, 0.50922847,\n",
       "        0.50922847, 0.50922847, 0.49077153, 0.50922847, 0.51994207,\n",
       "        0.47999882, 0.52045928, 0.47946683, 0.47954072, 0.47954072,\n",
       "        0.47930428, 0.52045928, 0.47954072, 0.45990158, 0.45990158,\n",
       "        0.45990158, 0.54009842, 0.54009842, 0.45990158, 0.54009842,\n",
       "        0.54009842, 0.54006886, 0.48571766, 0.48571766, 0.48571766,\n",
       "        0.51428234, 0.48571766, 0.51428234, 0.51428234, 0.48604277,\n",
       "        0.48571766, 0.51428234, 0.48571766, 0.48554033, 0.51428234,\n",
       "        0.48571766, 0.48571766, 0.51401634, 0.51428234, 0.51428234,\n",
       "        0.48571766, 0.51428234, 0.48571766, 0.48571766, 0.51428234,\n",
       "        0.48571766, 0.48571766, 0.51428234, 0.51428234]),\n",
       " 'split2_test_roc_auc_ovo': array([0.50846005, 0.52289755, 0.5       , 0.48786038, 0.48772739,\n",
       "        0.47587593, 0.53109899, 0.52885283, 0.60548832, 0.48339761,\n",
       "        0.5       , 0.52074005, 0.49071242, 0.49805677, 0.52412407,\n",
       "        0.56313635, 0.58562752, 0.65899721, 0.5       , 0.48058991,\n",
       "        0.49541162, 0.52455261, 0.51227261, 0.53872412, 0.56332846,\n",
       "        0.63216149, 0.66700655, 0.52341476, 0.51474044, 0.50458838,\n",
       "        0.47618625, 0.45935482, 0.60396625, 0.59097693, 0.62370883,\n",
       "        0.66616424, 0.52344431, 0.48525956, 0.49541162, 0.50721875,\n",
       "        0.53972898, 0.55357539, 0.61457641, 0.6308463 , 0.66258811,\n",
       "        0.47655569, 0.48525956, 0.53250284, 0.49230837, 0.60692172,\n",
       "        0.56986006, 0.56261914, 0.65140163, 0.66226301, 0.50290375,\n",
       "        0.46965465, 0.51466655, 0.48890958, 0.54289134, 0.53811825,\n",
       "        0.53896056, 0.67321305, 0.6629871 , 0.4741322 , 0.49913552,\n",
       "        0.54330511, 0.50801673, 0.54640836, 0.5601661 , 0.49937196,\n",
       "        0.68476896, 0.66508549, 0.49935718, 0.45617768, 0.53259151,\n",
       "        0.54476807, 0.54989582, 0.56142217, 0.50062804, 0.68485762,\n",
       "        0.66026806, 0.47009797, 0.49094886, 0.5       , 0.45978336,\n",
       "        0.53439435, 0.46566476, 0.49507174, 0.56340234, 0.48212676,\n",
       "        0.47889051, 0.5       , 0.49204238, 0.45978336, 0.53439435,\n",
       "        0.53433524, 0.48493446, 0.5591169 , 0.56350579, 0.5       ,\n",
       "        0.48704763, 0.49204238, 0.45978336, 0.53439435, 0.52651801,\n",
       "        0.45276411, 0.58033722, 0.52029673, 0.49180594, 0.51295237,\n",
       "        0.49204238, 0.45978336, 0.47346722, 0.51162241, 0.42312069,\n",
       "        0.5197943 , 0.58425323, 0.49180594, 0.51295237, 0.50795762,\n",
       "        0.48812638, 0.48833326, 0.44162197, 0.57670198, 0.547428  ,\n",
       "        0.45450784, 0.50819406, 0.51295237, 0.48992922, 0.48456503,\n",
       "        0.4718417 , 0.46904878, 0.59747898, 0.55446203, 0.54561038,\n",
       "        0.49180594, 0.4994754 , 0.46848724, 0.48511179, 0.51187362,\n",
       "        0.50485437, 0.42948974, 0.55772783, 0.4539463 , 0.48561422,\n",
       "        0.46157143, 0.51135642, 0.52354775, 0.47577249, 0.48525956,\n",
       "        0.55419604, 0.53969943, 0.5362563 , 0.54271401, 0.510322  ,\n",
       "        0.5214937 , 0.49975617, 0.50819406, 0.46937388, 0.58048499,\n",
       "        0.55202376, 0.51076532, 0.5       , 0.5       , 0.5       ,\n",
       "        0.46301222, 0.44550842, 0.52716821, 0.52716821, 0.51200662,\n",
       "        0.51734125, 0.5       , 0.5       , 0.5       , 0.46886406,\n",
       "        0.51080226, 0.52716821, 0.47283179, 0.48806727, 0.48901302,\n",
       "        0.5       , 0.5       , 0.5       , 0.47562471, 0.47283179,\n",
       "        0.52716821, 0.52716821, 0.49983006, 0.45693133, 0.5       ,\n",
       "        0.5       , 0.45017068, 0.44556014, 0.47283179, 0.52716821,\n",
       "        0.48725451, 0.48453547, 0.42487919, 0.5       , 0.5       ,\n",
       "        0.47040091, 0.48918296, 0.5       , 0.47283179, 0.48808204,\n",
       "        0.48155044, 0.57367262, 0.5       , 0.5       , 0.47568382,\n",
       "        0.52716821, 0.47283179, 0.52716821, 0.49176161, 0.45670967,\n",
       "        0.57367262, 0.5       , 0.45721949, 0.44547886, 0.52716821,\n",
       "        0.47283179, 0.48774216, 0.52022284, 0.42632738, 0.57367262,\n",
       "        0.5       , 0.44941703, 0.51080965, 0.47283179, 0.47283179,\n",
       "        0.48806727, 0.49356445, 0.42632738, 0.57367262, 0.5       ,\n",
       "        0.5156123 , 0.47283179, 0.52716821, 0.47283179, 0.49616527,\n",
       "        0.45696088, 0.42628305, 0.42632738, 0.5209026 , 0.5209026 ,\n",
       "        0.4790974 , 0.4790974 , 0.5209026 , 0.51989774, 0.5209026 ,\n",
       "        0.5209026 , 0.5209026 , 0.48938245, 0.51061755, 0.51061755,\n",
       "        0.48938245, 0.51061755, 0.51061755, 0.48938245, 0.51061755,\n",
       "        0.51061755, 0.50851916, 0.49148084, 0.49148084, 0.49148084,\n",
       "        0.50851916, 0.50851916, 0.50851916, 0.49148084, 0.50851916,\n",
       "        0.498042  , 0.49894342, 0.501958  , 0.498042  , 0.501958  ,\n",
       "        0.49787945, 0.498042  , 0.498042  , 0.501958  , 0.47704334,\n",
       "        0.52295666, 0.52295666, 0.52295666, 0.47704334, 0.47704334,\n",
       "        0.52295666, 0.52295666, 0.47704334, 0.53640407, 0.46359593,\n",
       "        0.46359593, 0.53640407, 0.46359593, 0.53640407, 0.53640407,\n",
       "        0.46359593, 0.46359593, 0.49180594, 0.49180594, 0.50819406,\n",
       "        0.50819406, 0.49180594, 0.49180594, 0.50819406, 0.49180594,\n",
       "        0.49180594, 0.49180594, 0.49196849, 0.50819406, 0.49180594,\n",
       "        0.49180594, 0.50819406, 0.50819406, 0.49180594, 0.49180594,\n",
       "        0.50819406, 0.50819406, 0.49199805, 0.50819406, 0.49180594,\n",
       "        0.49180594, 0.50819406, 0.50819406, 0.49180594]),\n",
       " 'split3_test_roc_auc_ovo': array([0.51001167, 0.49465798, 0.5       , 0.53368503, 0.53572431,\n",
       "        0.53361115, 0.4634186 , 0.56496875, 0.57334752, 0.45796575,\n",
       "        0.51431189, 0.5092137 , 0.53368503, 0.53572431, 0.46638885,\n",
       "        0.57650988, 0.66301665, 0.68887707, 0.5       , 0.46504411,\n",
       "        0.54135449, 0.46631497, 0.46427569, 0.58422367, 0.65117997,\n",
       "        0.64943624, 0.69901435, 0.51648417, 0.46641841, 0.44707482,\n",
       "        0.52733076, 0.52391719, 0.57280076, 0.60888712, 0.65320447,\n",
       "        0.69542345, 0.51648417, 0.46641841, 0.44707482, 0.56120051,\n",
       "        0.54707334, 0.63126007, 0.53489678, 0.65720914, 0.69984188,\n",
       "        0.48351583, 0.53358159, 0.50392339, 0.47562471, 0.59332654,\n",
       "        0.57129346, 0.57702709, 0.67058267, 0.69957589, 0.46325605,\n",
       "        0.48800816, 0.5002586 , 0.52552792, 0.61074907, 0.55323551,\n",
       "        0.54244802, 0.63519085, 0.69815726, 0.52140503, 0.43876993,\n",
       "        0.53740893, 0.52775931, 0.58311537, 0.52947348, 0.501958  ,\n",
       "        0.62635398, 0.69797993, 0.47006842, 0.46799959, 0.5603582 ,\n",
       "        0.48840715, 0.59981381, 0.53798525, 0.50244566, 0.62497968,\n",
       "        0.70046253, 0.51912932, 0.47980671, 0.5       , 0.50655377,\n",
       "        0.47980671, 0.55459503, 0.49221971, 0.55257053, 0.49524907,\n",
       "        0.55582155, 0.5       , 0.44416367, 0.49344623, 0.47980671,\n",
       "        0.44540497, 0.5353401 , 0.5486693 , 0.48152089, 0.5       ,\n",
       "        0.47980671, 0.55583633, 0.50655377, 0.47980671, 0.45334043,\n",
       "        0.51948397, 0.5353401 , 0.48678163, 0.44417845, 0.52019329,\n",
       "        0.44416367, 0.50655377, 0.52486294, 0.50027338, 0.49573673,\n",
       "        0.54228547, 0.49906164, 0.44417845, 0.47980671, 0.44416367,\n",
       "        0.46334471, 0.4657682 , 0.45873417, 0.39618153, 0.43837094,\n",
       "        0.51680927, 0.55582155, 0.47980671, 0.50439627, 0.48060469,\n",
       "        0.50243088, 0.57486959, 0.55032436, 0.49489442, 0.51748903,\n",
       "        0.44417845, 0.52486294, 0.47781177, 0.48650086, 0.50974568,\n",
       "        0.46423135, 0.4965347 , 0.55896913, 0.51658761, 0.54289134,\n",
       "        0.5342318 , 0.51311492, 0.49814544, 0.50189889, 0.44552319,\n",
       "        0.5326654 , 0.44026245, 0.51459266, 0.54303912, 0.46372892,\n",
       "        0.47064474, 0.47293523, 0.5529104 , 0.51375035, 0.45449306,\n",
       "        0.54519661, 0.51219873, 0.5       , 0.5       , 0.5       ,\n",
       "        0.49929807, 0.47784132, 0.52226212, 0.52226212, 0.4621773 ,\n",
       "        0.5016329 , 0.5       , 0.5       , 0.5       , 0.54711028,\n",
       "        0.52226212, 0.5       , 0.52226212, 0.49383044, 0.530833  ,\n",
       "        0.5       , 0.5       , 0.5       , 0.52270544, 0.47773788,\n",
       "        0.47773788, 0.52226212, 0.49402255, 0.50514992, 0.5       ,\n",
       "        0.5       , 0.50274859, 0.52216607, 0.52226212, 0.52226212,\n",
       "        0.4621773 , 0.52477428, 0.52854251, 0.5       , 0.5       ,\n",
       "        0.5446203 , 0.52226212, 0.5       , 0.52226212, 0.50611045,\n",
       "        0.49114096, 0.52854251, 0.5       , 0.5       , 0.47690296,\n",
       "        0.47773788, 0.52226212, 0.52226212, 0.50430761, 0.50782462,\n",
       "        0.52854251, 0.5       , 0.51056583, 0.47783393, 0.52226212,\n",
       "        0.52226212, 0.4621773 , 0.51367646, 0.47145749, 0.52854251,\n",
       "        0.5       , 0.54783438, 0.47773788, 0.5       , 0.47773788,\n",
       "        0.50612522, 0.48162433, 0.47145749, 0.52854251, 0.5       ,\n",
       "        0.47817381, 0.52226212, 0.52226212, 0.52226212, 0.52764109,\n",
       "        0.49214582, 0.52854251, 0.52854251, 0.52631112, 0.52631112,\n",
       "        0.47368888, 0.47368888, 0.52631112, 0.52631112, 0.52631112,\n",
       "        0.52631112, 0.52631112, 0.51583396, 0.51583396, 0.48416604,\n",
       "        0.51583396, 0.51583396, 0.51583396, 0.48447636, 0.51583396,\n",
       "        0.48416604, 0.54464985, 0.54463507, 0.45535015, 0.45535015,\n",
       "        0.45535015, 0.45535015, 0.45535015, 0.45535015, 0.54464985,\n",
       "        0.51447444, 0.51447444, 0.51447444, 0.48552556, 0.48552556,\n",
       "        0.48551078, 0.51447444, 0.48552556, 0.51447444, 0.48138789,\n",
       "        0.48194943, 0.51861211, 0.51861211, 0.48138789, 0.51878944,\n",
       "        0.51861211, 0.48138789, 0.51905543, 0.4934019 , 0.4934019 ,\n",
       "        0.4934019 , 0.5065981 , 0.4934019 , 0.4934019 , 0.4934019 ,\n",
       "        0.5065981 , 0.4934019 , 0.46381759, 0.46381759, 0.53618241,\n",
       "        0.53618241, 0.53618241, 0.53618241, 0.46381759, 0.53618241,\n",
       "        0.53618241, 0.53618241, 0.46381759, 0.46381759, 0.53618241,\n",
       "        0.46381759, 0.46381759, 0.53618241, 0.53618241, 0.53618241,\n",
       "        0.53618241, 0.53618241, 0.46381759, 0.53618241, 0.53618241,\n",
       "        0.53618241, 0.46381759, 0.46381759, 0.53618241]),\n",
       " 'split4_test_roc_auc_ovo': array([0.52561659, 0.49443632, 0.5       , 0.46033013, 0.51609995,\n",
       "        0.50231266, 0.50087925, 0.58678016, 0.64566801, 0.48246664,\n",
       "        0.51827223, 0.5168536 , 0.52229168, 0.51609995, 0.50231266,\n",
       "        0.53538443, 0.63991961, 0.69994532, 0.5       , 0.47411742,\n",
       "        0.52161192, 0.48768305, 0.51609995, 0.51171107, 0.57352485,\n",
       "        0.66300188, 0.71337796, 0.47991015, 0.47039352, 0.51114953,\n",
       "        0.47770832, 0.46919655, 0.53234029, 0.56040254, 0.66431706,\n",
       "        0.70983139, 0.52008985, 0.47039352, 0.51114953, 0.49516041,\n",
       "        0.50082014, 0.56663859, 0.61429564, 0.65865733, 0.71104314,\n",
       "        0.47991015, 0.52960648, 0.47101417, 0.46975809, 0.5252176 ,\n",
       "        0.52721254, 0.60816302, 0.65225872, 0.71107269, 0.50752907,\n",
       "        0.46591598, 0.54852152, 0.49910597, 0.4901361 , 0.5441622 ,\n",
       "        0.50145557, 0.65856866, 0.71225488, 0.50942058, 0.52412407,\n",
       "        0.45458173, 0.45016329, 0.53436479, 0.5460537 , 0.48871747,\n",
       "        0.65797757, 0.71475226, 0.53148321, 0.5373646 , 0.45419751,\n",
       "        0.47730933, 0.51214701, 0.44862644, 0.48911646, 0.65848   ,\n",
       "        0.71376217, 0.49845576, 0.50215011, 0.49643126, 0.49415555,\n",
       "        0.47026053, 0.44190274, 0.47965894, 0.57795806, 0.5165285 ,\n",
       "        0.5       , 0.5       , 0.47863191, 0.50584445, 0.47026053,\n",
       "        0.44190274, 0.48221542, 0.52561659, 0.51342525, 0.5       ,\n",
       "        0.50958313, 0.52136809, 0.50584445, 0.52973947, 0.47324556,\n",
       "        0.52493683, 0.51686838, 0.51907021, 0.5167871 , 0.49041687,\n",
       "        0.47862452, 0.49415555, 0.49595839, 0.53126154, 0.56743657,\n",
       "        0.4982341 , 0.52006029, 0.5167871 , 0.49041687, 0.52137548,\n",
       "        0.46841335, 0.51831656, 0.5005246 , 0.54432475, 0.52483339,\n",
       "        0.51618862, 0.4832129 , 0.50958313, 0.50234221, 0.52611902,\n",
       "        0.52453784, 0.43942014, 0.46362548, 0.50714486, 0.51212484,\n",
       "        0.4832129 , 0.49517519, 0.49097841, 0.52651801, 0.5041155 ,\n",
       "        0.48596888, 0.52532104, 0.51091309, 0.51209528, 0.48747617,\n",
       "        0.4819051 , 0.49459887, 0.49060898, 0.48239275, 0.48462414,\n",
       "        0.52387286, 0.50288898, 0.51366169, 0.51015945, 0.48274741,\n",
       "        0.4761567 , 0.47764921, 0.52700566, 0.48364883, 0.4728909 ,\n",
       "        0.52523237, 0.51357302, 0.5       , 0.5       , 0.5       ,\n",
       "        0.50182501, 0.43611739, 0.43612478, 0.56387522, 0.45053272,\n",
       "        0.50628777, 0.5       , 0.5       , 0.5       , 0.4737406 ,\n",
       "        0.43612478, 0.43612478, 0.56387522, 0.4760237 , 0.48905735,\n",
       "        0.5       , 0.5       , 0.5       , 0.45976859, 0.56387522,\n",
       "        0.56387522, 0.56387522, 0.53012369, 0.50551935, 0.5       ,\n",
       "        0.5       , 0.5       , 0.56391216, 0.5       , 0.56387522,\n",
       "        0.54951161, 0.51067666, 0.49028387, 0.5       , 0.5       ,\n",
       "        0.46755626, 0.56388261, 0.43612478, 0.56387522, 0.4760237 ,\n",
       "        0.49860354, 0.50971613, 0.5       , 0.5       , 0.4592366 ,\n",
       "        0.5       , 0.56387522, 0.56387522, 0.49951974, 0.49428854,\n",
       "        0.49028387, 0.5       , 0.50650944, 0.5       , 0.56387522,\n",
       "        0.56387522, 0.4496313 , 0.52594169, 0.50031771, 0.49028387,\n",
       "        0.5       , 0.5588583 , 0.56386783, 0.56387522, 0.56387522,\n",
       "        0.4760237 , 0.5174447 , 0.50031771, 0.49028387, 0.5       ,\n",
       "        0.45965776, 0.56386783, 0.56387522, 0.56387522, 0.4704083 ,\n",
       "        0.50551935, 0.49968229, 0.49028387, 0.46999453, 0.53000547,\n",
       "        0.53000547, 0.53000547, 0.53000547, 0.53000547, 0.46999453,\n",
       "        0.53000547, 0.53000547, 0.46219208, 0.46219208, 0.53780792,\n",
       "        0.53780792, 0.46219208, 0.46220685, 0.53780792, 0.53776359,\n",
       "        0.46219208, 0.50565235, 0.50565235, 0.50565235, 0.49434765,\n",
       "        0.50565235, 0.49434765, 0.50565235, 0.49434765, 0.50565235,\n",
       "        0.47809254, 0.52190746, 0.52190746, 0.47809254, 0.47809254,\n",
       "        0.52190746, 0.52190746, 0.47809254, 0.47809254, 0.4707334 ,\n",
       "        0.5292666 , 0.4707334 , 0.5292666 , 0.4706004 , 0.5292666 ,\n",
       "        0.4707334 , 0.5292666 , 0.53047834, 0.51287849, 0.51287849,\n",
       "        0.48712151, 0.48712151, 0.48712151, 0.48712151, 0.48712151,\n",
       "        0.48712151, 0.51287849, 0.47985104, 0.52014896, 0.52014896,\n",
       "        0.47985104, 0.52014896, 0.47985104, 0.52014896, 0.47985104,\n",
       "        0.47985104, 0.52014896, 0.52014896, 0.47985104, 0.47985104,\n",
       "        0.52014896, 0.47985104, 0.47977716, 0.47985104, 0.52014896,\n",
       "        0.47985104, 0.47985104, 0.47985104, 0.47985104, 0.47985104,\n",
       "        0.52014896, 0.52014896, 0.47985104, 0.52014896]),\n",
       " 'mean_test_roc_auc_ovo': array([0.49934536, 0.48796087, 0.50419234, 0.49450429, 0.52159714,\n",
       "        0.48777467, 0.52248674, 0.54282041, 0.59249605, 0.473946  ,\n",
       "        0.49917838, 0.51562708, 0.51433258, 0.52366302, 0.51315039,\n",
       "        0.54623399, 0.60705177, 0.66687651, 0.50088664, 0.4957249 ,\n",
       "        0.51222828, 0.49314182, 0.50331752, 0.53086551, 0.57956584,\n",
       "        0.62975869, 0.67504544, 0.51456606, 0.4962096 , 0.5023097 ,\n",
       "        0.50534498, 0.49550915, 0.55698305, 0.56023407, 0.6290671 ,\n",
       "        0.67446026, 0.50139942, 0.49580175, 0.48416308, 0.48622305,\n",
       "        0.50649466, 0.56026363, 0.55878589, 0.63058326, 0.6724594 ,\n",
       "        0.48786334, 0.49830208, 0.50218853, 0.48334737, 0.54856881,\n",
       "        0.54963574, 0.54058016, 0.62748592, 0.6726781 , 0.51724668,\n",
       "        0.49487373, 0.53045174, 0.49254186, 0.52735441, 0.53791728,\n",
       "        0.51830474, 0.62637467, 0.67270175, 0.50080241, 0.48207061,\n",
       "        0.50161221, 0.48618758, 0.54446366, 0.51317699, 0.49053804,\n",
       "        0.62377385, 0.6738337 , 0.48868201, 0.47428588, 0.51277504,\n",
       "        0.47619512, 0.5325457 , 0.49432105, 0.49096659, 0.62362903,\n",
       "        0.67292045, 0.47863043, 0.50316088, 0.49979016, 0.49789127,\n",
       "        0.49773758, 0.49416737, 0.49874836, 0.55716038, 0.51319768,\n",
       "        0.52374429, 0.5       , 0.47775413, 0.49760754, 0.50917232,\n",
       "        0.49570126, 0.49705487, 0.53598144, 0.51852049, 0.5       ,\n",
       "        0.48870565, 0.50762808, 0.49843508, 0.52106811, 0.48692941,\n",
       "        0.4986922 , 0.53043992, 0.52213504, 0.48416752, 0.49633669,\n",
       "        0.48918739, 0.48809978, 0.47568678, 0.51671765, 0.50649466,\n",
       "        0.51133868, 0.53211272, 0.48416752, 0.48825937, 0.48847808,\n",
       "        0.4710585 , 0.48800816, 0.47087231, 0.50923143, 0.5007965 ,\n",
       "        0.51916774, 0.51583248, 0.4938866 , 0.47786496, 0.51792939,\n",
       "        0.50215011, 0.47722954, 0.51842591, 0.51212188, 0.5248659 ,\n",
       "        0.47745268, 0.50841276, 0.48119579, 0.47693103, 0.51594036,\n",
       "        0.47957914, 0.49331915, 0.52510529, 0.50637053, 0.50062213,\n",
       "        0.49195667, 0.51473748, 0.50220331, 0.48421333, 0.48312571,\n",
       "        0.5155059 , 0.49290242, 0.51494141, 0.52307192, 0.49417919,\n",
       "        0.49538798, 0.49764005, 0.52985178, 0.48008157, 0.50330274,\n",
       "        0.51743287, 0.51967312, 0.5       , 0.5       , 0.5       ,\n",
       "        0.4931167 , 0.49281819, 0.51008261, 0.53563269, 0.47178851,\n",
       "        0.52222961, 0.5       , 0.5       , 0.5       , 0.50180136,\n",
       "        0.4946964 , 0.50563018, 0.50922256, 0.47541487, 0.52480679,\n",
       "        0.5       , 0.5       , 0.5       , 0.49374178, 0.51586056,\n",
       "        0.52672785, 0.53563269, 0.48964549, 0.48158   , 0.5       ,\n",
       "        0.5       , 0.48702546, 0.52723028, 0.49644752, 0.52008985,\n",
       "        0.48662204, 0.49447474, 0.4802589 , 0.5       , 0.5       ,\n",
       "        0.49136114, 0.5176368 , 0.49242512, 0.51436509, 0.47787383,\n",
       "        0.51274549, 0.51390404, 0.5       , 0.5       , 0.4832262 ,\n",
       "        0.50355248, 0.50922256, 0.52523237, 0.52031742, 0.47542079,\n",
       "        0.52369848, 0.5       , 0.48624374, 0.46548595, 0.52008985,\n",
       "        0.50927281, 0.4930768 , 0.48737273, 0.47934566, 0.51330112,\n",
       "        0.5       , 0.50681976, 0.50791181, 0.50477014, 0.48991739,\n",
       "        0.49155177, 0.51893721, 0.47933384, 0.51001759, 0.5       ,\n",
       "        0.49170694, 0.49882077, 0.53563269, 0.52476541, 0.52294484,\n",
       "        0.48899233, 0.49062671, 0.48054854, 0.51705162, 0.5290538 ,\n",
       "        0.51016831, 0.50107432, 0.5290538 , 0.52885283, 0.48983169,\n",
       "        0.5290538 , 0.5290538 , 0.50077581, 0.48004611, 0.48883569,\n",
       "        0.52599489, 0.47998995, 0.48004906, 0.48465074, 0.50570259,\n",
       "        0.50907774, 0.52767655, 0.50843641, 0.4905942 , 0.50414801,\n",
       "        0.49398708, 0.47573111, 0.49376838, 0.4881382 , 0.52767655,\n",
       "        0.5040889 , 0.51672356, 0.51732648, 0.48267352, 0.50277371,\n",
       "        0.49509243, 0.51654328, 0.48267352, 0.50856349, 0.49268076,\n",
       "        0.49997488, 0.50979888, 0.51291986, 0.47885505, 0.49815726,\n",
       "        0.50118071, 0.51383015, 0.49836414, 0.51880126, 0.50423963,\n",
       "        0.49908824, 0.53232847, 0.4785595 , 0.51364986, 0.52968923,\n",
       "        0.48113963, 0.52027309, 0.46956894, 0.47762853, 0.52471812,\n",
       "        0.52237147, 0.49210149, 0.51909385, 0.51595809, 0.48410693,\n",
       "        0.48404191, 0.52715343, 0.50700004, 0.4728111 , 0.51909385,\n",
       "        0.50696753, 0.50218557, 0.5223035 , 0.51909385, 0.49781443,\n",
       "        0.51665854, 0.52237147, 0.46960737, 0.51665854, 0.51909385,\n",
       "        0.49210149, 0.48090615, 0.50789851, 0.52715343]),\n",
       " 'std_test_roc_auc_ovo': array([0.02133767, 0.0230204 , 0.00838468, 0.04343333, 0.01990992,\n",
       "        0.03633652, 0.04074772, 0.02848525, 0.03104884, 0.00939362,\n",
       "        0.02495755, 0.01362244, 0.01448944, 0.01653889, 0.03601206,\n",
       "        0.02769504, 0.0390559 , 0.02432914, 0.02158396, 0.03449842,\n",
       "        0.01726826, 0.03492961, 0.02918622, 0.03093907, 0.04324424,\n",
       "        0.03084513, 0.02721207, 0.01771201, 0.02900218, 0.03048262,\n",
       "        0.03016426, 0.02780714, 0.02771607, 0.03962234, 0.0334031 ,\n",
       "        0.02509651, 0.0228955 , 0.02894596, 0.02614798, 0.05193325,\n",
       "        0.04067755, 0.05121029, 0.05405161, 0.0322187 , 0.02830894,\n",
       "        0.01946443, 0.0291995 , 0.03136778, 0.02663056, 0.04723963,\n",
       "        0.02116399, 0.06024881, 0.04795518, 0.02783031, 0.04002679,\n",
       "        0.02607149, 0.02080221, 0.02786108, 0.0560904 , 0.01649507,\n",
       "        0.03577281, 0.0494336 , 0.02822662, 0.01972387, 0.03082507,\n",
       "        0.03717677, 0.02788368, 0.02453755, 0.05298385, 0.00932421,\n",
       "        0.05201879, 0.02827724, 0.02409397, 0.03298291, 0.0370714 ,\n",
       "        0.04985278, 0.04420826, 0.04855841, 0.00967097, 0.05230008,\n",
       "        0.02925866, 0.04550047, 0.01662727, 0.00194236, 0.0214083 ,\n",
       "        0.0294737 , 0.04247131, 0.01859592, 0.02621084, 0.02287652,\n",
       "        0.03280179, 0.        , 0.01993377, 0.02137845, 0.02810136,\n",
       "        0.04265387, 0.01950889, 0.01892419, 0.02643776, 0.        ,\n",
       "        0.01701761, 0.02887986, 0.02145491, 0.02073529, 0.02922758,\n",
       "        0.0268702 , 0.02952053, 0.02119952, 0.0487418 , 0.02009332,\n",
       "        0.02784573, 0.01792057, 0.04115356, 0.01119828, 0.05009927,\n",
       "        0.01773419, 0.02851993, 0.0487418 , 0.01671284, 0.0275598 ,\n",
       "        0.00925695, 0.01709571, 0.03418718, 0.06204512, 0.03682917,\n",
       "        0.03718497, 0.0487418 , 0.01948814, 0.03885848, 0.03209897,\n",
       "        0.04233627, 0.06295551, 0.05839917, 0.0219996 , 0.01226844,\n",
       "        0.04602227, 0.01942428, 0.00784519, 0.03285649, 0.0256199 ,\n",
       "        0.02793035, 0.03455213, 0.02767013, 0.02703999, 0.03395556,\n",
       "        0.02767263, 0.02806998, 0.03738749, 0.00923895, 0.02006332,\n",
       "        0.02957134, 0.03189636, 0.0259183 , 0.02770911, 0.02495898,\n",
       "        0.01978519, 0.03617727, 0.01715746, 0.03727642, 0.04383546,\n",
       "        0.02996333, 0.0102689 , 0.        , 0.        , 0.        ,\n",
       "        0.02403812, 0.05891108, 0.03739353, 0.01517386, 0.0250454 ,\n",
       "        0.02027439, 0.        , 0.        , 0.        , 0.02959779,\n",
       "        0.0350536 , 0.03700156, 0.03761488, 0.01469063, 0.0310271 ,\n",
       "        0.        , 0.        , 0.        , 0.02276044, 0.03533239,\n",
       "        0.02802779, 0.01517386, 0.02621924, 0.03321554, 0.        ,\n",
       "        0.        , 0.01982613, 0.05270791, 0.02590957, 0.03311092,\n",
       "        0.03534111, 0.04992346, 0.03417846, 0.        , 0.        ,\n",
       "        0.02839241, 0.03263198, 0.02989713, 0.03596636, 0.01817856,\n",
       "        0.02889584, 0.03635189, 0.        , 0.        , 0.01684249,\n",
       "        0.02590957, 0.03761488, 0.02938132, 0.02916409, 0.02806868,\n",
       "        0.03087336, 0.        , 0.02405641, 0.03890001, 0.03311092,\n",
       "        0.03755074, 0.0373459 , 0.0403621 , 0.03565639, 0.0365768 ,\n",
       "        0.        , 0.04365871, 0.03623392, 0.03712223, 0.03739353,\n",
       "        0.02735847, 0.02894094, 0.03566088, 0.03760891, 0.        ,\n",
       "        0.02023751, 0.0387086 , 0.01517386, 0.02977599, 0.04062006,\n",
       "        0.01726776, 0.04014259, 0.03371087, 0.02508405, 0.00870883,\n",
       "        0.02857573, 0.03031193, 0.00870883, 0.00890402, 0.02857573,\n",
       "        0.00870883, 0.00870883, 0.0360788 , 0.02938578, 0.03372002,\n",
       "        0.02345872, 0.02946552, 0.02938398, 0.03200212, 0.03535205,\n",
       "        0.03434059, 0.01693106, 0.03134302, 0.0310513 , 0.03217835,\n",
       "        0.03190089, 0.02153308, 0.0317929 , 0.03019851, 0.01693106,\n",
       "        0.02107532, 0.01344125, 0.01267602, 0.01267602, 0.02128837,\n",
       "        0.02090508, 0.01368241, 0.01267602, 0.01968641, 0.02031842,\n",
       "        0.02151193, 0.01965682, 0.01744338, 0.00500399, 0.02158757,\n",
       "        0.02170577, 0.01684984, 0.02203931, 0.04411974, 0.04777095,\n",
       "        0.04795005, 0.03542469, 0.04289923, 0.04597521, 0.03766415,\n",
       "        0.04421708, 0.04345764, 0.02339183, 0.03118884, 0.02936394,\n",
       "        0.03118884, 0.03756115, 0.03329642, 0.03490797, 0.03491133,\n",
       "        0.03490797, 0.0271278 , 0.03773193, 0.02711107, 0.03329642,\n",
       "        0.03774494, 0.03832036, 0.03122294, 0.03329642, 0.03832036,\n",
       "        0.03457918, 0.03118884, 0.02342845, 0.03457918, 0.03329642,\n",
       "        0.03756115, 0.03329642, 0.03756115, 0.0271278 ]),\n",
       " 'rank_test_roc_auc_ovo': array([197, 265, 152, 224,  73, 267,  67,  28,  17, 317, 198, 105, 111,\n",
       "         64, 118,  26,  16,   8, 170, 217, 122, 234, 156,  38,  18,  10,\n",
       "          1, 109, 215, 160, 149, 219,  23,  20,  11,   2, 167, 216, 279,\n",
       "        273, 144,  19,  21,   9,   7, 266, 205, 162, 282,  25,  24,  29,\n",
       "         12,   6,  94, 222,  39, 240,  50,  30,  89,  13,   5, 171, 287,\n",
       "        166, 274,  27, 117, 251,  14,   3, 259, 316, 120, 311,  35, 226,\n",
       "        248,  15,   4, 302, 158, 196, 207, 209, 228, 201,  22, 116,  62,\n",
       "        175, 306, 211, 133, 218, 212,  31,  87, 175, 258, 140, 203,  74,\n",
       "        270, 202,  40,  72, 277, 214, 255, 263, 313,  97, 144, 124,  37,\n",
       "        277, 261, 260, 320, 264, 321, 130, 172,  80, 104, 230, 305,  90,\n",
       "        164, 309,  88, 123,  58, 308, 137, 289, 310, 102, 298, 233,  57,\n",
       "        146, 174, 244, 108, 161, 276, 284, 106, 237, 107,  65, 227, 220,\n",
       "        210,  41, 294, 157,  92,  79, 175, 175, 175, 235, 238, 126,  32,\n",
       "        319,  71, 175, 175, 175, 165, 223, 148, 131, 315,  59, 175, 175,\n",
       "        175, 232, 103,  54,  32, 254, 288, 175, 175, 269,  51, 213,  77,\n",
       "        271, 225, 293, 175, 175, 247,  91, 241, 110, 304, 121, 112, 175,\n",
       "        175, 283, 155, 131,  56,  75, 314,  63, 175, 272, 324,  77, 129,\n",
       "        236, 268, 299, 115, 175, 143, 138, 150, 252, 246,  85, 300, 127,\n",
       "        175, 245, 200,  32,  60,  66, 256, 249, 292,  95,  43, 125, 169,\n",
       "         43,  47, 253,  43,  43, 173, 296, 257,  55, 297, 295, 275, 147,\n",
       "        134,  48, 136, 250, 153, 229, 312, 231, 262,  48, 154,  96,  93,\n",
       "        285, 159, 221, 100, 285, 135, 239, 195, 128, 119, 301, 206, 168,\n",
       "        113, 204,  86, 151, 199,  36, 303, 114,  42, 290,  76, 323, 307,\n",
       "         61,  68, 242,  81, 101, 280, 281,  52, 141, 318,  81, 142, 163,\n",
       "         70,  81, 208,  98,  68, 322,  98,  81, 242, 291, 139,  52]),\n",
       " 'split0_test_neg_log_loss': array([-0.26133078, -0.26133237, -0.26133112, -0.26128397, -0.26128004,\n",
       "        -0.26144242, -0.26024001, -0.2619499 , -0.25055666, -0.2613309 ,\n",
       "        -0.26133348, -0.26121358, -0.26127901, -0.26119468, -0.26077859,\n",
       "        -0.26302639, -0.26131573, -0.24905308, -0.26240338, -0.26074837,\n",
       "        -0.26133086, -0.2613816 , -0.26121789, -0.26145254, -0.26230128,\n",
       "        -0.26059137, -0.24896935, -0.26110175, -0.26126648, -0.26132999,\n",
       "        -0.26123818, -0.26118301, -0.2622348 , -0.26387992, -0.26065396,\n",
       "        -0.24884123, -0.26167576, -0.26115329, -0.26135616, -0.2623098 ,\n",
       "        -0.2655316 , -0.26415657, -0.26436297, -0.26016985, -0.24846319,\n",
       "        -0.26125153, -0.26137742, -0.26138949, -0.26101744, -0.26380103,\n",
       "        -0.26027394, -0.26857181, -0.26418828, -0.24854036, -0.26119106,\n",
       "        -0.26120646, -0.26107209, -0.26133389, -0.26767885, -0.26159294,\n",
       "        -0.30171376, -0.26424312, -0.24819332, -0.26129666, -0.26155394,\n",
       "        -0.26183686, -0.26148547, -0.26367942, -3.92492954, -0.26171305,\n",
       "        -0.26504849, -0.24853399, -0.26151899, -0.2633646 , -0.26148251,\n",
       "        -0.26528939, -0.29042654, -0.26171844, -0.26159147, -0.26337985,\n",
       "        -0.24859888, -0.26133081, -0.26133076, -0.26133112, -0.26133086,\n",
       "        -0.26137825, -0.26133518, -0.26133664, -0.26234959, -0.26129934,\n",
       "        -0.26133078, -0.26133112, -0.26141192, -0.2613383 , -0.26129649,\n",
       "        -0.26132144, -0.26212621, -0.26257549, -0.26157166, -0.26133112,\n",
       "        -0.26134041, -0.26133864, -0.26134069, -0.26129615, -0.26144177,\n",
       "        -0.26134454, -0.26097349, -0.26041087, -0.2617757 , -0.26133081,\n",
       "        -0.26131522, -0.26135672, -0.26252827, -0.26120197, -0.26282575,\n",
       "        -0.26230055, -0.2607222 , -0.26141703, -0.26134806, -0.26144265,\n",
       "        -0.26191621, -0.26157766, -0.26204627, -0.26366155, -0.26256464,\n",
       "        -0.26088356, -0.26132778, -0.26134222, -0.26197541, -0.26116405,\n",
       "        -0.26015644, -0.26169155, -0.26290111, -0.2631731 , -0.26108796,\n",
       "        -0.26145707, -0.26122271, -0.26151545, -0.26235433, -0.26070603,\n",
       "        -0.26274528, -0.26423279, -0.26168414, -0.26093832, -0.26134242,\n",
       "        -0.26223709, -0.26092923, -0.26115068, -0.26143928, -0.26133882,\n",
       "        -0.26270557, -0.26197904, -0.26189758, -0.26100475, -0.26133083,\n",
       "        -0.26143249, -0.26127534, -0.26076261, -0.26221237, -0.26138437,\n",
       "        -0.26227649, -0.2611865 , -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133077, -0.26088364, -0.26217755,\n",
       "        -0.26122858, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26125423, -0.26088722, -0.26259684, -0.26103029,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26086471, -0.26092018, -0.26176721, -0.26106678, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26132876, -0.26091364,\n",
       "        -0.26175485, -0.26111471, -0.26134115, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.261323  , -0.26172056, -0.26174547,\n",
       "        -0.26114359, -0.26132959, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133079, -0.26119614, -0.26174071, -0.26097294, -0.26511137,\n",
       "        -0.26135034, -0.26133078, -0.26133078, -0.26133078, -0.2613304 ,\n",
       "        -0.26131948, -0.26112618, -0.26211816, -0.26128085, -0.26136667,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.2610738 , -0.2617837 ,\n",
       "        -0.26181392, -0.25998534, -0.26124735, -0.26170132, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26120441, -0.2610783 , -0.26132794,\n",
       "        -0.26191461, -0.26153926, -0.26139781, -0.26110286, -0.26132184,\n",
       "        -0.26093045, -0.26100093, -0.26119967, -0.26101509, -0.26141801,\n",
       "        -0.26087137, -0.2610898 , -0.26013315, -0.2626467 , -0.26175598,\n",
       "        -0.26024768, -0.26457628, -0.26150647, -0.26223638, -0.26493614,\n",
       "        -0.26082348, -0.26105833, -0.26102813, -0.26104984, -0.26126383,\n",
       "        -0.26110731, -0.26219171, -0.26170974, -0.26211037, -0.26097525,\n",
       "        -0.26105081, -0.26116829, -0.2612883 , -0.26182374, -0.26097157,\n",
       "        -0.26156513, -0.26108533, -0.2614191 , -0.26117607, -0.26131062,\n",
       "        -0.26136661, -0.26209214, -0.26127221, -0.26141194, -0.26190761,\n",
       "        -0.26127093, -0.26243291, -0.26161711, -0.26016358, -0.26060411,\n",
       "        -0.26014876, -0.26070219, -0.26257119, -0.26069547, -0.26056687,\n",
       "        -0.26364469, -0.26051907, -0.26180045, -0.26143956, -0.26085157,\n",
       "        -0.26104619, -0.26146106, -0.26126848, -0.26126528, -0.26193171,\n",
       "        -0.26137156, -0.2611247 , -0.2602765 , -0.26253682, -0.26076059,\n",
       "        -0.26100427, -0.26107056, -0.26083097, -0.26096796, -0.26140925,\n",
       "        -0.26111458, -0.26085221, -0.26141826, -0.26102316, -0.2609357 ,\n",
       "        -0.26253864, -0.26207976, -0.26125162, -0.26108592]),\n",
       " 'split1_test_neg_log_loss': array([-0.2613308 , -0.26133097, -0.26132199, -0.2614888 , -0.26125628,\n",
       "        -0.26133286, -0.26115224, -0.26293628, -0.24045   , -0.26133144,\n",
       "        -0.26132872, -0.26134361, -0.26132953, -0.26127741, -0.26137765,\n",
       "        -0.26132236, -0.25443505, -0.23351227, -0.26111891, -0.26131613,\n",
       "        -0.26132687, -0.26127738, -0.26137597, -0.26254815, -0.25813319,\n",
       "        -0.25103675, -0.23393929, -0.26131108, -0.26161679, -0.26130152,\n",
       "        -0.26134478, -0.26150042, -0.26090991, -0.26038773, -0.25195558,\n",
       "        -0.23334331, -0.2615142 , -0.2612552 , -0.26156442, -0.26203416,\n",
       "        -0.26219672, -0.25880546, -0.25998074, -0.25094999, -0.23387988,\n",
       "        -0.2613603 , -0.26136682, -0.26108042, -0.26317213, -0.26222805,\n",
       "        -0.26281995, -0.26156025, -0.25228725, -0.23383545, -0.26106071,\n",
       "        -0.2611708 , -0.26093378, -0.26135191, -0.26068497, -0.26016604,\n",
       "        -0.26931393, -0.25332153, -0.23393358, -0.26153936, -0.26276096,\n",
       "        -0.26147082, -0.26243597, -0.26061055, -6.01905203, -0.26140033,\n",
       "        -0.25479177, -0.23389485, -0.26193025, -0.26232675, -0.26119011,\n",
       "        -0.26137811, -0.31504877, -0.26234198, -0.26147294, -0.25520572,\n",
       "        -0.23394964, -0.26133078, -0.26133078, -0.26133348, -0.26133024,\n",
       "        -0.26130633, -0.26131255, -0.26120773, -0.25990459, -0.26099313,\n",
       "        -0.26133078, -0.26133112, -0.261333  , -0.26129127, -0.26132716,\n",
       "        -0.26119098, -0.26154807, -0.26101493, -0.26118484, -0.26133112,\n",
       "        -0.26144242, -0.26133178, -0.2613225 , -0.26119065, -0.26122194,\n",
       "        -0.26132171, -0.26119854, -0.26115905, -0.2612126 , -0.26133601,\n",
       "        -0.26133767, -0.26139247, -0.26146925, -0.26132238, -0.26088562,\n",
       "        -0.26160477, -0.2607724 , -0.26128789, -0.26135171, -0.26133033,\n",
       "        -0.26195982, -0.26152916, -0.26117224, -0.26117195, -0.26188769,\n",
       "        -0.26043031, -0.26142779, -0.26140243, -0.261624  , -0.26060159,\n",
       "        -0.26381184, -0.26132895, -0.26115056, -0.26137184, -0.26133036,\n",
       "        -0.26124611, -0.26678991, -0.26141278, -0.26159481, -0.26226417,\n",
       "        -0.26258108, -0.26119139, -0.26123849, -0.26125281, -0.2611078 ,\n",
       "        -0.26129255, -0.26146947, -0.26138112, -0.26178646, -0.26273009,\n",
       "        -0.26133192, -0.26159335, -0.26069284, -0.26133825, -0.26117104,\n",
       "        -0.26134038, -0.26135409, -0.26150144, -0.26127181, -0.26122823,\n",
       "        -0.26136779, -0.26097452, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133077, -0.26129005, -0.26194875,\n",
       "        -0.26121261, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.261329  , -0.26177801, -0.26168597, -0.2609765 ,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26128061, -0.26132397, -0.2618157 , -0.2919303 , -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133084, -0.26158933,\n",
       "        -0.26213491, -0.26253638, -0.26148058, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133112, -0.26132562, -0.26148482,\n",
       "        -0.26129333, -0.26199552, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26139284, -0.26128996, -0.26078814, -0.26325067,\n",
       "        -0.26130652, -0.26133078, -0.26133078, -0.26133078, -0.2613311 ,\n",
       "        -0.26201375, -0.26130133, -0.26176839, -0.26223951, -0.26151272,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26135337, -0.26167119,\n",
       "        -0.26104277, -0.26111991, -0.26244497, -0.26140849, -0.26133078,\n",
       "        -0.26133078, -0.26133079, -0.26130754, -0.26129001, -0.26038512,\n",
       "        -0.29932839, -0.2616407 , -0.26189017, -0.26119209, -0.26127019,\n",
       "        -0.26125684, -0.26133915, -0.26132127, -0.2612104 , -0.26133299,\n",
       "        -0.26119482, -0.2612203 , -0.2614547 , -0.26302113, -0.2614661 ,\n",
       "        -0.26116955, -0.26137213, -0.26143123, -0.26201513, -0.2613517 ,\n",
       "        -0.26113494, -0.26100861, -0.26225932, -0.26150229, -0.26090971,\n",
       "        -0.26279231, -0.26149092, -0.26080136, -0.26080396, -0.2611846 ,\n",
       "        -0.2615896 , -0.26119853, -0.26116444, -0.26145266, -0.26125855,\n",
       "        -0.26131267, -0.26128626, -0.26146229, -0.2613123 , -0.26136389,\n",
       "        -0.26219986, -0.26124538, -0.26202938, -0.26148073, -0.26140319,\n",
       "        -0.26545907, -0.26126536, -0.26139291, -0.26136186, -0.26174697,\n",
       "        -0.26142466, -0.26095173, -0.2611566 , -0.26155215, -0.26074694,\n",
       "        -0.26129946, -0.2606781 , -0.26144106, -0.26143588, -0.26152202,\n",
       "        -0.26121121, -0.26139945, -0.26128846, -0.26123431, -0.26236907,\n",
       "        -0.26163161, -0.26125092, -0.2614469 , -0.26220192, -0.26118046,\n",
       "        -0.26137905, -0.26136172, -0.26121927, -0.26128772, -0.26116915,\n",
       "        -0.26167453, -0.26119222, -0.26144321, -0.26191533, -0.26121919,\n",
       "        -0.26139969, -0.26171795, -0.26117416, -0.26121448]),\n",
       " 'split2_test_neg_log_loss': array([-0.26133078, -0.26133075, -0.26133112, -0.26135016, -0.26132962,\n",
       "        -0.26137829, -0.26100495, -0.26077713, -0.23588085, -0.26133079,\n",
       "        -0.26133112, -0.2612905 , -0.26133094, -0.26134318, -0.26123674,\n",
       "        -0.26198894, -0.25672993, -0.22586022, -0.26133112, -0.26195522,\n",
       "        -0.26133913, -0.26131735, -0.26140842, -0.26125984, -0.25876449,\n",
       "        -0.25230748, -0.22536145, -0.26112711, -0.2612451 , -0.26132929,\n",
       "        -0.26158023, -0.26158215, -0.25738742, -0.25793454, -0.25203901,\n",
       "        -0.22595584, -0.2611692 , -0.26175714, -0.26134422, -0.2613139 ,\n",
       "        -0.26111964, -0.25924994, -0.25826732, -0.25199965, -0.22466011,\n",
       "        -0.26146985, -0.26143337, -0.26095462, -0.26151097, -0.25729281,\n",
       "        -0.259754  , -0.25904567, -0.24943119, -0.22480384, -0.26135053,\n",
       "        -0.26167939, -0.26201645, -0.26338516, -0.26344342, -0.26044863,\n",
       "        -0.26459328, -0.2502387 , -0.22490758, -0.26150895, -0.26152565,\n",
       "        -0.26124492, -0.26216923, -0.26199877, -1.43263292, -0.26149507,\n",
       "        -0.24782719, -0.22501204, -0.26175971, -0.26333357, -0.26126592,\n",
       "        -0.26105531, -0.30672546, -0.26079921, -0.26133625, -0.24783395,\n",
       "        -0.22477529, -0.26133079, -0.26133079, -0.26133112, -0.26146064,\n",
       "        -0.26120894, -0.26133766, -0.26133092, -0.26041347, -0.26133238,\n",
       "        -0.26133079, -0.26133112, -0.2614809 , -0.26140703, -0.26131822,\n",
       "        -0.26129216, -0.26250254, -0.26100337, -0.26062743, -0.26133112,\n",
       "        -0.26137136, -0.26136312, -0.26150026, -0.26120998, -0.2613096 ,\n",
       "        -0.26162606, -0.26048104, -0.26132776, -0.2614526 , -0.26130959,\n",
       "        -0.26134396, -0.26150584, -0.2613982 , -0.26145394, -0.26201465,\n",
       "        -0.26145081, -0.25977995, -0.26147862, -0.26131094, -0.2612962 ,\n",
       "        -0.26139698, -0.26142426, -0.26176481, -0.26117891, -0.26150521,\n",
       "        -0.26179595, -0.26123348, -0.26131098, -0.26183148, -0.26135796,\n",
       "        -0.2618796 , -0.26196683, -0.26047199, -0.26116069, -0.26101232,\n",
       "        -0.26133576, -0.26132775, -0.26147047, -0.26138211, -0.26126458,\n",
       "        -0.26546148, -0.26140496, -0.26111602, -0.26193799, -0.26155216,\n",
       "        -0.26152498, -0.26147931, -0.26203381, -0.26173671, -0.26298557,\n",
       "        -0.26108448, -0.26119758, -0.26109675, -0.26114031, -0.26131316,\n",
       "        -0.26134085, -0.26140881, -0.26209496, -0.26161316, -0.25858952,\n",
       "        -0.26114984, -0.26130084, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133068, -0.26107662, -0.26130891,\n",
       "        -0.26130744, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26126922, -0.26158529, -0.2615616 , -0.26211098,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26133079,\n",
       "        -0.26128922, -0.26117829, -0.26139871, -0.29433843, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26126544,\n",
       "        -0.26205259, -0.26241899, -0.26344814, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133112, -0.26173398, -0.26158781,\n",
       "        -0.26159671, -0.26066877, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26179006, -0.26115909, -0.26168127, -0.27904379,\n",
       "        -0.26083308, -0.26133078, -0.26133078, -0.26133078, -0.26133077,\n",
       "        -0.26158772, -0.26220265, -0.26128707, -0.26177037, -0.26069817,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26136056, -0.26167303,\n",
       "        -0.26155481, -0.26120875, -0.26201863, -0.26109391, -0.26133078,\n",
       "        -0.26133078, -0.26133079, -0.26119175, -0.2617645 , -0.26254142,\n",
       "        -0.33706176, -0.26234056, -0.2617553 , -0.26126611, -0.26118811,\n",
       "        -0.26190003, -0.26143768, -0.26117835, -0.2614356 , -0.26121246,\n",
       "        -0.26114696, -0.26123719, -0.26135194, -0.26141788, -0.26136156,\n",
       "        -0.26135682, -0.2613487 , -0.26134796, -0.26144862, -0.26133476,\n",
       "        -0.26140164, -0.26133364, -0.26147523, -0.26134274, -0.26133688,\n",
       "        -0.26138364, -0.2613258 , -0.26132265, -0.2613395 , -0.26132768,\n",
       "        -0.26134042, -0.26161166, -0.26153608, -0.26146586, -0.26133453,\n",
       "        -0.26157972, -0.26134706, -0.26137545, -0.26143712, -0.26149202,\n",
       "        -0.2613167 , -0.26132092, -0.2612257 , -0.26170146, -0.26191284,\n",
       "        -0.26132774, -0.26113036, -0.26147224, -0.26116261, -0.26177935,\n",
       "        -0.26151834, -0.26119758, -0.26165613, -0.26121581, -0.26125631,\n",
       "        -0.26144652, -0.26134462, -0.26145949, -0.26133528, -0.26130878,\n",
       "        -0.26135964, -0.26139231, -0.26139996, -0.26130077, -0.26140463,\n",
       "        -0.26137585, -0.26139257, -0.26187898, -0.2613005 , -0.26133573,\n",
       "        -0.26148833, -0.26130037, -0.26131381, -0.26133322, -0.26142842,\n",
       "        -0.26131879, -0.26129942, -0.26232137, -0.26129956, -0.26137897,\n",
       "        -0.26135107, -0.26142702, -0.26132119, -0.26133267]),\n",
       " 'split3_test_neg_log_loss': array([-0.26133078, -0.26133164, -0.26133112, -0.2613195 , -0.26132294,\n",
       "        -0.26121887, -0.26136298, -0.2597959 , -0.24874667, -0.26133163,\n",
       "        -0.26133069, -0.26128495, -0.26131196, -0.26133008, -0.26192044,\n",
       "        -0.26000579, -0.25092801, -0.23940953, -0.26133112, -0.2615251 ,\n",
       "        -0.26131804, -0.26135077, -0.26144411, -0.25977779, -0.25838367,\n",
       "        -0.25149687, -0.23905216, -0.26132077, -0.2615235 , -0.26136369,\n",
       "        -0.26131391, -0.26116688, -0.25903808, -0.25732264, -0.25082939,\n",
       "        -0.2393068 , -0.26131259, -0.26174284, -0.26142339, -0.26042543,\n",
       "        -0.26023795, -0.25565274, -0.26053373, -0.25061193, -0.23676715,\n",
       "        -0.26142467, -0.26127742, -0.26157833, -0.26152201, -0.2585414 ,\n",
       "        -0.25957672, -0.25891642, -0.24962669, -0.23674514, -0.26142026,\n",
       "        -0.26135048, -0.26203796, -0.26114704, -0.25658198, -0.25952437,\n",
       "        -0.26381719, -0.25319205, -0.23680362, -0.26129715, -0.26136683,\n",
       "        -0.26110425, -0.260946  , -0.25801557, -1.79147848, -0.26148382,\n",
       "        -0.25357807, -0.23686488, -0.26141091, -0.2623193 , -0.26059939,\n",
       "        -0.26179028, -0.28097349, -0.26087815, -0.26186515, -0.25395019,\n",
       "        -0.23673876, -0.26133078, -0.26133079, -0.26133112, -0.26132679,\n",
       "        -0.26139761, -0.26120208, -0.26143648, -0.26047532, -0.26185601,\n",
       "        -0.26133039, -0.26133112, -0.2615694 , -0.26138024, -0.2614229 ,\n",
       "        -0.26153593, -0.26114794, -0.26117443, -0.26171691, -0.26133112,\n",
       "        -0.26138494, -0.26131587, -0.26130526, -0.26135228, -0.26224023,\n",
       "        -0.26132322, -0.26114754, -0.26217234, -0.26153921, -0.26131448,\n",
       "        -0.26169645, -0.26131102, -0.26120702, -0.26132725, -0.26135263,\n",
       "        -0.26103029, -0.26223003, -0.26138853, -0.26135408, -0.26133232,\n",
       "        -0.26219339, -0.2614126 , -0.26150502, -0.26266797, -0.26191745,\n",
       "        -0.26153813, -0.26119115, -0.26140006, -0.26172847, -0.26144616,\n",
       "        -0.26132119, -0.26127931, -0.26068434, -0.26224279, -0.26224658,\n",
       "        -0.26165242, -0.26110928, -0.26357998, -0.26222717, -0.26136958,\n",
       "        -0.26337822, -0.26144857, -0.26055888, -0.26249587, -0.26114169,\n",
       "        -0.26112445, -0.26134884, -0.2614465 , -0.2613741 , -0.26368364,\n",
       "        -0.26077415, -0.26141352, -0.26138564, -0.26102484, -0.26311543,\n",
       "        -0.26198799, -0.26133674, -0.26110727, -0.26125092, -0.26206716,\n",
       "        -0.26124802, -0.26159325, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133068, -0.26130101, -0.26148884,\n",
       "        -0.26145549, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133112, -0.26131955, -0.26170142, -0.2607931 ,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.2613373 , -0.26130529, -0.26148731, -0.26249659, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26130433,\n",
       "        -0.26156983, -0.26095285, -0.26106409, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133112, -0.26130257, -0.26129148,\n",
       "        -0.26140474, -0.26120953, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133079, -0.26131234, -0.26133343, -0.26136645, -0.26133552,\n",
       "        -0.26118214, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26130933, -0.2620326 , -0.26133705, -0.26185824, -0.26118456,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133112, -0.26135484,\n",
       "        -0.26129709, -0.26201002, -0.2616011 , -0.26107491, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26135153, -0.26136187, -0.26127873,\n",
       "        -0.2613799 , -0.26110457, -0.26117911, -0.26121069, -0.2611958 ,\n",
       "        -0.26135033, -0.26153091, -0.26129628, -0.26122344, -0.26122228,\n",
       "        -0.26117902, -0.26123747, -0.26111014, -0.26110914, -0.26166066,\n",
       "        -0.26116471, -0.26129837, -0.26120216, -0.26218769, -0.26125082,\n",
       "        -0.26178354, -0.261241  , -0.26075099, -0.26200778, -0.26207593,\n",
       "        -0.26179337, -0.2618364 , -0.26177905, -0.26194248, -0.26081463,\n",
       "        -0.26130599, -0.26131289, -0.26132143, -0.2613452 , -0.26140586,\n",
       "        -0.26169379, -0.26133157, -0.2614124 , -0.26131192, -0.26134322,\n",
       "        -0.26188546, -0.26131686, -0.26131199, -0.26135878, -0.26139948,\n",
       "        -0.26140037, -0.26137152, -0.26135789, -0.26172976, -0.26135003,\n",
       "        -0.26141816, -0.26130696, -0.26139548, -0.26156909, -0.26146482,\n",
       "        -0.26127882, -0.26169091, -0.26159053, -0.26139769, -0.26106858,\n",
       "        -0.26114739, -0.26122249, -0.26111041, -0.26138976, -0.26124955,\n",
       "        -0.26124699, -0.26128395, -0.26189937, -0.26155082, -0.2612364 ,\n",
       "        -0.26143197, -0.26188695, -0.26123718, -0.26126154, -0.26105556,\n",
       "        -0.26119046, -0.26112053, -0.26201538, -0.26112957, -0.26122539,\n",
       "        -0.26131379, -0.26150347, -0.26137562, -0.26115939]),\n",
       " 'split4_test_neg_log_loss': array([-0.26133078, -0.26133088, -0.26133112, -0.26142268, -0.26130739,\n",
       "        -0.26134591, -0.26138845, -0.25743457, -0.22963454, -0.26133166,\n",
       "        -0.26122993, -0.26129001, -0.26117073, -0.26132363, -0.26209967,\n",
       "        -0.26735741, -0.25357831, -0.22452904, -0.26133112, -0.26157245,\n",
       "        -0.26132228, -0.26143582, -0.26131165, -0.26178977, -0.25914898,\n",
       "        -0.25063394, -0.2244348 , -0.26134004, -0.26136587, -0.26129591,\n",
       "        -0.2613746 , -0.26196137, -0.26159338, -0.26048618, -0.25140649,\n",
       "        -0.22474104, -0.26128806, -0.26191954, -0.26126541, -0.26133379,\n",
       "        -0.26159278, -0.25941411, -0.25759134, -0.25051299, -0.22325325,\n",
       "        -0.26142035, -0.26121883, -0.26291594, -0.2614201 , -0.26523315,\n",
       "        -0.26190636, -0.25909559, -0.25165337, -0.22310009, -0.26171235,\n",
       "        -0.26134993, -0.26050315, -0.26453847, -0.26451767, -0.26164875,\n",
       "        -0.3268232 , -0.25293358, -0.22327154, -0.26133791, -0.26133936,\n",
       "        -0.26239682, -0.2634462 , -0.26103391, -2.40710847, -0.2615251 ,\n",
       "        -0.2523177 , -0.22336618, -0.26124826, -0.26155119, -0.26294334,\n",
       "        -0.26284561, -0.35126733, -0.26142415, -0.26172308, -0.25378075,\n",
       "        -0.22356367, -0.26133078, -0.26133078, -0.26133107, -0.26134323,\n",
       "        -0.26141539, -0.26138031, -0.2614975 , -0.26068744, -0.26129451,\n",
       "        -0.26133112, -0.26133112, -0.26141544, -0.2613307 , -0.26145478,\n",
       "        -0.26141147, -0.26196711, -0.26117946, -0.2614242 , -0.26133112,\n",
       "        -0.26122145, -0.26132315, -0.26133097, -0.26124938, -0.26238995,\n",
       "        -0.26117104, -0.26134219, -0.26126236, -0.26132831, -0.26149659,\n",
       "        -0.26141129, -0.26133142, -0.26138398, -0.26114679, -0.26132945,\n",
       "        -0.26261234, -0.26117107, -0.26132771, -0.26133314, -0.26131404,\n",
       "        -0.26141423, -0.261217  , -0.26135071, -0.26105791, -0.26129732,\n",
       "        -0.26158908, -0.26133705, -0.26117776, -0.26143099, -0.26114349,\n",
       "        -0.26131739, -0.26169164, -0.26264334, -0.26148882, -0.26201659,\n",
       "        -0.26134049, -0.26158687, -0.26193541, -0.26114856, -0.26134382,\n",
       "        -0.26288513, -0.26117726, -0.26124743, -0.26130177, -0.26136586,\n",
       "        -0.26221085, -0.26136192, -0.26163482, -0.26195103, -0.26140165,\n",
       "        -0.26114504, -0.26149452, -0.26172915, -0.26139619, -0.26172055,\n",
       "        -0.2613443 , -0.26148356, -0.26098668, -0.26182385, -0.26161687,\n",
       "        -0.26115321, -0.26149736, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133081, -0.26102749, -0.26138055,\n",
       "        -0.26133041, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26136073, -0.26074657, -0.26159484, -0.26147722,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26133075,\n",
       "        -0.26067624, -0.2607107 , -0.26108418, -0.26267653, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133112, -0.26114186,\n",
       "        -0.26092801, -0.26135605, -0.26134447, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133463, -0.26066155, -0.26151646,\n",
       "        -0.26133685, -0.26140682, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133112, -0.26112094, -0.26081719, -0.26133053, -0.26179162,\n",
       "        -0.26172934, -0.26133078, -0.26133078, -0.26133112, -0.26133055,\n",
       "        -0.26038733, -0.26265351, -0.26112607, -0.2614858 , -0.26207859,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26116485, -0.2609535 ,\n",
       "        -0.26133992, -0.26130656, -0.26156298, -0.26140749, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26039453, -0.26085623, -0.26160807,\n",
       "        -0.26132181, -0.26143236, -0.26174426, -0.26163372, -0.26123828,\n",
       "        -0.26130038, -0.26127826, -0.26121866, -0.26108049, -0.26202145,\n",
       "        -0.2612629 , -0.26123978, -0.26139666, -0.26243966, -0.26098169,\n",
       "        -0.26125482, -0.26179677, -0.26292695, -0.26092007, -0.26087875,\n",
       "        -0.26157234, -0.26135937, -0.26133219, -0.26132746, -0.2613412 ,\n",
       "        -0.26134644, -0.26161805, -0.2614334 , -0.26140151, -0.26138327,\n",
       "        -0.26181077, -0.2613132 , -0.26109651, -0.26133578, -0.26142349,\n",
       "        -0.26118501, -0.26126609, -0.26150905, -0.2614865 , -0.26151535,\n",
       "        -0.26128235, -0.26161944, -0.2611245 , -0.26238316, -0.2611951 ,\n",
       "        -0.26179651, -0.2611039 , -0.2610564 , -0.26125409, -0.26132858,\n",
       "        -0.26151786, -0.26134914, -0.26136475, -0.26133389, -0.26151915,\n",
       "        -0.26142994, -0.26125487, -0.26146792, -0.26128073, -0.26125731,\n",
       "        -0.26189925, -0.26125642, -0.26145533, -0.26125091, -0.26138767,\n",
       "        -0.26154329, -0.26129919, -0.26131831, -0.26139277, -0.2616728 ,\n",
       "        -0.26125234, -0.26166996, -0.26222383, -0.26147297, -0.26126136,\n",
       "        -0.26147407, -0.26160454, -0.26135373, -0.26143503, -0.26177546,\n",
       "        -0.26131484, -0.26126669, -0.26158416, -0.2613125 ]),\n",
       " 'mean_test_neg_log_loss': array([-0.26133079, -0.26133132, -0.26132929, -0.26137302, -0.26129925,\n",
       "        -0.26134367, -0.26102972, -0.26057875, -0.24105374, -0.26133128,\n",
       "        -0.26131079, -0.26128453, -0.26128443, -0.2612938 , -0.26148262,\n",
       "        -0.26274018, -0.2553974 , -0.23447283, -0.26150313, -0.26142345,\n",
       "        -0.26132744, -0.26135258, -0.26135161, -0.26136562, -0.25934632,\n",
       "        -0.25321328, -0.23435141, -0.26124015, -0.26140355, -0.26132408,\n",
       "        -0.26137034, -0.26147877, -0.26023272, -0.2600022 , -0.25337689,\n",
       "        -0.23443764, -0.26139196, -0.2615656 , -0.26139072, -0.26148342,\n",
       "        -0.26213574, -0.25945576, -0.26014722, -0.25284888, -0.23340472,\n",
       "        -0.26138534, -0.26133477, -0.26158376, -0.26172853, -0.26141929,\n",
       "        -0.26086619, -0.26143795, -0.25343736, -0.23340498, -0.26134698,\n",
       "        -0.26135141, -0.26131269, -0.26235129, -0.26258138, -0.26067614,\n",
       "        -0.28525227, -0.2547858 , -0.23342193, -0.26139601, -0.26170935,\n",
       "        -0.26161074, -0.26209657, -0.26106764, -3.11504029, -0.26152347,\n",
       "        -0.25471264, -0.23353439, -0.26157363, -0.26257908, -0.26149625,\n",
       "        -0.26247174, -0.30888832, -0.26143239, -0.26159778, -0.25483009,\n",
       "        -0.23352525, -0.26133079, -0.26133078, -0.26133158, -0.26135835,\n",
       "        -0.2613413 , -0.26131356, -0.26136185, -0.26076608, -0.26135507,\n",
       "        -0.26133077, -0.26133112, -0.26144213, -0.26134951, -0.26136391,\n",
       "        -0.2613504 , -0.26185837, -0.26138954, -0.26130501, -0.26133112,\n",
       "        -0.26135212, -0.26133451, -0.26135994, -0.26125969, -0.2617207 ,\n",
       "        -0.26135731, -0.26102856, -0.26126648, -0.26146169, -0.26135749,\n",
       "        -0.26142092, -0.26137949, -0.26159735, -0.26129047, -0.26168162,\n",
       "        -0.26179975, -0.26093513, -0.26137996, -0.26133959, -0.26134311,\n",
       "        -0.26177613, -0.26143214, -0.26156781, -0.26194766, -0.26183446,\n",
       "        -0.26124741, -0.26130345, -0.26132669, -0.26171807, -0.26114265,\n",
       "        -0.26169729, -0.26159166, -0.26157027, -0.26188745, -0.26153876,\n",
       "        -0.26140637, -0.2624073 , -0.26198282, -0.2617414 , -0.26138964,\n",
       "        -0.26341024, -0.26189099, -0.26116899, -0.26158535, -0.26130199,\n",
       "        -0.26167798, -0.26131775, -0.26152938, -0.26165752, -0.26242795,\n",
       "        -0.26140823, -0.2615356 , -0.26136039, -0.26118087, -0.2617302 ,\n",
       "        -0.2614892 , -0.26137171, -0.26129059, -0.26163442, -0.26097723,\n",
       "        -0.26143907, -0.26131049, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133074, -0.26111576, -0.26166092,\n",
       "        -0.26130691, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26130886, -0.26126333, -0.26182813, -0.26127762,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26108961, -0.26108769, -0.26151062, -0.27450173, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26133046, -0.26124292,\n",
       "        -0.26168804, -0.2616758 , -0.26173569, -0.26133078, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.2613302 , -0.26134886, -0.26152521,\n",
       "        -0.26135504, -0.26132205, -0.26133078, -0.26133078, -0.26133078,\n",
       "        -0.26133085, -0.26136247, -0.26126808, -0.26122787, -0.26610659,\n",
       "        -0.26128028, -0.26133078, -0.26133078, -0.26133085, -0.26133072,\n",
       "        -0.26132352, -0.26186325, -0.26152735, -0.26172695, -0.26136814,\n",
       "        -0.26133078, -0.26133078, -0.26133078, -0.26125674, -0.26148725,\n",
       "        -0.2614097 , -0.26112611, -0.26177501, -0.26133723, -0.26133078,\n",
       "        -0.26133078, -0.26133078, -0.26108995, -0.26127018, -0.26142825,\n",
       "        -0.28420129, -0.26161149, -0.26159333, -0.26128109, -0.26124285,\n",
       "        -0.2613476 , -0.26131738, -0.26124285, -0.26119301, -0.26144144,\n",
       "        -0.26113102, -0.26120491, -0.26108932, -0.2621269 , -0.2614452 ,\n",
       "        -0.26103871, -0.26207845, -0.26168295, -0.26176158, -0.26195043,\n",
       "        -0.26134319, -0.26120019, -0.26136917, -0.26144602, -0.26138551,\n",
       "        -0.26168461, -0.26169257, -0.26140924, -0.26151956, -0.26113709,\n",
       "        -0.26141952, -0.26132091, -0.26128135, -0.26148465, -0.2612788 ,\n",
       "        -0.26146727, -0.26126326, -0.26143566, -0.26134478, -0.26140502,\n",
       "        -0.2616102 , -0.26151895, -0.26139276, -0.26166721, -0.26156365,\n",
       "        -0.26225092, -0.26146081, -0.26137931, -0.26113438, -0.26136181,\n",
       "        -0.26120556, -0.26110152, -0.26162883, -0.26127328, -0.26111082,\n",
       "        -0.26181989, -0.26109752, -0.26155189, -0.26137783, -0.26120165,\n",
       "        -0.26133274, -0.26134635, -0.26130453, -0.26128821, -0.26166853,\n",
       "        -0.26143386, -0.26127027, -0.26136401, -0.26179657, -0.26123719,\n",
       "        -0.26131119, -0.26145791, -0.26136501, -0.26126468, -0.26126475,\n",
       "        -0.26135449, -0.26121379, -0.26171039, -0.26136053, -0.26130694,\n",
       "        -0.26158361, -0.26159898, -0.26134135, -0.26122099]),\n",
       " 'std_test_neg_log_loss': array([6.25761201e-09, 6.09615749e-07, 3.65153928e-06, 7.37403826e-05,\n",
       "        2.74415769e-05, 7.30023175e-05, 4.19290108e-04, 1.89610392e-03,\n",
       "        7.83591822e-03, 3.69153079e-07, 4.04561433e-05, 4.14479426e-05,\n",
       "        5.98537200e-05, 5.42928981e-05, 4.77403925e-04, 2.50807374e-03,\n",
       "        3.49322114e-03, 9.06568752e-03, 4.57567354e-04, 3.95616761e-04,\n",
       "        7.26132134e-06, 5.41684693e-05, 7.98193509e-05, 9.07549784e-04,\n",
       "        1.51707812e-03, 3.73076410e-03, 9.11163548e-03, 1.03384456e-04,\n",
       "        1.45033578e-04, 2.42205033e-05, 1.14347618e-04, 2.92852779e-04,\n",
       "        1.77995377e-03, 2.31839623e-03, 3.66436842e-03, 8.92563358e-03,\n",
       "        1.80113696e-04, 3.03224078e-04, 1.00296315e-04, 6.56762094e-04,\n",
       "        1.81463414e-03, 2.72130689e-03, 2.36711517e-03, 3.69821141e-03,\n",
       "        9.14122318e-03, 7.54263216e-05, 7.65494638e-05, 7.01663603e-04,\n",
       "        7.44951133e-04, 3.03915398e-03, 1.27668297e-03, 3.70066576e-03,\n",
       "        5.48923108e-03, 9.17160767e-03, 2.21422271e-04, 1.79555821e-04,\n",
       "        6.12879474e-04, 1.36650677e-03, 3.74341480e-03, 8.27651022e-04,\n",
       "        2.50575713e-02, 4.86275501e-03, 9.00462583e-03, 1.06136840e-04,\n",
       "        5.32541633e-04, 4.64541822e-04, 8.53141204e-04, 1.85545890e-03,\n",
       "        1.68360819e+00, 1.03427696e-04, 5.67923141e-03, 9.08001257e-03,\n",
       "        2.43773820e-04, 6.89060129e-04, 7.80435093e-04, 1.53268479e-03,\n",
       "        2.43256439e-02, 5.68743797e-04, 1.85047201e-04, 4.98118088e-03,\n",
       "        9.09413074e-03, 8.61598418e-09, 8.04050116e-09, 9.47081389e-07,\n",
       "        5.14459922e-05, 7.58533863e-05, 5.98869834e-05, 9.93128885e-05,\n",
       "        8.32431791e-04, 2.79010556e-04, 2.30433652e-07, 0.00000000e+00,\n",
       "        7.90367330e-05, 4.03110689e-05, 6.28021569e-05, 1.16443617e-04,\n",
       "        4.68937091e-04, 5.97721956e-04, 3.81711221e-04, 0.00000000e+00,\n",
       "        7.32299967e-05, 1.62465015e-05, 7.11199705e-05, 5.87298472e-05,\n",
       "        4.92621064e-04, 1.47998094e-04, 2.98070576e-04, 5.59992587e-04,\n",
       "        1.92110277e-04, 7.02367318e-05, 1.41448535e-04, 6.87759455e-05,\n",
       "        4.73405752e-04, 1.07302875e-04, 6.76139551e-04, 5.76707999e-04,\n",
       "        7.92299013e-04, 6.69127026e-05, 1.60688310e-05, 5.14475540e-05,\n",
       "        3.16923065e-04, 1.24353861e-04, 3.08310452e-04, 1.04313182e-03,\n",
       "        4.33547518e-04, 5.10334841e-04, 8.32936940e-05, 8.22057550e-05,\n",
       "        1.84639268e-04, 2.93829061e-04, 1.19704343e-03, 2.55851444e-04,\n",
       "        1.00894407e-03, 7.39204010e-04, 5.00624619e-04, 1.40086861e-04,\n",
       "        2.19699434e-03, 8.19639971e-04, 4.71952161e-04, 5.00054528e-04,\n",
       "        1.05962656e-03, 1.17599878e-03, 3.60943642e-04, 5.59118565e-04,\n",
       "        1.62297735e-04, 4.63663992e-04, 2.01488211e-04, 2.95915095e-04,\n",
       "        2.17716134e-04, 9.18530735e-04, 6.73060964e-04, 2.57223955e-04,\n",
       "        4.33663381e-04, 1.60086348e-04, 7.16243683e-04, 2.51855664e-04,\n",
       "        7.02930545e-05, 4.68230632e-04, 3.60254895e-04, 1.22694665e-03,\n",
       "        4.26199981e-04, 2.20554743e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.61667305e-14, 9.99535892e-14, 5.33134304e-08,\n",
       "        1.59937277e-04, 3.41141706e-04, 8.67833671e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.69828966e-14, 1.24024525e-11,\n",
       "        4.03676275e-05, 3.95022241e-04, 3.87978746e-04, 4.73484666e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.29444999e-13, 4.06423520e-15,\n",
       "        1.21448373e-08, 2.68004108e-04, 2.37304300e-04, 2.66018272e-04,\n",
       "        1.52427446e-02, 0.00000000e+00, 0.00000000e+00, 2.18401215e-14,\n",
       "        1.67316449e-11, 8.56263873e-07, 2.20415845e-04, 4.30970044e-04,\n",
       "        6.68229349e-04, 8.66871959e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.39452484e-14, 2.14338589e-11, 3.84929641e-06, 3.90269001e-04,\n",
       "        1.47492978e-04, 1.48137290e-04, 4.24320173e-04, 0.00000000e+00,\n",
       "        1.24202327e-13, 1.37723603e-14, 1.33244127e-07, 2.33355519e-04,\n",
       "        2.97759329e-04, 3.14219238e-04, 6.60151542e-03, 2.88744743e-04,\n",
       "        0.00000000e+00, 1.68572295e-14, 1.34378873e-07, 2.35490094e-07,\n",
       "        5.33458415e-04, 5.70512765e-04, 3.63902600e-04, 3.28330446e-04,\n",
       "        4.49042847e-04, 0.00000000e+00, 2.08518091e-15, 7.68819389e-12,\n",
       "        1.16240183e-04, 3.02871318e-04, 2.59474265e-04, 6.51474273e-04,\n",
       "        4.15169073e-04, 2.32634253e-04, 9.36526624e-14, 1.18695252e-15,\n",
       "        7.45778112e-10, 3.52942665e-04, 3.03754045e-04, 6.91666736e-04,\n",
       "        3.02127168e-02, 4.06613675e-04, 2.63413747e-04, 1.83964008e-04,\n",
       "        4.94343170e-05, 3.12941885e-04, 1.80116612e-04, 5.58820675e-05,\n",
       "        1.44492661e-04, 2.99730348e-04, 1.35231438e-04, 5.79743764e-05,\n",
       "        4.92265990e-04, 7.35690974e-04, 2.70288759e-04, 4.01651280e-04,\n",
       "        1.26161994e-03, 6.30148929e-04, 5.05444736e-04, 1.50265991e-03,\n",
       "        3.35650367e-04, 1.42575102e-04, 5.10576635e-04, 3.16360199e-04,\n",
       "        3.80051732e-04, 5.96162794e-04, 3.00186778e-04, 3.47753352e-04,\n",
       "        4.66123820e-04, 2.14177471e-04, 2.59652603e-04, 1.56797982e-04,\n",
       "        1.51245369e-04, 1.77746824e-04, 1.64307169e-04, 1.88206159e-04,\n",
       "        9.36837055e-05, 4.59054559e-05, 1.08822284e-04, 8.26620687e-05,\n",
       "        3.67814230e-04, 3.14181045e-04, 3.24409316e-04, 3.76516467e-04,\n",
       "        2.92837781e-04, 1.61460991e-03, 4.95524023e-04, 1.84445478e-04,\n",
       "        5.22264978e-04, 4.23803900e-04, 5.30170287e-04, 2.42755706e-04,\n",
       "        4.97188031e-04, 3.18155466e-04, 3.85099177e-04, 9.14874332e-04,\n",
       "        4.35535975e-04, 1.35015504e-04, 6.13431572e-05, 2.26924174e-04,\n",
       "        3.00963949e-04, 9.11254457e-05, 1.19238903e-04, 5.53058772e-05,\n",
       "        4.20497781e-04, 1.36563605e-04, 8.66552069e-05, 5.90497987e-04,\n",
       "        4.86170632e-04, 2.93201209e-04, 1.72183532e-04, 2.87455271e-04,\n",
       "        4.61082144e-04, 1.65325350e-04, 1.41831876e-04, 2.01227667e-04,\n",
       "        2.44915773e-04, 3.87363524e-04, 3.11201841e-04, 2.74543991e-04,\n",
       "        4.78543739e-04, 2.80860134e-04, 1.38953331e-04, 9.26573311e-05]),\n",
       " 'rank_test_neg_log_loss': array([146, 153, 105, 196,  84, 164,  30,  23,   9, 152,  93,  79,  78,\n",
       "         83, 235, 317,  17,   8, 241, 218, 104, 175, 173, 191,  18,  11,\n",
       "          6,  57, 209, 102, 194, 234,  22,  20,  12,   7, 206, 253, 205,\n",
       "        236, 309,  19,  21,  10,   1, 201, 157, 258, 287, 215,  26, 224,\n",
       "         13,   2, 167, 172,  95, 311, 316,  24, 322,  15,   3, 208, 282,\n",
       "        266, 307,  32, 324, 245,  14,   5, 256, 315, 240, 314, 323, 221,\n",
       "        263,  16,   4, 147, 112, 154, 181, 160,  96, 186,  25, 178, 110,\n",
       "        150, 227, 170, 188, 171, 299, 203,  88, 150, 174, 156, 182,  63,\n",
       "        285, 179,  29,  68, 232, 180, 217, 199, 262,  81, 276, 295,  27,\n",
       "        200, 159, 162, 293, 220, 254, 303, 298,  61,  86, 103, 284,  45,\n",
       "        281, 260, 255, 301, 250, 211, 312, 305, 290, 204, 318, 302,  46,\n",
       "        259,  85, 275,  98, 248, 270, 313, 212, 249, 183,  47, 288, 239,\n",
       "        195,  82, 269,  28, 225,  92, 118, 118, 118, 137, 139, 109,  40,\n",
       "        271,  89, 118, 118, 118, 115, 143,  91,  65, 297,  73, 118, 118,\n",
       "        142, 134, 111,  35,  33, 242, 320, 118, 118, 138, 144, 107,  60,\n",
       "        279, 274, 289, 118, 118, 116, 113, 106, 169, 246, 177, 100, 118,\n",
       "        141, 117, 149, 187,  69,  55, 319,  75, 118, 136, 148, 108, 101,\n",
       "        300, 247, 286, 192, 118, 133, 114,  62, 238, 214,  41, 292, 158,\n",
       "        140, 135, 145,  36,  70, 219, 321, 267, 261,  76,  58, 168,  97,\n",
       "         59,  48, 226,  42,  51,  34, 308, 228,  31, 306, 277, 291, 304,\n",
       "        163,  49, 193, 229, 202, 278, 280, 213, 244,  44, 216,  99,  77,\n",
       "        237,  74, 233,  64, 223, 165, 210, 265, 243, 207, 272, 252, 310,\n",
       "        231, 198,  43, 185,  52,  38, 268,  72,  39, 296,  37, 251, 197,\n",
       "         50, 155, 166,  87,  80, 273, 222,  71, 189, 294,  56,  94, 230,\n",
       "        190,  66,  67, 176,  53, 283, 184,  90, 257, 264, 161,  54])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIAL_3_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL THREE NEG LOG LOSS RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL THREE NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_3_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL THREE F1 RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL THREE F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_3_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL THREE ROC AUC RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL THREE ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_3_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 3 svm using best NEG LOG LOSS hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 3 svm using best F1 hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 3 svm using best ROC_AUC hyperparameters :0.9319\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 3 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 3 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 3 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL FOUR ON POKER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FOUR RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = pokerData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_4_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL FOUR RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.39684114, 0.41385574, 0.41976042, 0.42616601, 0.43137088,\n",
       "        0.43597469, 0.44288087, 0.44218006, 0.48401642, 0.42456532,\n",
       "        0.43407302, 0.43257203, 0.44478269, 0.44278083, 0.43467393,\n",
       "        0.47901196, 0.71111164, 1.89703121, 0.44688406, 0.45238905,\n",
       "        0.41815968, 0.44428229, 0.43407345, 0.43217182, 0.51424236,\n",
       "        1.46395922, 3.31444974, 0.44308095, 0.47160583, 0.48962097,\n",
       "        0.51744466, 0.48791866, 0.63714767, 1.53542085, 1.96729198,\n",
       "        3.53353839, 0.47070494, 0.46509986, 0.43167119, 0.42806816,\n",
       "        0.49152255, 0.84772906, 2.1617588 , 1.66292996, 3.60900373,\n",
       "        0.43357277, 0.42236295, 0.43107076, 0.44217992, 1.16380076,\n",
       "        1.56714764, 2.25553975, 2.34311504, 3.61580944, 0.49242358,\n",
       "        0.55227504, 0.88546133, 1.9972177 , 2.15975742, 2.36703525,\n",
       "        3.06279826, 2.36353259, 3.56716766, 0.62884092, 0.80178962,\n",
       "        1.32874274, 1.99661679, 2.29697533, 3.10497041, 3.21376381,\n",
       "        2.34501672, 3.69287591, 0.71641574, 0.86094036, 1.42762766,\n",
       "        2.27946005, 3.14610558, 3.37920618, 3.4648798 , 2.58912654,\n",
       "        3.76513686, 0.55507751, 0.48811941, 0.51324129, 0.48751917,\n",
       "        0.47500858, 0.49762778, 0.50613561, 0.66186929, 1.21003942,\n",
       "        0.48531704, 0.47751055, 0.48872042, 0.48571773, 0.46830292,\n",
       "        0.47811136, 0.47801132, 0.80269027, 1.30902576, 0.50873737,\n",
       "        0.50143132, 0.5025321 , 0.48391604, 0.4833158 , 0.48561764,\n",
       "        0.49892888, 0.82541022, 1.2798007 , 0.50733638, 0.47570906,\n",
       "        0.48023486, 0.46890354, 0.46480012, 0.45819349, 1.92875857,\n",
       "        0.76876101, 1.16340027, 0.47010417, 0.4765099 , 0.50973802,\n",
       "        0.49812832, 0.47280626, 0.48271503, 1.92265315, 0.6540627 ,\n",
       "        1.13367476, 0.47951274, 0.46730189, 0.47360725, 0.48852005,\n",
       "        0.48241487, 0.48371639, 2.00722637, 0.68028507, 1.1937264 ,\n",
       "        0.48822007, 0.48381634, 0.46960373, 0.46479974, 0.47220602,\n",
       "        2.05326567, 2.41557689, 0.64375353, 1.14948874, 0.47360787,\n",
       "        0.47881212, 0.48051324, 0.48721895, 0.56638699, 2.66289015,\n",
       "        2.19011254, 0.64115138, 1.17105474, 0.49431095, 0.48041286,\n",
       "        0.49212308, 0.6022181 , 1.55743933, 2.81622195, 2.19188452,\n",
       "        0.68178616, 1.16350031, 0.29375291, 0.29685569, 0.31657233,\n",
       "        0.30836535, 0.30396152, 0.32177672, 0.34629774, 0.36681514,\n",
       "        0.73232989, 0.30266027, 0.30516238, 0.31346965, 0.31286917,\n",
       "        0.32117643, 0.33688984, 0.32708082, 0.42986965, 1.0423965 ,\n",
       "        0.31036696, 0.31156807, 0.33438711, 0.3172729 , 0.31947517,\n",
       "        0.31056714, 0.30516214, 0.60502052, 2.40116501, 0.45869427,\n",
       "        0.36301227, 0.32958326, 0.32417874, 0.30906577, 0.32397857,\n",
       "        0.33979244, 0.74393969, 2.35012107, 0.32547979, 0.33078456,\n",
       "        0.3176734 , 0.31607184, 0.3130692 , 0.31206851, 0.44758482,\n",
       "        0.98594785, 2.31318932, 0.30766463, 0.32588034, 0.31927476,\n",
       "        0.32007527, 0.31927471, 0.3274817 , 0.56728764, 2.36883411,\n",
       "        2.29737587, 0.31266894, 0.30065856, 0.29715576, 0.32598042,\n",
       "        0.33939166, 0.34199429, 0.73162918, 2.37724452, 2.56130252,\n",
       "        0.31447072, 0.42386465, 0.35390396, 0.33128476, 0.37151957,\n",
       "        0.49542618, 1.10284848, 2.60013638, 2.65037932, 0.3525034 ,\n",
       "        0.33939161, 0.32017522, 0.35220275, 0.3812273 , 0.66507177,\n",
       "        2.61534872, 2.68350735, 2.72524366, 0.30156026, 0.28264256,\n",
       "        0.26933174, 0.26392741, 0.26983247, 0.27103243, 0.28064179,\n",
       "        0.26522803, 0.26242619, 0.26442733, 0.25732083, 0.26372666,\n",
       "        0.26442723, 0.26402693, 0.27743883, 0.25562005, 0.27543745,\n",
       "        0.26933208, 0.26418324, 0.25622039, 0.27673764, 0.25241666,\n",
       "        0.25461864, 0.27023306, 0.27553706, 0.26883106, 0.26112542,\n",
       "        0.32778249, 0.32608051, 0.34459639, 0.32728143, 0.31336942,\n",
       "        0.31797352, 0.33038411, 0.32337775, 0.3275816 , 1.02057748,\n",
       "        1.10945387, 1.15279131, 1.11365752, 0.99625716, 1.1477869 ,\n",
       "        1.09354019, 1.13727794, 1.0857337 , 2.22491336, 2.43799734,\n",
       "        2.26604877, 2.25884237, 2.06437488, 2.1848784 , 2.12502751,\n",
       "        2.17677183, 2.18037534, 2.1056107 , 1.98860974, 1.9552815 ,\n",
       "        1.96989427, 1.95047746, 1.96308866, 2.00692601, 2.06647716,\n",
       "        2.11561956, 2.06417508, 2.02323999, 2.0366518 , 2.11391754,\n",
       "        2.09500208, 2.04365754, 2.08529353, 2.08489275, 2.02203918,\n",
       "        2.23622298, 2.21820741, 2.16876493, 2.22811584, 2.05316544,\n",
       "        2.06427498, 2.09159894, 1.92085233, 1.57215176]),\n",
       " 'std_fit_time': array([0.00394041, 0.0115294 , 0.01520002, 0.0149042 , 0.01145556,\n",
       "        0.00721336, 0.02730382, 0.01219492, 0.02133375, 0.00949293,\n",
       "        0.02094818, 0.00701752, 0.01095187, 0.01376484, 0.01826849,\n",
       "        0.01601481, 0.02064049, 0.01017942, 0.00874256, 0.02135618,\n",
       "        0.00484746, 0.02398608, 0.01361554, 0.01098496, 0.01390693,\n",
       "        0.0803949 , 0.11477897, 0.01268631, 0.0359272 , 0.02410706,\n",
       "        0.03357131, 0.01656545, 0.01181441, 0.08043395, 0.12553821,\n",
       "        0.03640608, 0.02406571, 0.02768389, 0.0080231 , 0.00963451,\n",
       "        0.00548584, 0.02990579, 0.06627193, 0.04290066, 0.09533241,\n",
       "        0.01333301, 0.00658586, 0.01460921, 0.00729062, 0.02129874,\n",
       "        0.07014708, 0.02277573, 0.10710184, 0.0786612 , 0.01306881,\n",
       "        0.00868313, 0.03772007, 0.06493136, 0.03083462, 0.07006252,\n",
       "        0.08535233, 0.11188384, 0.06520534, 0.00387139, 0.02224872,\n",
       "        0.03699205, 0.0599072 , 0.04378438, 0.03553059, 0.07145603,\n",
       "        0.05584212, 0.0538146 , 0.02378777, 0.01019518, 0.05964454,\n",
       "        0.07402099, 0.03445849, 0.03045903, 0.28183336, 0.10373983,\n",
       "        0.0998397 , 0.05868431, 0.02110036, 0.01166591, 0.02192173,\n",
       "        0.01244204, 0.01904419, 0.02095737, 0.01373615, 0.02014925,\n",
       "        0.02047597, 0.01390958, 0.0139713 , 0.02140196, 0.01300882,\n",
       "        0.0136485 , 0.0162511 , 0.04074989, 0.04736551, 0.0116831 ,\n",
       "        0.01973753, 0.01852658, 0.0233824 , 0.01830605, 0.02034141,\n",
       "        0.0184414 , 0.01818069, 0.02909678, 0.0204296 , 0.01478286,\n",
       "        0.01114619, 0.01311476, 0.01374277, 0.01376955, 0.03334735,\n",
       "        0.01308581, 0.04525344, 0.00911594, 0.00934315, 0.01160136,\n",
       "        0.01590901, 0.01707479, 0.00693851, 0.05895143, 0.00917863,\n",
       "        0.02670365, 0.0111512 , 0.01777851, 0.0105856 , 0.00983912,\n",
       "        0.01477425, 0.01518387, 0.01345397, 0.01641393, 0.01312881,\n",
       "        0.00925224, 0.01457707, 0.00615009, 0.00541197, 0.00841918,\n",
       "        0.02044548, 0.02118237, 0.02369036, 0.0238533 , 0.01404968,\n",
       "        0.02395874, 0.01177184, 0.01587738, 0.01305125, 0.07023378,\n",
       "        0.03608154, 0.03778219, 0.02926355, 0.02064542, 0.00411467,\n",
       "        0.01779648, 0.00932744, 0.03841046, 0.04561612, 0.03528526,\n",
       "        0.02068562, 0.00758933, 0.00598003, 0.00794657, 0.01247525,\n",
       "        0.00899876, 0.00859587, 0.01352824, 0.010968  , 0.01169779,\n",
       "        0.00948738, 0.00698784, 0.00593277, 0.01168323, 0.00976711,\n",
       "        0.00546745, 0.01804173, 0.01873404, 0.00921105, 0.04202325,\n",
       "        0.01024284, 0.00744022, 0.02225958, 0.01616291, 0.00639776,\n",
       "        0.00834148, 0.01108407, 0.06331417, 0.08243753, 0.00727674,\n",
       "        0.03652743, 0.00952987, 0.01166518, 0.01361894, 0.01428689,\n",
       "        0.00992313, 0.01805567, 0.02423762, 0.02979911, 0.01857099,\n",
       "        0.00833408, 0.01426218, 0.00954505, 0.00859577, 0.01691012,\n",
       "        0.03452385, 0.06093493, 0.01092928, 0.01161789, 0.02490319,\n",
       "        0.01992855, 0.01688764, 0.02733034, 0.02337104, 0.03086664,\n",
       "        0.03608978, 0.01845341, 0.01203268, 0.00905998, 0.01163565,\n",
       "        0.01213694, 0.01193766, 0.03026656, 0.08986668, 0.25488642,\n",
       "        0.02035344, 0.05947788, 0.02912212, 0.03877333, 0.07815708,\n",
       "        0.07630514, 0.09012452, 0.18787326, 0.22806552, 0.02120673,\n",
       "        0.01228475, 0.04105528, 0.02658276, 0.05246104, 0.06827076,\n",
       "        0.25562652, 0.23478094, 0.09653147, 0.03697558, 0.01246697,\n",
       "        0.01806658, 0.0164965 , 0.02106437, 0.01769417, 0.02085141,\n",
       "        0.01763001, 0.01265444, 0.01722128, 0.019007  , 0.00731376,\n",
       "        0.03304804, 0.02272575, 0.02809471, 0.0173105 , 0.02545319,\n",
       "        0.00647361, 0.01847746, 0.00902976, 0.00720353, 0.00589281,\n",
       "        0.01167786, 0.01826693, 0.01066091, 0.01935443, 0.00906493,\n",
       "        0.01068625, 0.01019464, 0.01483031, 0.01591045, 0.01299749,\n",
       "        0.01003636, 0.02461086, 0.00837635, 0.02675241, 0.05285042,\n",
       "        0.07299417, 0.04415903, 0.03784585, 0.01531453, 0.07236333,\n",
       "        0.14069628, 0.09225845, 0.04661549, 0.05996134, 0.12336555,\n",
       "        0.17901058, 0.10351487, 0.06790642, 0.08469957, 0.03200358,\n",
       "        0.09855032, 0.01718164, 0.06134414, 0.05898138, 0.01287361,\n",
       "        0.01158825, 0.01710452, 0.01232055, 0.0601071 , 0.06750408,\n",
       "        0.03702211, 0.08582197, 0.04344019, 0.04912748, 0.06453682,\n",
       "        0.04875445, 0.04862962, 0.17199823, 0.09328242, 0.04210957,\n",
       "        0.1349832 , 0.15002598, 0.09437595, 0.08647264, 0.09747993,\n",
       "        0.06759552, 0.05858294, 0.06177579, 0.12982159]),\n",
       " 'mean_score_time': array([0.04203644, 0.04694023, 0.04003453, 0.04533906, 0.03873343,\n",
       "        0.0407352 , 0.04083524, 0.03883357, 0.04163561, 0.04123549,\n",
       "        0.04343748, 0.0437376 , 0.04133554, 0.04593973, 0.04183578,\n",
       "        0.04613986, 0.06065221, 0.13501663, 0.04123559, 0.04153576,\n",
       "        0.04013433, 0.04263649, 0.04003415, 0.0416358 , 0.04874196,\n",
       "        0.08066931, 0.2017736 , 0.04183645, 0.05054355, 0.05024347,\n",
       "        0.04473872, 0.04714088, 0.05534782, 0.06825852, 0.07436404,\n",
       "        0.20247426, 0.05004287, 0.0396338 , 0.04023461, 0.04253674,\n",
       "        0.05694885, 0.0645556 , 0.07126174, 0.072262  , 0.20357518,\n",
       "        0.04193592, 0.0411355 , 0.04253645, 0.0420362 , 0.07586517,\n",
       "        0.08026919, 0.08257117, 0.08267102, 0.20387554, 0.04063473,\n",
       "        0.04203615, 0.04583964, 0.06115251, 0.08267117, 0.09518213,\n",
       "        0.16634336, 0.09107881, 0.20928016, 0.04253664, 0.04043469,\n",
       "        0.04493856, 0.05895052, 0.11840162, 0.16984577, 0.17575111,\n",
       "        0.08817582, 0.22048979, 0.04363761, 0.04463878, 0.04644027,\n",
       "        0.07426405, 0.22609453, 0.18786144, 0.20037236, 0.09087806,\n",
       "        0.21388383, 0.0451386 , 0.04704051, 0.04303703, 0.04283695,\n",
       "        0.04373751, 0.04453855, 0.0433372 , 0.04623971, 0.0666574 ,\n",
       "        0.04563947, 0.04674044, 0.04313726, 0.0437377 , 0.0425364 ,\n",
       "        0.0459394 , 0.04243665, 0.04303679, 0.06615686, 0.04854174,\n",
       "        0.04363751, 0.04243665, 0.04433837, 0.05064335, 0.05104399,\n",
       "        0.04623976, 0.04353695, 0.06509657, 0.04804125, 0.04473844,\n",
       "        0.04181385, 0.04243617, 0.04333696, 0.04483876, 0.0480413 ,\n",
       "        0.0480413 , 0.06685743, 0.04523897, 0.04523883, 0.04644008,\n",
       "        0.04393792, 0.04583964, 0.04383774, 0.05024323, 0.04553881,\n",
       "        0.06355476, 0.04403768, 0.04684072, 0.04123549, 0.04774122,\n",
       "        0.04383755, 0.04834127, 0.04744129, 0.04273667, 0.06935973,\n",
       "        0.04523902, 0.04553871, 0.04213619, 0.04183607, 0.04343777,\n",
       "        0.06255398, 0.05064368, 0.04624004, 0.0616529 , 0.04333687,\n",
       "        0.04413791, 0.04283671, 0.04283671, 0.05494742, 0.09207926,\n",
       "        0.05181541, 0.04073505, 0.06550837, 0.04403787, 0.04654012,\n",
       "        0.05174441, 0.05774913, 0.08607397, 0.08367214, 0.04513903,\n",
       "        0.04223647, 0.06245394, 0.02772365, 0.02832398, 0.02722325,\n",
       "        0.02652307, 0.02772388, 0.02972546, 0.02662306, 0.02842493,\n",
       "        0.0390336 , 0.02602239, 0.03022623, 0.0289248 , 0.02952504,\n",
       "        0.02622256, 0.02892504, 0.02632279, 0.03412986, 0.04613957,\n",
       "        0.0285244 , 0.02842469, 0.02812428, 0.02652264, 0.02602239,\n",
       "        0.02872481, 0.02932539, 0.04223647, 0.04573956, 0.0324286 ,\n",
       "        0.02712331, 0.02792425, 0.02752371, 0.03002572, 0.02812433,\n",
       "        0.02952566, 0.04583979, 0.04213634, 0.02902489, 0.02942557,\n",
       "        0.02652264, 0.02852435, 0.02702365, 0.02742372, 0.03242807,\n",
       "        0.04834175, 0.04914255, 0.02755923, 0.02662268, 0.02832408,\n",
       "        0.02992578, 0.0280241 , 0.02992578, 0.03633142, 0.04443817,\n",
       "        0.04373736, 0.02712317, 0.02822423, 0.02712336, 0.02962546,\n",
       "        0.0276237 , 0.03222771, 0.03863325, 0.04653997, 0.05074406,\n",
       "        0.02802391, 0.0370316 , 0.02612247, 0.02782393, 0.02772384,\n",
       "        0.04644036, 0.04694018, 0.04924221, 0.06195354, 0.03132696,\n",
       "        0.02642283, 0.03182755, 0.0359314 , 0.02932558, 0.04924273,\n",
       "        0.0543469 , 0.04684029, 0.04864206, 0.02792373, 0.02612262,\n",
       "        0.02231936, 0.02592244, 0.02642221, 0.02722363, 0.02593012,\n",
       "        0.02291956, 0.02622232, 0.02342019, 0.02201939, 0.02522221,\n",
       "        0.02211924, 0.02542219, 0.02762389, 0.02211924, 0.02642241,\n",
       "        0.02432098, 0.02281952, 0.02311993, 0.02282004, 0.02272034,\n",
       "        0.02402105, 0.02392201, 0.02402072, 0.0224195 , 0.02572188,\n",
       "        0.02992492, 0.02792368, 0.02742329, 0.02822428, 0.02642312,\n",
       "        0.02772374, 0.03012595, 0.02932506, 0.0283246 , 0.04413862,\n",
       "        0.04393854, 0.0385335 , 0.04073529, 0.03673182, 0.07226243,\n",
       "        0.03803334, 0.03913383, 0.0391335 , 0.05724907, 0.0484417 ,\n",
       "        0.04934244, 0.03653131, 0.04343743, 0.04393773, 0.04083514,\n",
       "        0.04754114, 0.04123545, 0.03853345, 0.03863349, 0.03643131,\n",
       "        0.03563061, 0.03963428, 0.04433837, 0.0402349 , 0.04253669,\n",
       "        0.03823295, 0.04473844, 0.04674015, 0.03863277, 0.0376327 ,\n",
       "        0.0421361 , 0.03833289, 0.04894218, 0.04694047, 0.03703151,\n",
       "        0.04814134, 0.04623995, 0.04233642, 0.03743229, 0.04623995,\n",
       "        0.05074377, 0.03563075, 0.02722311, 0.02101784]),\n",
       " 'std_score_time': array([0.00164433, 0.00554006, 0.00349561, 0.00631886, 0.00103037,\n",
       "        0.00229554, 0.0039608 , 0.00160142, 0.00159557, 0.00177922,\n",
       "        0.00259858, 0.00273366, 0.00361669, 0.00778767, 0.00244339,\n",
       "        0.00637302, 0.01027234, 0.00297612, 0.00248405, 0.00424612,\n",
       "        0.0012421 , 0.00432134, 0.00212321, 0.00102095, 0.00620714,\n",
       "        0.00817035, 0.00171583, 0.00428901, 0.00563514, 0.00559613,\n",
       "        0.00497021, 0.0098746 , 0.00231701, 0.00332833, 0.00431213,\n",
       "        0.00545975, 0.00370462, 0.00066382, 0.00107782, 0.00452063,\n",
       "        0.00331029, 0.00145025, 0.00426529, 0.00512888, 0.0056564 ,\n",
       "        0.00267437, 0.00350156, 0.00528668, 0.00483117, 0.00519673,\n",
       "        0.00326774, 0.00207501, 0.00357235, 0.00591802, 0.00250009,\n",
       "        0.00083768, 0.00087214, 0.0037903 , 0.00182897, 0.00779397,\n",
       "        0.01146687, 0.00232567, 0.00891475, 0.00382409, 0.00222483,\n",
       "        0.00376369, 0.00208504, 0.0135119 , 0.00150487, 0.01091515,\n",
       "        0.00368285, 0.0294644 , 0.00380326, 0.00381638, 0.00386859,\n",
       "        0.00686581, 0.02223482, 0.01015563, 0.0199811 , 0.00317417,\n",
       "        0.00686602, 0.00305881, 0.00429339, 0.00221554, 0.00103046,\n",
       "        0.00220661, 0.00228228, 0.00169204, 0.00289384, 0.00300929,\n",
       "        0.00271159, 0.00665844, 0.00235582, 0.00254401, 0.00187232,\n",
       "        0.00491735, 0.00091714, 0.0032893 , 0.00139391, 0.00555444,\n",
       "        0.00058356, 0.00159507, 0.0012094 , 0.00618935, 0.00664654,\n",
       "        0.00496   , 0.00134357, 0.0028559 , 0.00518101, 0.00502046,\n",
       "        0.00150234, 0.00124214, 0.00163224, 0.00325242, 0.00369104,\n",
       "        0.00707703, 0.0039098 , 0.00323692, 0.00143641, 0.00231276,\n",
       "        0.00132027, 0.00489923, 0.00199195, 0.00216088, 0.00513283,\n",
       "        0.00277732, 0.00281276, 0.00662833, 0.00120952, 0.00546928,\n",
       "        0.0024843 , 0.0050502 , 0.00460187, 0.00354695, 0.00319006,\n",
       "        0.00194061, 0.00702762, 0.0033106 , 0.00242274, 0.00215632,\n",
       "        0.00141551, 0.00979291, 0.00667322, 0.00215588, 0.00242304,\n",
       "        0.00188318, 0.00163234, 0.00120942, 0.00210881, 0.00321214,\n",
       "        0.00700282, 0.00143647, 0.00399703, 0.00336433, 0.00295222,\n",
       "        0.0103218 , 0.00479586, 0.00318075, 0.00111411, 0.00213257,\n",
       "        0.00067873, 0.00156347, 0.00315856, 0.00233904, 0.00240205,\n",
       "        0.00189916, 0.00252402, 0.00242292, 0.00124221, 0.0011582 ,\n",
       "        0.00189904, 0.00100112, 0.00698167, 0.00413181, 0.00833165,\n",
       "        0.00081316, 0.00177378, 0.00143695, 0.00226928, 0.00139411,\n",
       "        0.00122621, 0.00111453, 0.00188339, 0.0016138 , 0.00100074,\n",
       "        0.00390973, 0.00218325, 0.00818364, 0.00388367, 0.00772907,\n",
       "        0.00217891, 0.00177353, 0.00192544, 0.00173373, 0.00162609,\n",
       "        0.00230411, 0.00554157, 0.00159479, 0.00683212, 0.00591565,\n",
       "        0.00109619, 0.00488259, 0.0012655 , 0.00271195, 0.00049014,\n",
       "        0.00451596, 0.0060996 , 0.00176191, 0.00049034, 0.0027336 ,\n",
       "        0.0052331 , 0.00114097, 0.00452479, 0.00160152, 0.00097002,\n",
       "        0.00092807, 0.00261752, 0.0041216 , 0.00271162, 0.00245983,\n",
       "        0.00255927, 0.00470117, 0.00124218, 0.00519143, 0.00752044,\n",
       "        0.00241056, 0.01203128, 0.0020853 , 0.00160167, 0.00248443,\n",
       "        0.01870723, 0.00913176, 0.00924168, 0.01476192, 0.00504975,\n",
       "        0.00159497, 0.00432295, 0.00511729, 0.00246435, 0.01167502,\n",
       "        0.00531124, 0.00302917, 0.00362848, 0.00879088, 0.00633291,\n",
       "        0.00240167, 0.0035868 , 0.00751212, 0.00643667, 0.0049937 ,\n",
       "        0.0017733 , 0.00917639, 0.00177388, 0.00137979, 0.00319012,\n",
       "        0.00106881, 0.00445804, 0.00506808, 0.00139408, 0.00435613,\n",
       "        0.00301292, 0.00201627, 0.00146418, 0.00143664, 0.00120866,\n",
       "        0.002918  , 0.00213189, 0.00295188, 0.00168616, 0.0020662 ,\n",
       "        0.00302581, 0.00168669, 0.001498  , 0.00341774, 0.00115845,\n",
       "        0.00206593, 0.00274803, 0.00204193, 0.00143641, 0.00881273,\n",
       "        0.00769681, 0.00249248, 0.00431178, 0.00186161, 0.02512682,\n",
       "        0.00155045, 0.00233416, 0.00351615, 0.01499494, 0.0073377 ,\n",
       "        0.01177708, 0.00151791, 0.01106583, 0.00413184, 0.00375316,\n",
       "        0.01815135, 0.00479571, 0.00207564, 0.00278438, 0.00086076,\n",
       "        0.00206101, 0.00315564, 0.00627104, 0.00248411, 0.00602176,\n",
       "        0.00163231, 0.00770475, 0.00929549, 0.00404589, 0.00198692,\n",
       "        0.00329493, 0.00240179, 0.0187524 , 0.01240987, 0.00164473,\n",
       "        0.00905975, 0.01301331, 0.00729046, 0.00210911, 0.01415306,\n",
       "        0.01817505, 0.00518592, 0.00480636, 0.00077519]),\n",
       " 'param_classifier': masked_array(data=[SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__gamma': masked_array(data=[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'}],\n",
       " 'split0_test_recall_micro': array([0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.938,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.931, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.896, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.862, 0.891, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.796, 0.815, 0.892, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.666, 0.779, 0.815, 0.892, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.904,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.915, 0.885,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.873, 0.871,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.872, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.896, 0.87 , 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.83 , 0.871, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.754, 0.794, 0.879, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.868,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.864, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.838, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.838, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.864, 0.838, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637]),\n",
       " 'split1_test_recall_micro': array([0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.938,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.901, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.794, 0.879, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.748, 0.79 , 0.881, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.864, 0.856, 0.667, 0.881, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.909,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.911, 0.869,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.884, 0.878,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.896, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.909, 0.887, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.868, 0.882, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.702, 0.844, 0.889, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.875,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.875, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.865, 0.799, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.655, 0.655, 0.655, 0.655, 0.655, 0.655, 0.655, 0.655, 0.655,\n",
       "        0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698,\n",
       "        0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698,\n",
       "        0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698]),\n",
       " 'split2_test_recall_micro': array([0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.931, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.905, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.778, 0.889, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.82 , 0.838, 0.889, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.741, 0.767, 0.838, 0.889, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.907,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.908, 0.889,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.888, 0.895,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.867, 0.891,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.905, 0.871, 0.891,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.849, 0.867, 0.888,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.716, 0.786, 0.874, 0.888,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.859,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.859, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.859, 0.845, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645]),\n",
       " 'split3_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.937,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.919, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.803, 0.904, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.751, 0.788, 0.904, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.678, 0.646, 0.788, 0.904, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.89 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.917, 0.871,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.883, 0.874,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.889, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.908, 0.873, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.866, 0.877, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.62 , 0.814, 0.889, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857, 0.874, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637]),\n",
       " 'split4_test_recall_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.933,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.896, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.839, 0.878, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.739, 0.742, 0.886, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.769, 0.667, 0.742, 0.886, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.912,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.912, 0.896,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.886, 0.89 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.883, 0.889,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.901, 0.89 , 0.887,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857, 0.886, 0.887,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.676, 0.845, 0.882, 0.887,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.836,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.832, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.832, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.832, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716,\n",
       "        0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695,\n",
       "        0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695,\n",
       "        0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695]),\n",
       " 'mean_test_recall_micro': array([0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.936 , 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.93  , 0.939 , 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9034, 0.939 , 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.8152, 0.8882, 0.939 , 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.7708, 0.7946, 0.8904, 0.939 ,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.7436, 0.743 , 0.77  , 0.8904,\n",
       "        0.939 , 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9044, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9126, 0.882 , 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.8828, 0.8816, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8814, 0.8862, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9038, 0.8782, 0.8858,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.854 , 0.8766,\n",
       "        0.8852, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.6936, 0.8166,\n",
       "        0.8826, 0.8852, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.859 , 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8326, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8326, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8658, 0.8326,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8376,\n",
       "        0.8326, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.8376, 0.8326, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.8638, 0.8376, 0.8326, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.658 , 0.658 , 0.658 , 0.658 , 0.658 , 0.658 , 0.658 , 0.658 ,\n",
       "        0.658 , 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624,\n",
       "        0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624,\n",
       "        0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624,\n",
       "        0.6624, 0.6624, 0.6624, 0.6624]),\n",
       " 'std_test_recall_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00209762, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00089443, 0.00252982,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00849941, 0.00252982, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.03078571, 0.00945304, 0.00252982, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.03155567, 0.03203498,\n",
       "        0.00770973, 0.00252982, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.07137675, 0.07723471, 0.06060693, 0.00770973,\n",
       "        0.00252982, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00765768, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00313688, 0.01043072, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0051923 ,\n",
       "        0.00930806, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.01066958, 0.0040694 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00479166, 0.00851822, 0.00386782, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.01378405, 0.0069455 , 0.00318748, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.04460314, 0.02454058,\n",
       "        0.00581722, 0.00318748, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.01319091, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.01868261, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.01868261, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.00746726,\n",
       "        0.01868261, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.02408817, 0.01868261,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.02408817, 0.01868261, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0059127 , 0.02408817, 0.01868261, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.02974559, 0.02974559,\n",
       "        0.02974559, 0.02974559, 0.02974559, 0.02974559, 0.02974559,\n",
       "        0.02974559, 0.02974559, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143]),\n",
       " 'rank_test_recall_micro': array([  8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   6,   8,   8,   8,\n",
       "          8,   8,   8,   8,   7,   1,   8,   8,   8,   8,   8,   8,   8,\n",
       "        253,   1,   8,   8,   8,   8,   8,   8, 282, 256,   1,   8,   8,\n",
       "          8,   8,   8, 284, 283, 254,   1,   8,   8,   8,   8, 286, 287,\n",
       "        285, 254,   1,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8, 251,   8,   8,   8,   8,   8,   8,   8, 250, 263,\n",
       "          8,   8,   8,   8,   8,   8,   8, 261, 264,   8,   8,   8,   8,\n",
       "          8,   8,   8, 265, 257,   8,   8,   8,   8,   8,   8, 252, 266,\n",
       "        258,   8,   8,   8,   8,   8,   8, 271, 267, 259,   8,   8,   8,\n",
       "          8,   8, 288, 281, 262, 259,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8, 270,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 275,   8,   8,   8,   8,   8,   8,   8,   8, 275,   8,\n",
       "          8,   8,   8,   8,   8,   8, 268, 275,   8,   8,   8,   8,   8,\n",
       "          8,   8, 272, 275,   8,   8,   8,   8,   8,   8,   8, 272, 275,\n",
       "          8,   8,   8,   8,   8,   8, 269, 272, 275,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 316, 316, 316, 316, 316, 316, 316, 316, 316, 289, 289,\n",
       "        289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289,\n",
       "        289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289]),\n",
       " 'split0_test_f1_micro': array([0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.938,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.931, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.896, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.862, 0.891, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.796, 0.815, 0.892, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.666, 0.779, 0.815, 0.892, 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.904,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.915, 0.885,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.873, 0.871,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.872, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.896, 0.87 , 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.83 , 0.871, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.754, 0.794, 0.879, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.868,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.864, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.838, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.838, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.864, 0.838, 0.827,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637]),\n",
       " 'split1_test_f1_micro': array([0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.938,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.901, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.794, 0.879, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.748, 0.79 , 0.881, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.864, 0.856, 0.667, 0.881, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.909,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.911, 0.869,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.884, 0.878,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.896, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.909, 0.887, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.868, 0.882, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.702, 0.844, 0.889, 0.886,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.875,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.875, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.799, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.865, 0.799, 0.799,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.655, 0.655, 0.655, 0.655, 0.655, 0.655, 0.655, 0.655, 0.655,\n",
       "        0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698,\n",
       "        0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698,\n",
       "        0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698]),\n",
       " 'split2_test_f1_micro': array([0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.934,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.931, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.905, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.778, 0.889, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.82 , 0.838, 0.889, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.741, 0.767, 0.838, 0.889, 0.94 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.907,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.908, 0.889,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.888, 0.895,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.867, 0.891,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.905, 0.871, 0.891,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.849, 0.867, 0.888,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.716, 0.786, 0.874, 0.888,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.859,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.859, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.845, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.859, 0.845, 0.845,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 , 0.93 ,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645,\n",
       "        0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645]),\n",
       " 'split3_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.937,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.919, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.803, 0.904, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.751, 0.788, 0.904, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.678, 0.646, 0.788, 0.904, 0.94 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.89 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.917, 0.871,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.883, 0.874,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.889, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.908, 0.873, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.866, 0.877, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.62 , 0.814, 0.889, 0.879,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857, 0.874, 0.852,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637,\n",
       "        0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637]),\n",
       " 'split4_test_f1_micro': array([0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.933,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.896, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.839, 0.878, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.739, 0.742, 0.886, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.769, 0.667, 0.742, 0.886, 0.941,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.912,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.912, 0.896,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.886, 0.89 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.883, 0.889,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.901, 0.89 , 0.887,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.857, 0.886, 0.887,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.676, 0.845, 0.882, 0.887,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.836,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.832, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.832, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.874, 0.832, 0.84 ,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929, 0.929,\n",
       "        0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716,\n",
       "        0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695,\n",
       "        0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695,\n",
       "        0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695]),\n",
       " 'mean_test_f1_micro': array([0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.936 , 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.93  , 0.939 , 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9034, 0.939 , 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.8152, 0.8882, 0.939 , 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.7708, 0.7946, 0.8904, 0.939 ,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.7436, 0.743 , 0.77  , 0.8904,\n",
       "        0.939 , 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9044, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9126, 0.882 , 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.8828, 0.8816, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8814, 0.8862, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9038, 0.8782, 0.8858,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.854 , 0.8766,\n",
       "        0.8852, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.6936, 0.8166,\n",
       "        0.8826, 0.8852, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.859 , 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8326, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8326, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8658, 0.8326,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.8376,\n",
       "        0.8326, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.8376, 0.8326, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.8638, 0.8376, 0.8326, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296, 0.9296,\n",
       "        0.658 , 0.658 , 0.658 , 0.658 , 0.658 , 0.658 , 0.658 , 0.658 ,\n",
       "        0.658 , 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624,\n",
       "        0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624,\n",
       "        0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624, 0.6624,\n",
       "        0.6624, 0.6624, 0.6624, 0.6624]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00209762, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00089443, 0.00252982,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00849941, 0.00252982, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.03078571, 0.00945304, 0.00252982, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.03155567, 0.03203498,\n",
       "        0.00770973, 0.00252982, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.07137675, 0.07723471, 0.06060693, 0.00770973,\n",
       "        0.00252982, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00765768, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00313688, 0.01043072, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0051923 ,\n",
       "        0.00930806, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.01066958, 0.0040694 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00479166, 0.00851822, 0.00386782, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.01378405, 0.0069455 , 0.00318748, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.04460314, 0.02454058,\n",
       "        0.00581722, 0.00318748, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.01319091, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.01868261, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.01868261, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.00746726,\n",
       "        0.01868261, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.02408817, 0.01868261,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.02408817, 0.01868261, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0059127 , 0.02408817, 0.01868261, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.02974559, 0.02974559,\n",
       "        0.02974559, 0.02974559, 0.02974559, 0.02974559, 0.02974559,\n",
       "        0.02974559, 0.02974559, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143, 0.02801143,\n",
       "        0.02801143, 0.02801143, 0.02801143, 0.02801143]),\n",
       " 'rank_test_f1_micro': array([  8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   6,   8,   8,   8,\n",
       "          8,   8,   8,   8,   7,   1,   8,   8,   8,   8,   8,   8,   8,\n",
       "        253,   1,   8,   8,   8,   8,   8,   8, 282, 256,   1,   8,   8,\n",
       "          8,   8,   8, 284, 283, 254,   1,   8,   8,   8,   8, 286, 287,\n",
       "        285, 254,   1,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8, 251,   8,   8,   8,   8,   8,   8,   8, 250, 263,\n",
       "          8,   8,   8,   8,   8,   8,   8, 261, 264,   8,   8,   8,   8,\n",
       "          8,   8,   8, 265, 257,   8,   8,   8,   8,   8,   8, 252, 266,\n",
       "        258,   8,   8,   8,   8,   8,   8, 271, 267, 259,   8,   8,   8,\n",
       "          8,   8, 288, 281, 262, 259,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8, 270,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 275,   8,   8,   8,   8,   8,   8,   8,   8, 275,   8,\n",
       "          8,   8,   8,   8,   8,   8, 268, 275,   8,   8,   8,   8,   8,\n",
       "          8,   8, 272, 275,   8,   8,   8,   8,   8,   8,   8, 272, 275,\n",
       "          8,   8,   8,   8,   8,   8, 269, 272, 275,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8, 316, 316, 316, 316, 316, 316, 316, 316, 316, 289, 289,\n",
       "        289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289,\n",
       "        289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289]),\n",
       " 'split0_test_roc_auc_ovo': array([0.54210445, 0.54514593, 0.46546851, 0.53576037, 0.50705069,\n",
       "        0.5227957 , 0.5090937 , 0.5637788 , 0.62809524, 0.5111828 ,\n",
       "        0.5184639 , 0.55155146, 0.47046083, 0.50705069, 0.5227957 ,\n",
       "        0.52697389, 0.59201229, 0.68897081, 0.48109063, 0.44442396,\n",
       "        0.41981567, 0.53576037, 0.49294931, 0.47173579, 0.55970814,\n",
       "        0.60236559, 0.69614439, 0.54663594, 0.53152074, 0.52024578,\n",
       "        0.46423963, 0.48735791, 0.51863287, 0.54894009, 0.59655914,\n",
       "        0.69769585, 0.45336406, 0.46847926, 0.52024578, 0.46016897,\n",
       "        0.48016897, 0.5243318 , 0.5203533 , 0.59975422, 0.70301075,\n",
       "        0.45336406, 0.46847926, 0.46837174, 0.55479263, 0.50857143,\n",
       "        0.54321045, 0.53502304, 0.61201229, 0.70258065, 0.57036866,\n",
       "        0.48175115, 0.50967742, 0.52195084, 0.52456221, 0.49345622,\n",
       "        0.52317972, 0.61187404, 0.70196621, 0.50376344, 0.50723502,\n",
       "        0.50081413, 0.54506912, 0.58678955, 0.51815668, 0.47869432,\n",
       "        0.61434716, 0.70018433, 0.47835637, 0.47718894, 0.52301075,\n",
       "        0.43663594, 0.50015361, 0.48139785, 0.47869432, 0.61431644,\n",
       "        0.70162826, 0.51058372, 0.53371736, 0.43623656, 0.5       ,\n",
       "        0.51577573, 0.5543318 , 0.50526882, 0.55935484, 0.42447005,\n",
       "        0.48228879, 0.53371736, 0.56376344, 0.50654378, 0.51577573,\n",
       "        0.4456682 , 0.43483871, 0.46064516, 0.48890937, 0.49855607,\n",
       "        0.5       , 0.56376344, 0.49345622, 0.51577573, 0.46890937,\n",
       "        0.4909831 , 0.56132104, 0.51623656, 0.5       , 0.53371736,\n",
       "        0.56376344, 0.50654378, 0.443702  , 0.51227343, 0.45304147,\n",
       "        0.44860215, 0.48248848, 0.50144393, 0.53371736, 0.56376344,\n",
       "        0.52053763, 0.41623656, 0.48967742, 0.49970814, 0.49814132,\n",
       "        0.49447005, 0.49855607, 0.53371736, 0.46588326, 0.51043011,\n",
       "        0.53016897, 0.5175576 , 0.51056836, 0.48743472, 0.47356375,\n",
       "        0.49855607, 0.48459293, 0.54282642, 0.5197235 , 0.49041475,\n",
       "        0.57268817, 0.51254992, 0.47797235, 0.47328725, 0.53533794,\n",
       "        0.45652842, 0.44824885, 0.50485407, 0.5040553 , 0.50142857,\n",
       "        0.49804916, 0.46480799, 0.52668203, 0.50668203, 0.53557604,\n",
       "        0.56917051, 0.53210445, 0.55359447, 0.46479263, 0.52423963,\n",
       "        0.51646697, 0.47311828, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.54270353, 0.49105991, 0.50894009, 0.4871275 ,\n",
       "        0.51365591, 0.5       , 0.5       , 0.5       , 0.49049155,\n",
       "        0.49106759, 0.49105991, 0.49105991, 0.50915515, 0.52892473,\n",
       "        0.5       , 0.5       , 0.5       , 0.48310292, 0.49105991,\n",
       "        0.5       , 0.50092166, 0.55152074, 0.44863287, 0.5       ,\n",
       "        0.5       , 0.51021505, 0.54268817, 0.49105991, 0.49105991,\n",
       "        0.4871275 , 0.51602151, 0.45986175, 0.5       , 0.5       ,\n",
       "        0.4650768 , 0.49106759, 0.49105991, 0.49105991, 0.50904762,\n",
       "        0.52513057, 0.45986175, 0.5       , 0.5       , 0.54615207,\n",
       "        0.49105991, 0.5       , 0.49907834, 0.53101382, 0.50480799,\n",
       "        0.45986175, 0.5       , 0.5       , 0.54261905, 0.50894009,\n",
       "        0.50894009, 0.48608295, 0.50043011, 0.46579109, 0.45986175,\n",
       "        0.5       , 0.52461598, 0.49106759, 0.49105991, 0.49105991,\n",
       "        0.50907834, 0.55947773, 0.53420891, 0.45986175, 0.5       ,\n",
       "        0.54679724, 0.50894009, 0.5       , 0.49907834, 0.53101382,\n",
       "        0.49127496, 0.46579109, 0.45986175, 0.50070661, 0.50205837,\n",
       "        0.49929339, 0.49929339, 0.49929339, 0.49929339, 0.50070661,\n",
       "        0.49929339, 0.50070661, 0.48185868, 0.51814132, 0.51814132,\n",
       "        0.48185868, 0.48185868, 0.48185868, 0.51814132, 0.51814132,\n",
       "        0.51814132, 0.50642089, 0.49357911, 0.49357911, 0.50642089,\n",
       "        0.50545315, 0.49357911, 0.50365591, 0.49380952, 0.49339478,\n",
       "        0.55445469, 0.55445469, 0.5544086 , 0.55445469, 0.44554531,\n",
       "        0.44554531, 0.5537788 , 0.55445469, 0.55445469, 0.46924731,\n",
       "        0.53211982, 0.53075269, 0.46924731, 0.46924731, 0.46924731,\n",
       "        0.53075269, 0.5303533 , 0.53058372, 0.47714286, 0.52285714,\n",
       "        0.47714286, 0.47714286, 0.47714286, 0.47714286, 0.47714286,\n",
       "        0.52285714, 0.52285714, 0.47714286, 0.52285714, 0.52285714,\n",
       "        0.47772657, 0.47714286, 0.52285714, 0.52285714, 0.52285714,\n",
       "        0.47714286, 0.47714286, 0.47714286, 0.47714286, 0.52285714,\n",
       "        0.52285714, 0.52285714, 0.52196621, 0.52285714, 0.52285714,\n",
       "        0.47714286, 0.47714286, 0.52276498, 0.52285714, 0.47708141,\n",
       "        0.47714286, 0.52285714, 0.52285714, 0.47689708]),\n",
       " 'split1_test_roc_auc_ovo': array([0.47795699, 0.54844854, 0.51935484, 0.50639017, 0.52210445,\n",
       "        0.48067588, 0.51165899, 0.49774194, 0.63980031, 0.5299232 ,\n",
       "        0.51470046, 0.47010753, 0.46347158, 0.47789555, 0.51932412,\n",
       "        0.51285714, 0.57296467, 0.65844854, 0.49250384, 0.5       ,\n",
       "        0.48976959, 0.46155146, 0.47789555, 0.48477727, 0.54789555,\n",
       "        0.60113671, 0.66715822, 0.5       , 0.48870968, 0.49543779,\n",
       "        0.50639017, 0.51689708, 0.58700461, 0.57907834, 0.59614439,\n",
       "        0.66695853, 0.50797235, 0.48870968, 0.49543779, 0.52199693,\n",
       "        0.48824885, 0.55631336, 0.48493088, 0.59777266, 0.65953917,\n",
       "        0.49202765, 0.51129032, 0.52457757, 0.52860215, 0.50831029,\n",
       "        0.56321045, 0.52400922, 0.61201229, 0.65949309, 0.50465438,\n",
       "        0.51929339, 0.49061444, 0.51310292, 0.56046083, 0.49150538,\n",
       "        0.52832565, 0.60642089, 0.65933948, 0.50645161, 0.49493088,\n",
       "        0.53256528, 0.48334869, 0.51360983, 0.45840246, 0.51322581,\n",
       "        0.60235023, 0.65976959, 0.52018433, 0.49009217, 0.54941628,\n",
       "        0.45682028, 0.52176651, 0.52528418, 0.48271889, 0.60290323,\n",
       "        0.65995392, 0.48251152, 0.4309447 , 0.45384025, 0.5       ,\n",
       "        0.47201229, 0.52142857, 0.47741935, 0.51078341, 0.52745008,\n",
       "        0.49095238, 0.44723502, 0.5       , 0.48688172, 0.47201229,\n",
       "        0.52142857, 0.52592934, 0.53499232, 0.53963134, 0.50016897,\n",
       "        0.5       , 0.51351767, 0.51311828, 0.47201229, 0.47145929,\n",
       "        0.49784946, 0.49032258, 0.51384025, 0.5       , 0.5128725 ,\n",
       "        0.51351767, 0.48688172, 0.50341014, 0.51348694, 0.55969278,\n",
       "        0.48311828, 0.51479263, 0.47821813, 0.5128725 , 0.51351767,\n",
       "        0.49545315, 0.49457757, 0.50565284, 0.49789555, 0.49645161,\n",
       "        0.48096774, 0.52178187, 0.53074501, 0.51228879, 0.4635023 ,\n",
       "        0.50560676, 0.47341014, 0.52070661, 0.49291859, 0.43804916,\n",
       "        0.47821813, 0.51798003, 0.47875576, 0.47231951, 0.50471582,\n",
       "        0.50864823, 0.52623656, 0.49095238, 0.43769585, 0.48543779,\n",
       "        0.46935484, 0.5056682 , 0.4859447 , 0.53288786, 0.49884793,\n",
       "        0.5327957 , 0.45941628, 0.43803379, 0.49127496, 0.5056682 ,\n",
       "        0.56016897, 0.46465438, 0.47984639, 0.49313364, 0.45691244,\n",
       "        0.5035023 , 0.4377573 , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.52493856, 0.55560676, 0.44410138, 0.54654378,\n",
       "        0.47399386, 0.5       , 0.5       , 0.5       , 0.50315668,\n",
       "        0.55560676, 0.44439324, 0.43952381, 0.49204301, 0.48556068,\n",
       "        0.5       , 0.5       , 0.5       , 0.5702381 , 0.55560676,\n",
       "        0.5       , 0.44439324, 0.48001536, 0.49225806, 0.5       ,\n",
       "        0.5       , 0.5       , 0.52474654, 0.44439324, 0.55560676,\n",
       "        0.54654378, 0.50554531, 0.56792627, 0.5       , 0.5       ,\n",
       "        0.49490783, 0.55560676, 0.44439324, 0.44437788, 0.48373272,\n",
       "        0.50380952, 0.56788018, 0.5       , 0.5       , 0.57026882,\n",
       "        0.55560676, 0.44439324, 0.55560676, 0.47927803, 0.50774194,\n",
       "        0.56788018, 0.5       , 0.5       , 0.47522273, 0.55560676,\n",
       "        0.55560676, 0.45345622, 0.50201229, 0.56794163, 0.56791091,\n",
       "        0.5       , 0.4956298 , 0.44438556, 0.44439324, 0.44462366,\n",
       "        0.46841782, 0.50734255, 0.43210445, 0.56791091, 0.5       ,\n",
       "        0.56897849, 0.55560676, 0.5       , 0.55560676, 0.46804916,\n",
       "        0.52557604, 0.56789555, 0.56786482, 0.50832565, 0.49239631,\n",
       "        0.50832565, 0.50832565, 0.49167435, 0.50835637, 0.50832565,\n",
       "        0.50832565, 0.49150538, 0.52768049, 0.52768049, 0.52768049,\n",
       "        0.52768049, 0.52768049, 0.47230415, 0.47231951, 0.52768049,\n",
       "        0.47231951, 0.48482335, 0.48482335, 0.51517665, 0.48482335,\n",
       "        0.51517665, 0.51517665, 0.51517665, 0.48482335, 0.48482335,\n",
       "        0.48786482, 0.51213518, 0.51235023, 0.48761905, 0.48956989,\n",
       "        0.4888172 , 0.48786482, 0.48786482, 0.48258065, 0.50407066,\n",
       "        0.49592934, 0.50407066, 0.50407066, 0.50407066, 0.50407066,\n",
       "        0.50407066, 0.50407066, 0.49592934, 0.55222734, 0.44777266,\n",
       "        0.55222734, 0.44777266, 0.55516129, 0.55222734, 0.55222734,\n",
       "        0.55222734, 0.55222734, 0.43989247, 0.56010753, 0.44024578,\n",
       "        0.43989247, 0.56010753, 0.43989247, 0.5584639 , 0.56010753,\n",
       "        0.56010753, 0.56010753, 0.56010753, 0.56010753, 0.43989247,\n",
       "        0.55984639, 0.56010753, 0.56010753, 0.56010753, 0.43989247,\n",
       "        0.43989247, 0.43989247, 0.43989247, 0.43989247, 0.43989247,\n",
       "        0.56010753, 0.56010753, 0.56010753, 0.43989247]),\n",
       " 'split2_test_roc_auc_ovo': array([0.50950845, 0.5352381 , 0.47207373, 0.58015361, 0.49815668,\n",
       "        0.57791091, 0.49341014, 0.4922427 , 0.6288172 , 0.45721966,\n",
       "        0.51139785, 0.41933948, 0.52290323, 0.49815668, 0.42208909,\n",
       "        0.54708141, 0.5672043 , 0.64984639, 0.45453149, 0.5       ,\n",
       "        0.54341014, 0.49367127, 0.50184332, 0.50290323, 0.62474654,\n",
       "        0.58675883, 0.65680492, 0.52076805, 0.49695853, 0.54158218,\n",
       "        0.47709677, 0.50096774, 0.57688172, 0.52583717, 0.58913978,\n",
       "        0.65552995, 0.47910906, 0.50304147, 0.45841782, 0.5127957 ,\n",
       "        0.51768049, 0.60173579, 0.54552995, 0.58506912, 0.65563748,\n",
       "        0.52089094, 0.49695853, 0.51665131, 0.49774194, 0.56740399,\n",
       "        0.5071275 , 0.54324117, 0.59376344, 0.65877112, 0.48709677,\n",
       "        0.47926267, 0.52537634, 0.45694316, 0.61652842, 0.49932412,\n",
       "        0.51837174, 0.58599078, 0.6584639 , 0.49141321, 0.50095238,\n",
       "        0.56617512, 0.49542243, 0.55820276, 0.52892473, 0.49525346,\n",
       "        0.60536098, 0.65517665, 0.46190476, 0.53516129, 0.46817204,\n",
       "        0.5655914 , 0.47313364, 0.57935484, 0.49525346, 0.60536098,\n",
       "        0.65721966, 0.46749616, 0.42402458, 0.50841014, 0.5       ,\n",
       "        0.52490015, 0.51852535, 0.49136713, 0.50403994, 0.41528418,\n",
       "        0.49379416, 0.42402458, 0.53336406, 0.4981106 , 0.52490015,\n",
       "        0.51852535, 0.46924731, 0.479447  , 0.50365591, 0.51801843,\n",
       "        0.5       , 0.46663594, 0.4981106 , 0.52490015, 0.48345622,\n",
       "        0.53863287, 0.48984639, 0.52927803, 0.5       , 0.42402458,\n",
       "        0.46663594, 0.5018894 , 0.46958525, 0.47333333, 0.51052227,\n",
       "        0.4871275 , 0.49107527, 0.51801843, 0.42402458, 0.53336406,\n",
       "        0.52215054, 0.47207373, 0.53858679, 0.49072197, 0.5037788 ,\n",
       "        0.5372043 , 0.51801843, 0.57597542, 0.46743472, 0.49975422,\n",
       "        0.49084485, 0.52448541, 0.50522273, 0.50291859, 0.53317972,\n",
       "        0.51801843, 0.54388633, 0.49875576, 0.49084485, 0.45993856,\n",
       "        0.46582181, 0.48119816, 0.5088172 , 0.53236559, 0.49450077,\n",
       "        0.51898618, 0.52705069, 0.55254992, 0.52479263, 0.53880184,\n",
       "        0.47562212, 0.50485407, 0.52889401, 0.56557604, 0.51569892,\n",
       "        0.51265745, 0.49448541, 0.51104455, 0.54669739, 0.51164363,\n",
       "        0.47837174, 0.52973886, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.48174347, 0.50741935, 0.50741935, 0.526298  ,\n",
       "        0.46112135, 0.5       , 0.5       , 0.5       , 0.45262673,\n",
       "        0.49257296, 0.49258065, 0.50658986, 0.54989247, 0.53101382,\n",
       "        0.5       , 0.5       , 0.5       , 0.49639017, 0.50741935,\n",
       "        0.49258065, 0.49258065, 0.43933948, 0.54700461, 0.5       ,\n",
       "        0.5       , 0.50698925, 0.48174347, 0.50741935, 0.50741935,\n",
       "        0.5265745 , 0.52282642, 0.49133641, 0.5       , 0.5       ,\n",
       "        0.56121352, 0.50742704, 0.50741935, 0.50741935, 0.45033794,\n",
       "        0.56608295, 0.50866359, 0.5       , 0.5       , 0.49477727,\n",
       "        0.50741935, 0.50741935, 0.50854071, 0.43374808, 0.45145929,\n",
       "        0.5087404 , 0.5       , 0.48609831, 0.51832565, 0.49258065,\n",
       "        0.49258065, 0.52663594, 0.49069124, 0.50864823, 0.49133641,\n",
       "        0.5       , 0.56333333, 0.50742704, 0.50741935, 0.49258065,\n",
       "        0.52325653, 0.44281106, 0.49135177, 0.49133641, 0.5       ,\n",
       "        0.50505376, 0.50741935, 0.5       , 0.50723502, 0.56691244,\n",
       "        0.45066052, 0.49133641, 0.49133641, 0.49915515, 0.49915515,\n",
       "        0.49915515, 0.49915515, 0.50084485, 0.49915515, 0.49915515,\n",
       "        0.50084485, 0.49915515, 0.49087558, 0.50912442, 0.49087558,\n",
       "        0.49081413, 0.50912442, 0.50912442, 0.49087558, 0.49087558,\n",
       "        0.49087558, 0.47617512, 0.47585253, 0.47617512, 0.47617512,\n",
       "        0.47617512, 0.52382488, 0.52382488, 0.5234255 , 0.52367127,\n",
       "        0.54694316, 0.54694316, 0.45305684, 0.54694316, 0.45305684,\n",
       "        0.45305684, 0.54694316, 0.54694316, 0.45305684, 0.42665131,\n",
       "        0.42665131, 0.57334869, 0.57334869, 0.42680492, 0.42941628,\n",
       "        0.57334869, 0.42665131, 0.42665131, 0.49248848, 0.50751152,\n",
       "        0.49247312, 0.50751152, 0.50751152, 0.49248848, 0.49248848,\n",
       "        0.50488479, 0.50751152, 0.49248848, 0.50751152, 0.50751152,\n",
       "        0.50751152, 0.4924424 , 0.50751152, 0.50751152, 0.50751152,\n",
       "        0.49248848, 0.49248848, 0.49248848, 0.50751152, 0.50751152,\n",
       "        0.50751152, 0.50821813, 0.49248848, 0.49248848, 0.50751152,\n",
       "        0.50751152, 0.5074808 , 0.49248848, 0.50751152, 0.50751152,\n",
       "        0.50751152, 0.49248848, 0.49248848, 0.49248848]),\n",
       " 'split3_test_roc_auc_ovo': array([0.4752801 , 0.5026001 , 0.5       , 0.48819721, 0.39351718,\n",
       "        0.51118119, 0.53448354, 0.53383162, 0.72719417, 0.50786094,\n",
       "        0.47723586, 0.49891599, 0.5188223 , 0.39351718, 0.48881881,\n",
       "        0.48662048, 0.68236329, 0.76344396, 0.5       , 0.44789945,\n",
       "        0.44025834, 0.58366561, 0.39351718, 0.47296048, 0.57432648,\n",
       "        0.67473734, 0.76690065, 0.4668961 , 0.56307706, 0.48189027,\n",
       "        0.5188223 , 0.4620446 , 0.53690929, 0.51635107, 0.67886111,\n",
       "        0.76500553, 0.4668961 , 0.56307706, 0.48189027, 0.4763262 ,\n",
       "        0.43854516, 0.55601207, 0.59059416, 0.67748147, 0.76729483,\n",
       "        0.5331039 , 0.43692294, 0.54483846, 0.51015024, 0.51733653,\n",
       "        0.47913098, 0.52602374, 0.68384906, 0.76432329, 0.4963538 ,\n",
       "        0.51713944, 0.4252187 , 0.45372125, 0.49041071, 0.49956791,\n",
       "        0.4746585 , 0.68930699, 0.76546036, 0.45085583, 0.44162283,\n",
       "        0.48960718, 0.48898558, 0.57907185, 0.53953971, 0.55560272,\n",
       "        0.68944344, 0.76555133, 0.49050168, 0.42306584, 0.52670598,\n",
       "        0.46077109, 0.48863688, 0.45829985, 0.55561788, 0.68964053,\n",
       "        0.76505102, 0.51988356, 0.50749708, 0.4551009 , 0.54135145,\n",
       "        0.54831031, 0.49407966, 0.47970709, 0.51550205, 0.47579557,\n",
       "        0.45907306, 0.52176352, 0.43369366, 0.54135145, 0.54831031,\n",
       "        0.49407966, 0.46513743, 0.48622629, 0.44377568, 0.42849346,\n",
       "        0.46563774, 0.56630634, 0.54135145, 0.54831031, 0.49471641,\n",
       "        0.4636365 , 0.52588729, 0.55742203, 0.42849346, 0.46563774,\n",
       "        0.43369366, 0.54135145, 0.46735093, 0.53415   , 0.49209357,\n",
       "        0.49461029, 0.47444625, 0.42849346, 0.46563774, 0.43369366,\n",
       "        0.56941433, 0.45355448, 0.44570112, 0.48884913, 0.509468  ,\n",
       "        0.49565639, 0.42849346, 0.46563774, 0.50619324, 0.54909868,\n",
       "        0.47515881, 0.48833366, 0.5594536 , 0.44078897, 0.50278203,\n",
       "        0.42849346, 0.49129004, 0.48384603, 0.5123031 , 0.5169575 ,\n",
       "        0.44327537, 0.47810003, 0.51245471, 0.50278203, 0.50924059,\n",
       "        0.53649995, 0.55235828, 0.55243409, 0.46651708, 0.48842463,\n",
       "        0.53599964, 0.49489835, 0.49703604, 0.44708076, 0.44532209,\n",
       "        0.4557983 , 0.56140936, 0.46280265, 0.5249928 , 0.52206674,\n",
       "        0.51810973, 0.50278203, 0.5       , 0.5       , 0.5       ,\n",
       "        0.46142301, 0.50476053, 0.53700026, 0.53700026, 0.49210873,\n",
       "        0.54797677, 0.5       , 0.5       , 0.5       , 0.50253946,\n",
       "        0.46299974, 0.53700026, 0.53700026, 0.52979881, 0.55284343,\n",
       "        0.5       , 0.5       , 0.5       , 0.53358905, 0.53700026,\n",
       "        0.53700026, 0.53700026, 0.49692991, 0.47746327, 0.5       ,\n",
       "        0.5       , 0.5       , 0.50477569, 0.46299974, 0.53700026,\n",
       "        0.4921239 , 0.56918692, 0.51833715, 0.5       , 0.5       ,\n",
       "        0.51780652, 0.53700026, 0.53700026, 0.53700026, 0.52981398,\n",
       "        0.54503555, 0.48166285, 0.5       , 0.5       , 0.53335405,\n",
       "        0.53700026, 0.53700026, 0.53700026, 0.50196334, 0.47746327,\n",
       "        0.48166285, 0.5       , 0.5       , 0.50483634, 0.53700026,\n",
       "        0.53700026, 0.5078761 , 0.53607544, 0.49223002, 0.48166285,\n",
       "        0.5       , 0.49756667, 0.53700026, 0.46272685, 0.53700026,\n",
       "        0.52979881, 0.44239603, 0.50623872, 0.48166285, 0.5       ,\n",
       "        0.5338013 , 0.53700026, 0.53700026, 0.53700026, 0.52575085,\n",
       "        0.52253673, 0.50623872, 0.48166285, 0.47394594, 0.52438636,\n",
       "        0.47511333, 0.52335542, 0.52438636, 0.47561364, 0.52438636,\n",
       "        0.47561364, 0.47547719, 0.50667839, 0.50916478, 0.49189648,\n",
       "        0.50966509, 0.50801255, 0.50789127, 0.49169939, 0.50846738,\n",
       "        0.49169939, 0.52505344, 0.47494656, 0.47494656, 0.52505344,\n",
       "        0.52505344, 0.52505344, 0.47538622, 0.47494656, 0.52505344,\n",
       "        0.50808836, 0.50808836, 0.49169939, 0.50808836, 0.50408587,\n",
       "        0.50808836, 0.49191164, 0.49191164, 0.5103625 , 0.46680514,\n",
       "        0.53319486, 0.53319486, 0.46680514, 0.53319486, 0.53319486,\n",
       "        0.46680514, 0.53319486, 0.53319486, 0.44262345, 0.55749784,\n",
       "        0.44262345, 0.55737655, 0.55737655, 0.44262345, 0.44262345,\n",
       "        0.55737655, 0.44254764, 0.55737655, 0.55737655, 0.55737655,\n",
       "        0.44262345, 0.55737655, 0.55737655, 0.44262345, 0.44262345,\n",
       "        0.55737655, 0.44262345, 0.55737655, 0.55737655, 0.55737655,\n",
       "        0.44168347, 0.55746752, 0.44262345, 0.44262345, 0.55736139,\n",
       "        0.44228991, 0.44262345, 0.44262345, 0.55737655, 0.44262345,\n",
       "        0.55758881, 0.44101639, 0.44262345, 0.55737655]),\n",
       " 'split4_test_roc_auc_ovo': array([0.4801316 , 0.53348292, 0.43669552, 0.49544414, 0.48245122,\n",
       "        0.5562698 , 0.51042314, 0.54162434, 0.6507679 , 0.51742749,\n",
       "        0.5       , 0.52640277, 0.50455586, 0.48245122, 0.5562698 ,\n",
       "        0.48875817, 0.64229294, 0.69135372, 0.5       , 0.50273655,\n",
       "        0.51720008, 0.48719659, 0.48245122, 0.48208736, 0.5672918 ,\n",
       "        0.64186843, 0.68759381, 0.50699677, 0.4745827 , 0.52294607,\n",
       "        0.49544414, 0.48701466, 0.46090753, 0.5363635 , 0.63970042,\n",
       "        0.6861232 , 0.50695129, 0.5254173 , 0.52294607, 0.52641793,\n",
       "        0.43621037, 0.49377644, 0.54934126, 0.63627405, 0.68151427,\n",
       "        0.49300323, 0.4745827 , 0.51137828, 0.52052032, 0.5188223 ,\n",
       "        0.48584727, 0.53910763, 0.61724708, 0.68058946, 0.49207841,\n",
       "        0.55871071, 0.49570188, 0.4456708 , 0.47706909, 0.46207493,\n",
       "        0.53633318, 0.64202004, 0.67895208, 0.5182007 , 0.44072833,\n",
       "        0.51971679, 0.49313968, 0.50564745, 0.58045149, 0.50823997,\n",
       "        0.63154384, 0.680923  , 0.49929502, 0.47001925, 0.43295077,\n",
       "        0.50094756, 0.45934596, 0.5377583 , 0.50823997, 0.6332267 ,\n",
       "        0.67901272, 0.55891539, 0.50542003, 0.53295229, 0.49489835,\n",
       "        0.45807244, 0.57127913, 0.58299853, 0.50952865, 0.49806698,\n",
       "        0.54065404, 0.45097712, 0.55884716, 0.50510165, 0.45807244,\n",
       "        0.57127913, 0.48619597, 0.47911581, 0.52302188, 0.50510165,\n",
       "        0.48916751, 0.55884716, 0.49489835, 0.45807244, 0.58835034,\n",
       "        0.43854516, 0.47946452, 0.53692445, 0.49489835, 0.48916751,\n",
       "        0.55884716, 0.50510165, 0.51583559, 0.43830258, 0.472445  ,\n",
       "        0.46863961, 0.49944663, 0.48887946, 0.51083249, 0.44115284,\n",
       "        0.56797404, 0.44028866, 0.44861202, 0.52684243, 0.45140163,\n",
       "        0.48969815, 0.48887946, 0.48916751, 0.53120878, 0.47030731,\n",
       "        0.50498037, 0.5175033 , 0.47682651, 0.50429812, 0.50193302,\n",
       "        0.48887946, 0.46057399, 0.41706211, 0.4879698 , 0.55630013,\n",
       "        0.46544065, 0.47380949, 0.48806077, 0.49583832, 0.54230658,\n",
       "        0.4415925 , 0.50367653, 0.58360497, 0.50637517, 0.50152367,\n",
       "        0.52796434, 0.47703877, 0.49583832, 0.45902758, 0.45074971,\n",
       "        0.51536561, 0.46307555, 0.55097864, 0.47279371, 0.53983535,\n",
       "        0.52108128, 0.4961567 , 0.5       , 0.5       , 0.5       ,\n",
       "        0.49833988, 0.5026001 , 0.5224306 , 0.4775694 , 0.49312452,\n",
       "        0.44826332, 0.5       , 0.5       , 0.5       , 0.48953896,\n",
       "        0.4775694 , 0.47742537, 0.51322791, 0.5487803 , 0.53060234,\n",
       "        0.5       , 0.5       , 0.5       , 0.51789748, 0.5224306 ,\n",
       "        0.5224306 , 0.4775694 , 0.53134523, 0.48710563, 0.5       ,\n",
       "        0.5       , 0.5       , 0.50258494, 0.4775694 , 0.48211768,\n",
       "        0.49312452, 0.55874104, 0.50572325, 0.5       , 0.5       ,\n",
       "        0.49053958, 0.4775694 , 0.5224306 , 0.4775694 , 0.4512197 ,\n",
       "        0.5356661 , 0.4942161 , 0.5       , 0.5       , 0.51855698,\n",
       "        0.5224306 , 0.5224306 , 0.47755424, 0.5318607 , 0.47728134,\n",
       "        0.50572325, 0.5       , 0.5       , 0.49740748, 0.5224306 ,\n",
       "        0.5224306 , 0.50687548, 0.45252354, 0.5584833 , 0.50572325,\n",
       "        0.5       , 0.49110053, 0.5224306 , 0.5224306 , 0.5224306 ,\n",
       "        0.5487803 , 0.46810898, 0.4415167 , 0.49427675, 0.5       ,\n",
       "        0.51782926, 0.5224306 , 0.4766749 , 0.5224306 , 0.46866993,\n",
       "        0.47418851, 0.4415167 , 0.49427675, 0.55645174, 0.55645174,\n",
       "        0.44354826, 0.55645174, 0.44350278, 0.44354826, 0.55645174,\n",
       "        0.55645174, 0.44354826, 0.53251262, 0.46748738, 0.46748738,\n",
       "        0.53251262, 0.53251262, 0.53251262, 0.53251262, 0.53251262,\n",
       "        0.53251262, 0.50291848, 0.49708152, 0.50291848, 0.49047135,\n",
       "        0.49708152, 0.50291848, 0.50291848, 0.49708152, 0.50291848,\n",
       "        0.46960991, 0.53037493, 0.53039009, 0.53039009, 0.46960991,\n",
       "        0.46957959, 0.53039009, 0.53039009, 0.46960991, 0.42929699,\n",
       "        0.42929699, 0.42929699, 0.42929699, 0.42929699, 0.57070301,\n",
       "        0.42929699, 0.57070301, 0.57070301, 0.44479146, 0.44479146,\n",
       "        0.44479146, 0.44479146, 0.44471566, 0.44479146, 0.44479146,\n",
       "        0.55520854, 0.44479146, 0.54853773, 0.54853773, 0.54853773,\n",
       "        0.45146227, 0.54853773, 0.54853773, 0.54853773, 0.54853773,\n",
       "        0.45143195, 0.54853773, 0.45146227, 0.45146227, 0.45143195,\n",
       "        0.45146227, 0.54853773, 0.54853773, 0.54853773, 0.45146227,\n",
       "        0.45146227, 0.45146227, 0.45143195, 0.45146227, 0.54853773,\n",
       "        0.45146227, 0.45146227, 0.54853773, 0.54853773]),\n",
       " 'mean_test_roc_auc_ovo': array([0.49699632, 0.53298312, 0.47871852, 0.5211891 , 0.48065605,\n",
       "        0.5297667 , 0.5118139 , 0.52584388, 0.65493496, 0.50472282,\n",
       "        0.50435961, 0.49326344, 0.49604276, 0.47181426, 0.50185951,\n",
       "        0.51245822, 0.6113675 , 0.69041268, 0.48562519, 0.47901199,\n",
       "        0.48209076, 0.51236906, 0.46973132, 0.48289282, 0.5747937 ,\n",
       "        0.62137338, 0.6949204 , 0.50825937, 0.51096974, 0.51242042,\n",
       "        0.4923986 , 0.4908564 , 0.53606721, 0.54131403, 0.62008097,\n",
       "        0.69426261, 0.48285857, 0.50974496, 0.49578754, 0.49954115,\n",
       "        0.47217077, 0.54643389, 0.53814991, 0.6192703 , 0.6933993 ,\n",
       "        0.49847795, 0.47764675, 0.51316347, 0.52236146, 0.52408891,\n",
       "        0.51570533, 0.53348096, 0.62377683, 0.69315152, 0.5101104 ,\n",
       "        0.51123147, 0.48931775, 0.47827779, 0.53380625, 0.48918571,\n",
       "        0.51617376, 0.62712255, 0.6928364 , 0.49413696, 0.47709389,\n",
       "        0.5217757 , 0.5011931 , 0.54866429, 0.52509502, 0.51020325,\n",
       "        0.62860913, 0.69232098, 0.49004843, 0.4791055 , 0.50005117,\n",
       "        0.48415325, 0.48860732, 0.516419  , 0.5041049 , 0.62908958,\n",
       "        0.69257312, 0.50787807, 0.48032075, 0.47730803, 0.50724996,\n",
       "        0.50381418, 0.5319289 , 0.50735218, 0.51984178, 0.46821337,\n",
       "        0.49335249, 0.47554352, 0.51793366, 0.50759784, 0.50381418,\n",
       "        0.51019618, 0.47626975, 0.48808532, 0.49979884, 0.49006772,\n",
       "        0.49096105, 0.53381411, 0.50818698, 0.50381418, 0.50137833,\n",
       "        0.48592942, 0.50936836, 0.53074027, 0.48467836, 0.48508394,\n",
       "        0.50729157, 0.5083536 , 0.47997678, 0.49430926, 0.49755902,\n",
       "        0.47641956, 0.49244985, 0.48301068, 0.48941693, 0.49709833,\n",
       "        0.53510594, 0.4553462 , 0.48564604, 0.50080344, 0.49184827,\n",
       "        0.49959933, 0.49114586, 0.51904861, 0.49660176, 0.49861853,\n",
       "        0.50135195, 0.50425802, 0.51455556, 0.4856718 , 0.48990154,\n",
       "        0.48243311, 0.49966467, 0.48424922, 0.49663215, 0.50566535,\n",
       "        0.49117485, 0.49437883, 0.49565148, 0.48839381, 0.51336473,\n",
       "        0.48459238, 0.50740051, 0.53587755, 0.50692561, 0.50580533,\n",
       "        0.51408619, 0.48020309, 0.49729684, 0.49392827, 0.49060299,\n",
       "        0.52263217, 0.50314583, 0.51165334, 0.50048203, 0.51093956,\n",
       "        0.50750641, 0.48791063, 0.5       , 0.5       , 0.5       ,\n",
       "        0.49195258, 0.51134924, 0.52270338, 0.4950061 , 0.50904051,\n",
       "        0.48900224, 0.5       , 0.5       , 0.5       , 0.48767067,\n",
       "        0.49596329, 0.48849188, 0.49748035, 0.52593395, 0.525789  ,\n",
       "        0.5       , 0.5       , 0.5       , 0.52024354, 0.52270338,\n",
       "        0.5104023 , 0.49049304, 0.49983014, 0.49049289, 0.5       ,\n",
       "        0.5       , 0.50344086, 0.51130776, 0.47668833, 0.51464079,\n",
       "        0.50909884, 0.53446424, 0.50863697, 0.5       , 0.5       ,\n",
       "        0.50590885, 0.51373421, 0.50046067, 0.49148536, 0.48483039,\n",
       "        0.53514494, 0.5024569 , 0.5       , 0.5       , 0.53262184,\n",
       "        0.52270338, 0.50224869, 0.51555606, 0.4955728 , 0.48375077,\n",
       "        0.50477369, 0.5       , 0.49721966, 0.50768225, 0.52331167,\n",
       "        0.52331167, 0.49618534, 0.49634652, 0.51861885, 0.50129903,\n",
       "        0.5       , 0.51444926, 0.50046221, 0.48560599, 0.49753901,\n",
       "        0.51586636, 0.48402727, 0.48108411, 0.49900973, 0.5       ,\n",
       "        0.53449201, 0.52627941, 0.50273503, 0.5242702 , 0.51207924,\n",
       "        0.49284735, 0.49455569, 0.49900052, 0.50771702, 0.51488959,\n",
       "        0.48508716, 0.51731627, 0.49194035, 0.48519336, 0.5178051 ,\n",
       "        0.50810586, 0.48207852, 0.50792115, 0.50631968, 0.49921625,\n",
       "        0.5085062 , 0.51183775, 0.50073823, 0.50110968, 0.51553548,\n",
       "        0.50110968, 0.49907826, 0.48525661, 0.49255918, 0.49658883,\n",
       "        0.50378798, 0.51211051, 0.50419243, 0.49481729, 0.50597226,\n",
       "        0.51339219, 0.53039926, 0.50838103, 0.52549907, 0.47237356,\n",
       "        0.47301746, 0.5221777 , 0.52231288, 0.49401291, 0.45921428,\n",
       "        0.48343846, 0.51413278, 0.48855376, 0.47252295, 0.50132643,\n",
       "        0.50085483, 0.51299463, 0.51141245, 0.48185472, 0.49608612,\n",
       "        0.48185165, 0.48691901, 0.50838158, 0.48185472, 0.48185472,\n",
       "        0.53851087, 0.49398702, 0.50308762, 0.53927809, 0.51530574,\n",
       "        0.46384326, 0.52712141, 0.51523508, 0.51599875, 0.51632747,\n",
       "        0.50770947, 0.50418001, 0.50771554, 0.51072015, 0.49581393,\n",
       "        0.49667216, 0.53943761, 0.51314468, 0.51332286, 0.49581696,\n",
       "        0.46365981, 0.46372037, 0.46984027, 0.49581999, 0.48312932,\n",
       "        0.5107626 , 0.49358636, 0.51332286, 0.50303846]),\n",
       " 'std_test_roc_auc_ovo': array([0.02572861, 0.01622082, 0.02860021, 0.03364346, 0.04542538,\n",
       "        0.03412976, 0.01312988, 0.02709481, 0.03706838, 0.02491825,\n",
       "        0.01490037, 0.04588814, 0.02460968, 0.04053662, 0.04524864,\n",
       "        0.02297351, 0.04426415, 0.04000965, 0.01701744, 0.02686324,\n",
       "        0.04621652, 0.04288599, 0.0390059 , 0.01120488, 0.02646835,\n",
       "        0.03236277, 0.03862606, 0.02611498, 0.03210407, 0.02117987,\n",
       "        0.01964853, 0.01809682, 0.04519753, 0.02177839, 0.03441982,\n",
       "        0.03828402, 0.02167924, 0.03249681, 0.02418902, 0.02642502,\n",
       "        0.03104011, 0.03608034, 0.0348686 , 0.03373548, 0.04066115,\n",
       "        0.02759761, 0.02552134, 0.02512066, 0.01923201, 0.02208749,\n",
       "        0.03260685, 0.00741111, 0.03107707, 0.03905646, 0.03067524,\n",
       "        0.02913853, 0.03425161, 0.03237756, 0.05048   , 0.01392257,\n",
       "        0.02159399, 0.03589356, 0.03963302, 0.02325536, 0.02958555,\n",
       "        0.02670642, 0.0223191 , 0.03331186, 0.03945553, 0.02565312,\n",
       "        0.03207128, 0.03998431, 0.01960942, 0.03602675, 0.04287955,\n",
       "        0.04575135, 0.02158014, 0.04265957, 0.02775642, 0.03209533,\n",
       "        0.03957981, 0.03171883, 0.04433278, 0.03686295, 0.01716484,\n",
       "        0.03367869, 0.02746928, 0.03909593, 0.02009093, 0.04283151,\n",
       "        0.02661157, 0.04377114, 0.04781292, 0.01825274, 0.03367869,\n",
       "        0.0408663 , 0.02984754, 0.02494697, 0.03285723, 0.03153645,\n",
       "        0.01333862, 0.03874071, 0.0179962 , 0.03367869, 0.04445019,\n",
       "        0.03372691, 0.0303646 , 0.01580043, 0.02816185, 0.0381064 ,\n",
       "        0.05090255, 0.01791946, 0.02614664, 0.03421847, 0.03652683,\n",
       "        0.01627742, 0.0139528 , 0.03031457, 0.03952955, 0.05134021,\n",
       "        0.02901655, 0.02675225, 0.03517489, 0.0136545 , 0.02073411,\n",
       "        0.01949954, 0.03360378, 0.0383099 , 0.02580724, 0.0307367 ,\n",
       "        0.01821082, 0.0198325 , 0.02675874, 0.02330014, 0.03206012,\n",
       "        0.02998357, 0.02869279, 0.04046276, 0.01719548, 0.03167275,\n",
       "        0.04593283, 0.02100919, 0.01302257, 0.03160522, 0.02224061,\n",
       "        0.03673169, 0.03441836, 0.03545628, 0.022955  , 0.01718577,\n",
       "        0.02349263, 0.01733629, 0.03279077, 0.04175128, 0.03610536,\n",
       "        0.04048183, 0.03845897, 0.03661688, 0.0310838 , 0.02847841,\n",
       "        0.01575983, 0.03089637, 0.        , 0.        , 0.        ,\n",
       "        0.01527832, 0.02080491, 0.02245893, 0.03164517, 0.02334309,\n",
       "        0.03673705, 0.        , 0.        , 0.        , 0.01844138,\n",
       "        0.03167881, 0.02981118, 0.03253606, 0.02254342, 0.02195705,\n",
       "        0.        , 0.        , 0.        , 0.03043508, 0.02245893,\n",
       "        0.01665028, 0.03022664, 0.03930719, 0.03203185, 0.        ,\n",
       "        0.        , 0.00433588, 0.02077563, 0.02182689, 0.02772766,\n",
       "        0.023382  , 0.02492751, 0.03548559, 0.        , 0.        ,\n",
       "        0.03232539, 0.02883078, 0.03193172, 0.03078457, 0.03140258,\n",
       "        0.02067584, 0.03642356, 0.        , 0.        , 0.02542019,\n",
       "        0.02245893, 0.03160388, 0.0276723 , 0.0366102 , 0.02070318,\n",
       "        0.03619464, 0.        , 0.00556068, 0.02236583, 0.02182689,\n",
       "        0.02182689, 0.024924  , 0.02675668, 0.03900889, 0.03649273,\n",
       "        0.        , 0.02711963, 0.0319343 , 0.02857819, 0.03175966,\n",
       "        0.02694252, 0.04454593, 0.03879436, 0.03650242, 0.        ,\n",
       "        0.02229561, 0.01814495, 0.01936841, 0.02035802, 0.03840606,\n",
       "        0.02857614, 0.04281618, 0.03648502, 0.02697547, 0.02339128,\n",
       "        0.02351472, 0.0214641 , 0.02657958, 0.02347915, 0.02129279,\n",
       "        0.02654618, 0.02123978, 0.0198319 , 0.02059099, 0.0214394 ,\n",
       "        0.01984139, 0.01788397, 0.02142914, 0.02144008, 0.01483633,\n",
       "        0.02144008, 0.01715301, 0.00898904, 0.01548255, 0.01731747,\n",
       "        0.01668617, 0.01218239, 0.01635723, 0.01624375, 0.01607571,\n",
       "        0.03288909, 0.01835057, 0.03451879, 0.02473955, 0.02191763,\n",
       "        0.0229981 , 0.02746929, 0.02762568, 0.03556437, 0.02872549,\n",
       "        0.04723913, 0.04784238, 0.04855525, 0.04158291, 0.04906399,\n",
       "        0.04987883, 0.04811328, 0.04854186, 0.04000091, 0.04378118,\n",
       "        0.04000009, 0.04193103, 0.04386072, 0.04000091, 0.04000091,\n",
       "        0.0209696 , 0.04353055, 0.04425404, 0.02062001, 0.04153574,\n",
       "        0.02560028, 0.03510728, 0.04166348, 0.04090252, 0.04124763,\n",
       "        0.04369332, 0.04416425, 0.04368551, 0.04304686, 0.04417034,\n",
       "        0.0444113 , 0.02041912, 0.0422751 , 0.04231376, 0.04416002,\n",
       "        0.02559337, 0.02552743, 0.03252832, 0.04416425, 0.0410353 ,\n",
       "        0.04309292, 0.0443195 , 0.04231376, 0.04428296]),\n",
       " 'rank_test_roc_auc_ovo': array([210,  35, 303,  60, 297,  40,  98,  44,   9, 143, 144, 237, 218,\n",
       "        316, 160,  92,  17,   8, 271, 302, 290,  94, 318, 287,  18,  14,\n",
       "          1, 121, 104,  93, 241, 249,  26,  21,  15,   2, 288, 112, 223,\n",
       "        197, 315,  20,  25,  16,   3, 203, 305,  89,  56,  49,  73,  34,\n",
       "         13,   4, 111, 103, 257, 304,  33, 258,  70,  12,   5, 231, 307,\n",
       "         59, 165,  19,  47, 109,  11,   7, 254, 301, 174, 281, 260,  68,\n",
       "        148,  10,   6, 125, 298, 306, 135, 149,  37, 133,  62, 319, 236,\n",
       "        311,  65, 130, 149, 110, 310, 264, 194, 253, 248,  32, 122, 149,\n",
       "        161, 268, 113,  38, 278, 276, 134, 120, 300, 230, 204, 309, 240,\n",
       "        286, 256, 209,  29, 324, 270, 169, 244, 196, 247,  63, 213, 202,\n",
       "        162, 145,  80, 269, 255, 289, 195, 280, 212, 141, 246, 229, 224,\n",
       "        263,  86, 279, 132,  27, 136, 140,  83, 299, 207, 234, 250,  55,\n",
       "        154,  99, 171, 105, 131, 265, 175, 175, 175, 242, 101,  52, 226,\n",
       "        115, 259, 175, 175, 175, 266, 219, 262, 206,  43,  45, 175, 175,\n",
       "        175,  61,  52, 108, 251, 193, 252, 175, 175, 153, 102, 308,  79,\n",
       "        114,  31, 116, 175, 175, 139,  84, 173, 245, 277,  28, 158, 175,\n",
       "        175,  36,  52, 159,  74, 225, 283, 142, 175, 208, 129,  50,  50,\n",
       "        216, 215,  64, 164, 175,  81, 172, 272, 205,  72, 282, 296, 200,\n",
       "        175,  30,  42, 157,  48,  96, 238, 228, 201, 126,  78, 275,  67,\n",
       "        243, 274,  66, 123, 291, 124, 137, 198, 117,  97, 170, 166,  75,\n",
       "        166, 199, 273, 239, 214, 152,  95, 146, 227, 138,  85,  39, 119,\n",
       "         46, 314, 312,  58,  57, 232, 323, 284,  82, 261, 313, 163, 168,\n",
       "         91, 100, 292, 217, 295, 267, 118, 292, 292,  24, 233, 155,  23,\n",
       "         76, 320,  41,  77,  71,  69, 128, 147, 127, 107, 222, 211,  22,\n",
       "         90,  87, 221, 322, 321, 317, 220, 285, 106, 235,  87, 156]),\n",
       " 'split0_test_neg_log_loss': array([-0.25364087, -0.2536406 , -0.25367097, -0.25358336, -0.25364212,\n",
       "        -0.2536343 , -0.25349077, -0.25137787, -0.23267069, -0.25364084,\n",
       "        -0.25360802, -0.25351897, -0.25368644, -0.25364101, -0.25363839,\n",
       "        -0.25391335, -0.24875914, -0.23045989, -0.25374894, -0.25365331,\n",
       "        -0.25375663, -0.25360999, -0.25366334, -0.25532411, -0.25197612,\n",
       "        -0.24776998, -0.23034102, -0.25358078, -0.25352141, -0.25358325,\n",
       "        -0.25376437, -0.25364365, -0.25499358, -0.25274675, -0.24770866,\n",
       "        -0.23019486, -0.25381205, -0.25369007, -0.25356153, -0.25364579,\n",
       "        -0.2563822 , -0.25439936, -0.25350253, -0.24755259, -0.22936753,\n",
       "        -0.25411017, -0.2537873 , -0.25375958, -0.25361935, -0.25535115,\n",
       "        -0.25307006, -0.25362   , -0.24774963, -0.22946366, -0.25274792,\n",
       "        -0.25409485, -0.25368678, -0.25351376, -0.25342533, -0.25379196,\n",
       "        -0.26642035, -0.2482177 , -0.22938073, -0.25371431, -0.25419533,\n",
       "        -0.25378185, -0.25331013, -0.2506832 , -0.67597134, -0.25370025,\n",
       "        -0.24838892, -0.22956206, -0.2565988 , -0.25401518, -0.25376025,\n",
       "        -0.25458238, -0.43363701, -0.25384142, -0.25373786, -0.24839367,\n",
       "        -0.22961744, -0.25364087, -0.25364085, -0.25365055, -0.25364285,\n",
       "        -0.25363724, -0.25357834, -0.25365323, -0.25327586, -0.2544627 ,\n",
       "        -0.25364089, -0.25361582, -0.25353431, -0.25363457, -0.25363093,\n",
       "        -0.25384173, -0.25380806, -0.25364251, -0.25423967, -0.25366061,\n",
       "        -0.25364285, -0.25351932, -0.25368394, -0.25363715, -0.25390508,\n",
       "        -0.25386626, -0.25361704, -0.25359416, -0.25364285, -0.25363679,\n",
       "        -0.25346547, -0.25363657, -0.25561419, -0.25375416, -0.25498135,\n",
       "        -0.25393795, -0.25411738, -0.25363451, -0.25358831, -0.25358634,\n",
       "        -0.25340543, -0.25413998, -0.25372734, -0.25395725, -0.25370518,\n",
       "        -0.25364919, -0.25368499, -0.25363766, -0.25373674, -0.25356231,\n",
       "        -0.25336931, -0.25314195, -0.25358643, -0.25363794, -0.25439817,\n",
       "        -0.25364397, -0.25366892, -0.25356867, -0.25371617, -0.25365473,\n",
       "        -0.25297873, -0.2544633 , -0.25368447, -0.25487256, -0.25347188,\n",
       "        -0.2543593 , -0.25392253, -0.25363758, -0.25361803, -0.25421421,\n",
       "        -0.25363532, -0.2538142 , -0.25341223, -0.25398542, -0.2535568 ,\n",
       "        -0.25281911, -0.25334162, -0.25312954, -0.25377268, -0.25357409,\n",
       "        -0.25357084, -0.25468297, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364122, -0.25363912, -0.25390611,\n",
       "        -0.25345983, -0.25364087, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25638193, -0.25544873, -0.25376306, -0.25325063,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364285, -0.25363366, -0.25279626, -0.25380188, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25364098, -0.25659572,\n",
       "        -0.25367756, -0.25371778, -0.25381523, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25538458, -0.25598507, -0.25361122,\n",
       "        -0.25346624, -0.25366592, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364285, -0.25459142, -0.25327784, -0.25456406,\n",
       "        -0.25453945, -0.25364087, -0.25364087, -0.25364087, -0.25364079,\n",
       "        -0.25361494, -0.25451223, -0.25412557, -0.25407888, -0.25375212,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25620911, -0.25736236,\n",
       "        -0.25352583, -0.25354795, -0.253588  , -0.25397858, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364285, -0.25396506, -0.25329943,\n",
       "        -0.25637177, -0.25394578, -0.25463877, -0.25367505, -0.25391403,\n",
       "        -0.25364366, -0.25377854, -0.2536558 , -0.2536398 , -0.25374993,\n",
       "        -0.25365162, -0.25367851, -0.25373283, -0.25358071, -0.25362442,\n",
       "        -0.25378576, -0.25376409, -0.25374419, -0.2536074 , -0.25367186,\n",
       "        -0.25358606, -0.25357484, -0.2540705 , -0.25369264, -0.25358354,\n",
       "        -0.25385855, -0.25366303, -0.25392225, -0.25427837, -0.25448037,\n",
       "        -0.25303478, -0.25346863, -0.25282869, -0.25360786, -0.25451412,\n",
       "        -0.25369149, -0.25279841, -0.25307688, -0.2534547 , -0.2536835 ,\n",
       "        -0.25335392, -0.25355807, -0.25369166, -0.2537325 , -0.25411132,\n",
       "        -0.25351565, -0.25355459, -0.25340522, -0.25374801, -0.25357276,\n",
       "        -0.25381028, -0.2538033 , -0.25393829, -0.25377519, -0.25365485,\n",
       "        -0.25356449, -0.2536279 , -0.25381113, -0.25361446, -0.25353684,\n",
       "        -0.25420011, -0.25386709, -0.25363409, -0.25361855, -0.25353506,\n",
       "        -0.25404284, -0.25374409, -0.25378153, -0.25394039, -0.25353468,\n",
       "        -0.2536036 , -0.25354117, -0.25357359, -0.25353528, -0.25359423,\n",
       "        -0.25376083, -0.25365484, -0.253527  , -0.25355231, -0.25407979,\n",
       "        -0.25391348, -0.25353224, -0.25352905, -0.25417343]),\n",
       " 'split1_test_neg_log_loss': array([-0.25364087, -0.25364067, -0.25364214, -0.25364883, -0.25361823,\n",
       "        -0.25365256, -0.25359156, -0.25426108, -0.22718901, -0.25364071,\n",
       "        -0.25363707, -0.25364795, -0.25377745, -0.2536625 , -0.25359413,\n",
       "        -0.25664551, -0.25071213, -0.22507105, -0.2538226 , -0.25364285,\n",
       "        -0.25365731, -0.25367528, -0.25365801, -0.25438216, -0.25364372,\n",
       "        -0.24858941, -0.22506654, -0.25364285, -0.25367167, -0.25364297,\n",
       "        -0.25374453, -0.25358011, -0.25163215, -0.25195302, -0.24894686,\n",
       "        -0.22455617, -0.25364698, -0.25369194, -0.25366711, -0.2535227 ,\n",
       "        -0.25567504, -0.25291799, -0.25508291, -0.24860069, -0.22226034,\n",
       "        -0.25366289, -0.2535913 , -0.25362293, -0.25335164, -0.25608735,\n",
       "        -0.25225536, -0.25375724, -0.24739124, -0.22221224, -0.25385615,\n",
       "        -0.25373191, -0.25404923, -0.25340754, -0.25271924, -0.25445698,\n",
       "        -0.27263864, -0.24929905, -0.22256009, -0.25363244, -0.25394374,\n",
       "        -0.25346072, -0.25373376, -0.25470305, -1.95522085, -0.25330117,\n",
       "        -0.24997034, -0.22229582, -0.25346837, -0.25402167, -0.25336933,\n",
       "        -0.25376214, -0.27204481, -0.25345456, -0.2539682 , -0.25045124,\n",
       "        -0.22231869, -0.25364087, -0.25364248, -0.25384171, -0.25364285,\n",
       "        -0.25367019, -0.25361325, -0.25366951, -0.253853  , -0.25344879,\n",
       "        -0.25364088, -0.25366506, -0.25364285, -0.25366817, -0.25366226,\n",
       "        -0.25355511, -0.25359203, -0.25330119, -0.25315713, -0.25362648,\n",
       "        -0.25364285, -0.25363582, -0.25363026, -0.25368396, -0.25372532,\n",
       "        -0.25364468, -0.25374937, -0.25362096, -0.25364285, -0.25363609,\n",
       "        -0.25363557, -0.25369321, -0.25364132, -0.25361257, -0.25351897,\n",
       "        -0.25438072, -0.25370359, -0.2536577 , -0.25363983, -0.25363565,\n",
       "        -0.25364362, -0.25366822, -0.25363271, -0.25455262, -0.25368474,\n",
       "        -0.25379364, -0.25361891, -0.25358408, -0.25364035, -0.25494105,\n",
       "        -0.25363749, -0.25384869, -0.25356855, -0.25388401, -0.25420232,\n",
       "        -0.25366047, -0.25366467, -0.25423585, -0.25371326, -0.25375969,\n",
       "        -0.25357223, -0.25453692, -0.25363847, -0.25480014, -0.25376466,\n",
       "        -0.25393453, -0.25363839, -0.25378838, -0.25357427, -0.25408589,\n",
       "        -0.2535491 , -0.25395942, -0.25434898, -0.25367309, -0.25363956,\n",
       "        -0.25353714, -0.25376441, -0.2543866 , -0.25364653, -0.25414236,\n",
       "        -0.25364052, -0.25484503, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364086, -0.2543306 , -0.25336314,\n",
       "        -0.25483391, -0.25364087, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25401459, -0.25521056, -0.25378036, -0.25392831,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364285, -0.25377885, -0.25407702, -0.25370012, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25364092, -0.25360379,\n",
       "        -0.25337575, -0.25357772, -0.25335961, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25365591, -0.25407569, -0.25417399,\n",
       "        -0.25387527, -0.25335931, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25372654, -0.25348554, -0.2546162 , -0.25446257,\n",
       "        -0.2533698 , -0.25364087, -0.25364087, -0.25364087, -0.25364086,\n",
       "        -0.25359938, -0.25404214, -0.25365496, -0.25336754, -0.25356047,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25392352, -0.2541613 ,\n",
       "        -0.2543087 , -0.25352035, -0.25369615, -0.25337837, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364285, -0.25339357, -0.25390768,\n",
       "        -0.25347127, -0.25344239, -0.25336586, -0.25374515, -0.25389395,\n",
       "        -0.25366327, -0.25366592, -0.253788  , -0.25367704, -0.25363892,\n",
       "        -0.25364129, -0.2538946 , -0.25354834, -0.25356206, -0.25355087,\n",
       "        -0.25350176, -0.25354151, -0.25416812, -0.25369228, -0.25352107,\n",
       "        -0.25371378, -0.25368681, -0.25380782, -0.25354889, -0.25372168,\n",
       "        -0.25352376, -0.25355703, -0.25354822, -0.25380221, -0.25374779,\n",
       "        -0.25374029, -0.25358352, -0.25354519, -0.25425356, -0.25430772,\n",
       "        -0.25430559, -0.25376896, -0.25382177, -0.25463851, -0.25375699,\n",
       "        -0.25365076, -0.25371469, -0.25364423, -0.25364256, -0.25365789,\n",
       "        -0.25365246, -0.25368227, -0.25365682, -0.25322734, -0.25437351,\n",
       "        -0.25325552, -0.25444279, -0.25281373, -0.25356911, -0.25359706,\n",
       "        -0.25327796, -0.25361414, -0.25368304, -0.25363433, -0.25508552,\n",
       "        -0.25381106, -0.25301981, -0.25364189, -0.2524584 , -0.25334852,\n",
       "        -0.25334625, -0.25343392, -0.25346283, -0.25345916, -0.25386598,\n",
       "        -0.25272305, -0.25363579, -0.25355343, -0.25328303, -0.25405622,\n",
       "        -0.25390674, -0.25448181, -0.25392858, -0.25401243, -0.2544184 ,\n",
       "        -0.25362548, -0.25363572, -0.25281216, -0.25369702]),\n",
       " 'split2_test_neg_log_loss': array([-0.25364087, -0.2536408 , -0.25367916, -0.25353894, -0.25365405,\n",
       "        -0.25360873, -0.25367449, -0.25526215, -0.22707918, -0.2536409 ,\n",
       "        -0.25360098, -0.25364663, -0.25363803, -0.25365683, -0.25369442,\n",
       "        -0.25309411, -0.24933814, -0.22228133, -0.25367613, -0.25364285,\n",
       "        -0.25358033, -0.25364549, -0.25365323, -0.2539668 , -0.24985742,\n",
       "        -0.24737009, -0.22266697, -0.2534086 , -0.25364454, -0.25362264,\n",
       "        -0.25366194, -0.25444383, -0.25165756, -0.25341115, -0.24704921,\n",
       "        -0.22228785, -0.25388072, -0.25363988, -0.25371908, -0.25354209,\n",
       "        -0.25466292, -0.25036984, -0.25263214, -0.24700923, -0.21980135,\n",
       "        -0.25359128, -0.25369568, -0.25356906, -0.25365304, -0.2516147 ,\n",
       "        -0.25355621, -0.25285555, -0.24799698, -0.21955034, -0.25385336,\n",
       "        -0.25365057, -0.25359705, -0.25369887, -0.24957864, -0.25456809,\n",
       "        -0.25454821, -0.24971275, -0.21991141, -0.25528908, -0.25367359,\n",
       "        -0.25281442, -0.25374629, -0.25251641, -1.08650438, -0.25368698,\n",
       "        -0.24890709, -0.21971577, -0.25375404, -0.25352801, -0.25373813,\n",
       "        -0.2528688 , -0.32870642, -0.25348553, -0.25366072, -0.2490186 ,\n",
       "        -0.21968047, -0.25364087, -0.25364092, -0.25363455, -0.25364285,\n",
       "        -0.25361404, -0.25363374, -0.25364497, -0.25354038, -0.25453122,\n",
       "        -0.25364087, -0.2536503 , -0.25363348, -0.25364039, -0.25362808,\n",
       "        -0.25362971, -0.25367302, -0.25386183, -0.25437033, -0.25363489,\n",
       "        -0.25364285, -0.25367638, -0.25364653, -0.25362689, -0.25367088,\n",
       "        -0.25355541, -0.25391288, -0.2535739 , -0.25364285, -0.25368644,\n",
       "        -0.25370902, -0.25365951, -0.25507031, -0.25389032, -0.25383797,\n",
       "        -0.25365195, -0.25384677, -0.25362145, -0.25371032, -0.25362135,\n",
       "        -0.25363648, -0.25470291, -0.253091  , -0.253616  , -0.2536303 ,\n",
       "        -0.25328923, -0.25361469, -0.25347575, -0.25467335, -0.25379333,\n",
       "        -0.25365409, -0.25311561, -0.25436582, -0.25361268, -0.25361192,\n",
       "        -0.25363399, -0.25305599, -0.25365593, -0.25376863, -0.25404687,\n",
       "        -0.25472778, -0.25399954, -0.25441104, -0.25331003, -0.25401718,\n",
       "        -0.25335078, -0.25354572, -0.25291839, -0.25343412, -0.25308945,\n",
       "        -0.25393714, -0.25353215, -0.25349594, -0.2533627 , -0.2535851 ,\n",
       "        -0.25363955, -0.25369093, -0.2535873 , -0.25332476, -0.25347272,\n",
       "        -0.25627656, -0.25339249, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364093, -0.25364425, -0.25353272,\n",
       "        -0.25390353, -0.25364087, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364043, -0.25412323, -0.25236401, -0.25364014,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25362205, -0.25355728, -0.25375646, -0.25401818, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25364094, -0.25381799,\n",
       "        -0.25350777, -0.25337064, -0.25380488, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364183, -0.25365551, -0.25398553,\n",
       "        -0.25262012, -0.25363919, -0.25364087, -0.25364087, -0.25364087,\n",
       "        -0.25364087, -0.25371998, -0.2541205 , -0.25402771, -0.25480068,\n",
       "        -0.25367504, -0.25364087, -0.25364087, -0.25364087, -0.25364086,\n",
       "        -0.25360691, -0.25344808, -0.25365846, -0.25363867, -0.25364848,\n",
       "        -0.25364087, -0.25364087, -0.25364087, -0.25379727, -0.25361188,\n",
       "        -0.25330225, -0.25428937, -0.25364534, -0.25366904, -0.25364087,\n",
       "        -0.25364087, -0.25364087, -0.25364285, -0.25397641, -0.25323243,\n",
       "        -0.25493524, -0.25395992, -0.25369709, -0.25369725, -0.25367419,\n",
       "        -0.25375404, -0.25369133, -0.25362675, -0.2536657 , -0.25370448,\n",
       "        -0.25363277, -0.25365513, -0.25365124, -0.25364484, -0.25363971,\n",
       "        -0.25375399, -0.25373031, -0.25375569, -0.25363946, -0.25364675,\n",
       "        -0.25363972, -0.25402572, -0.2544856 , -0.25381232, -0.25372634,\n",
       "        -0.25365141, -0.25359472, -0.25346817, -0.25350005, -0.25343065,\n",
       "        -0.25340949, -0.2535568 , -0.25394749, -0.25346602, -0.25401344,\n",
       "        -0.25411483, -0.2534403 , -0.25306173, -0.25383214, -0.25483377,\n",
       "        -0.25455498, -0.25346516, -0.25266402, -0.25488798, -0.25617949,\n",
       "        -0.25326023, -0.25388962, -0.25423612, -0.2536952 , -0.25366991,\n",
       "        -0.25390997, -0.253655  , -0.25362322, -0.25367304, -0.25380107,\n",
       "        -0.25421746, -0.25363942, -0.25378819, -0.25363082, -0.25362226,\n",
       "        -0.25369606, -0.25392492, -0.25368711, -0.25363185, -0.25363376,\n",
       "        -0.25375198, -0.25365458, -0.25379999, -0.25362105, -0.25362354,\n",
       "        -0.25362219, -0.25369275, -0.25368797, -0.25370962, -0.2536259 ,\n",
       "        -0.25363166, -0.25370698, -0.25376792, -0.2536296 , -0.25363484,\n",
       "        -0.25363069, -0.25370214, -0.25364774, -0.25377737]),\n",
       " 'split3_test_neg_log_loss': array([-0.25622226, -0.25622227, -0.25622017, -0.25638657, -0.25640825,\n",
       "        -0.25618822, -0.25592225, -0.25557023, -0.21758613, -0.25622219,\n",
       "        -0.25622248, -0.25630567, -0.25620004, -0.25648884, -0.2562515 ,\n",
       "        -0.25942861, -0.24890697, -0.21874628, -0.25622017, -0.25735998,\n",
       "        -0.25631585, -0.25575872, -0.25723327, -0.25663745, -0.2543104 ,\n",
       "        -0.24395205, -0.21843523, -0.2562428 , -0.25549271, -0.25651352,\n",
       "        -0.25619897, -0.25632034, -0.25618126, -0.25606779, -0.24491551,\n",
       "        -0.21719621, -0.25640683, -0.25607468, -0.25647316, -0.25719607,\n",
       "        -0.26013095, -0.25556666, -0.25458899, -0.24686982, -0.21798173,\n",
       "        -0.25604693, -0.25639468, -0.25615556, -0.2562113 , -0.25722548,\n",
       "        -0.2594011 , -0.25593187, -0.24394368, -0.21888503, -0.25633956,\n",
       "        -0.25621866, -0.25778183, -0.25667274, -0.26246368, -0.25655301,\n",
       "        -0.25700416, -0.24682147, -0.21892807, -0.25728129, -0.25782925,\n",
       "        -0.25637731, -0.25677409, -0.25448643, -3.9507611 , -0.25567746,\n",
       "        -0.24463258, -0.21815306, -0.25644408, -0.25798256, -0.25618544,\n",
       "        -0.25745094, -0.32904094, -0.25666421, -0.25602031, -0.24453745,\n",
       "        -0.21831079, -0.25622226, -0.25622224, -0.25629719, -0.25616477,\n",
       "        -0.25615906, -0.25623781, -0.25623803, -0.25649847, -0.25629169,\n",
       "        -0.25622227, -0.2562159 , -0.25633566, -0.25610706, -0.25618338,\n",
       "        -0.25623865, -0.25660049, -0.2563594 , -0.25700614, -0.25631035,\n",
       "        -0.25622258, -0.25610371, -0.25613979, -0.25612688, -0.25661579,\n",
       "        -0.2566626 , -0.25624355, -0.25578076, -0.25635309, -0.25628149,\n",
       "        -0.25668401, -0.25614283, -0.25632214, -0.25595465, -0.25629033,\n",
       "        -0.25623853, -0.25781442, -0.25649795, -0.25638025, -0.25646261,\n",
       "        -0.25591274, -0.25632937, -0.25628984, -0.25629124, -0.25715987,\n",
       "        -0.25671545, -0.25656461, -0.25644817, -0.25633405, -0.25575376,\n",
       "        -0.25639544, -0.25622747, -0.25576131, -0.25622676, -0.25619994,\n",
       "        -0.2565169 , -0.25670392, -0.25646817, -0.25620977, -0.25621724,\n",
       "        -0.25754757, -0.25762037, -0.25656977, -0.25621826, -0.25613457,\n",
       "        -0.2559962 , -0.25552578, -0.25595892, -0.25716418, -0.25649703,\n",
       "        -0.25597533, -0.25627655, -0.25660125, -0.25624816, -0.25873234,\n",
       "        -0.25708325, -0.25608617, -0.25708333, -0.25599929, -0.25614147,\n",
       "        -0.25613959, -0.25621173, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25622221, -0.25607677, -0.25682317,\n",
       "        -0.25528641, -0.25622226, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25619918, -0.25608947, -0.25589127, -0.25573205,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25605163, -0.25694943, -0.2562067 , -0.25794261, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25622228, -0.2560473 ,\n",
       "        -0.2563037 , -0.25508452, -0.2562497 , -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25621585, -0.25630175, -0.25590859,\n",
       "        -0.25619478, -0.25646908, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25617293, -0.25610979, -0.25620263, -0.25628112,\n",
       "        -0.25654361, -0.25622226, -0.25622226, -0.25622226, -0.2562221 ,\n",
       "        -0.25642842, -0.25613995, -0.25592311, -0.25671453, -0.25637639,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25622017, -0.25630274,\n",
       "        -0.25587079, -0.25675786, -0.25629805, -0.25622326, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25614189, -0.25607541, -0.25594271,\n",
       "        -0.256223  , -0.25622083, -0.25626701, -0.25709671, -0.25612221,\n",
       "        -0.25700524, -0.25720238, -0.25618194, -0.25681389, -0.25621747,\n",
       "        -0.2562971 , -0.25697125, -0.25634353, -0.25628759, -0.25697918,\n",
       "        -0.25629237, -0.25629241, -0.25629845, -0.25625547, -0.25628118,\n",
       "        -0.25624894, -0.25608161, -0.25630523, -0.25659021, -0.25612895,\n",
       "        -0.25610397, -0.25606932, -0.25677457, -0.25630329, -0.25602057,\n",
       "        -0.25598986, -0.25598746, -0.25740981, -0.25615782, -0.25629922,\n",
       "        -0.25602977, -0.25628032, -0.25649831, -0.25627408, -0.25626532,\n",
       "        -0.25597945, -0.2559428 , -0.25639013, -0.2559559 , -0.25616286,\n",
       "        -0.25675294, -0.2560616 , -0.25607068, -0.25683082, -0.2554643 ,\n",
       "        -0.25650605, -0.25585347, -0.25567671, -0.25623023, -0.25654673,\n",
       "        -0.25574857, -0.2572559 , -0.2558739 , -0.25607993, -0.2557702 ,\n",
       "        -0.25639193, -0.25600557, -0.25600563, -0.25705285, -0.25696308,\n",
       "        -0.25617528, -0.25658678, -0.25587065, -0.25559034, -0.2556548 ,\n",
       "        -0.25747913, -0.25546611, -0.25705436, -0.25646431, -0.25528252,\n",
       "        -0.25785587, -0.25674531, -0.25639486, -0.25586787, -0.25650122,\n",
       "        -0.25549327, -0.25830716, -0.25657971, -0.25570251]),\n",
       " 'split4_test_neg_log_loss': array([-0.25622226, -0.25622224, -0.25637978, -0.25624271, -0.25634184,\n",
       "        -0.25618442, -0.25622536, -0.25534987, -0.2263792 , -0.25622123,\n",
       "        -0.25622017, -0.25619787, -0.25622085, -0.25626441, -0.25603576,\n",
       "        -0.25835385, -0.24877862, -0.22495013, -0.25622017, -0.2562651 ,\n",
       "        -0.25621272, -0.25626633, -0.25635542, -0.25717548, -0.25492958,\n",
       "        -0.24712444, -0.22529829, -0.25621931, -0.25623105, -0.25614582,\n",
       "        -0.25623792, -0.25623299, -0.2584382 , -0.25586559, -0.24655115,\n",
       "        -0.22541388, -0.25632374, -0.25621672, -0.25620182, -0.2560108 ,\n",
       "        -0.26069847, -0.25698412, -0.25519053, -0.24792064, -0.22271085,\n",
       "        -0.25629303, -0.25655707, -0.25624875, -0.2561036 , -0.25623608,\n",
       "        -0.25815051, -0.25548991, -0.2470765 , -0.22277281, -0.25622387,\n",
       "        -0.25562578, -0.25626721, -0.25857069, -0.26169735, -0.25630019,\n",
       "        -0.26109141, -0.24769737, -0.22280007, -0.25640698, -0.25677538,\n",
       "        -0.25630313, -0.25784535, -0.26015777, -2.24637842, -0.2562568 ,\n",
       "        -0.24787918, -0.22278534, -0.25669466, -0.25723748, -0.25702737,\n",
       "        -0.25619887, -0.34537841, -0.25594639, -0.25631947, -0.24881928,\n",
       "        -0.22282608, -0.25622226, -0.25622227, -0.25622146, -0.25623143,\n",
       "        -0.25628775, -0.25619479, -0.25621301, -0.25627648, -0.25621679,\n",
       "        -0.25622219, -0.2562355 , -0.25617122, -0.25620498, -0.25640023,\n",
       "        -0.2559182 , -0.25636245, -0.25635344, -0.25621497, -0.25621862,\n",
       "        -0.25623965, -0.25595886, -0.25622573, -0.25622374, -0.25432032,\n",
       "        -0.25635636, -0.25625614, -0.25604323, -0.25624756, -0.25624528,\n",
       "        -0.2559758 , -0.25621332, -0.25620839, -0.25639832, -0.25678281,\n",
       "        -0.25698859, -0.25628407, -0.25622953, -0.2562205 , -0.25628128,\n",
       "        -0.25601938, -0.25649362, -0.25828514, -0.25616466, -0.25706084,\n",
       "        -0.2565535 , -0.25626707, -0.25622904, -0.25620519, -0.25758444,\n",
       "        -0.25620549, -0.25614699, -0.2571738 , -0.25584676, -0.25630626,\n",
       "        -0.2562575 , -0.2570304 , -0.25721575, -0.25657461, -0.25591324,\n",
       "        -0.25738237, -0.25631357, -0.25627177, -0.25621094, -0.25596959,\n",
       "        -0.25656832, -0.25664287, -0.25615837, -0.25629337, -0.25621394,\n",
       "        -0.2561521 , -0.25714633, -0.256228  , -0.25660589, -0.25622982,\n",
       "        -0.25613649, -0.25629934, -0.2561803 , -0.25690576, -0.25592374,\n",
       "        -0.25617852, -0.25651882, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25629358, -0.25614824,\n",
       "        -0.25672492, -0.25622226, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25622017, -0.25686475, -0.255815  , -0.25620303,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.2564063 , -0.25622657, -0.25588744, -0.25631454, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25622227, -0.25693894,\n",
       "        -0.25610989, -0.25527974, -0.25622799, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25622214, -0.25648217, -0.25627535,\n",
       "        -0.25592145, -0.25644769, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25622226, -0.25622138, -0.2565366 , -0.25583599, -0.25957019,\n",
       "        -0.25636457, -0.25622226, -0.25622226, -0.25622226, -0.25622226,\n",
       "        -0.25635148, -0.25627179, -0.25662282, -0.2561524 , -0.25622621,\n",
       "        -0.25622226, -0.25622226, -0.25622226, -0.25622264, -0.25622579,\n",
       "        -0.25579887, -0.25655915, -0.25718274, -0.25621428, -0.25622226,\n",
       "        -0.25622226, -0.25622226, -0.25680237, -0.25623344, -0.25645912,\n",
       "        -0.25657591, -0.25626794, -0.25626505, -0.25570127, -0.25612507,\n",
       "        -0.25682475, -0.25604208, -0.257131  , -0.25672712, -0.25601434,\n",
       "        -0.25565615, -0.25668161, -0.25597457, -0.25627567, -0.25638051,\n",
       "        -0.25587134, -0.25593   , -0.25601283, -0.25598162, -0.25603383,\n",
       "        -0.25605452, -0.25622176, -0.25627228, -0.25621585, -0.25690039,\n",
       "        -0.25622767, -0.25642024, -0.25621702, -0.25631634, -0.25621624,\n",
       "        -0.25647273, -0.25589867, -0.25596101, -0.25611701, -0.25677683,\n",
       "        -0.25689238, -0.25594556, -0.25604275, -0.25648057, -0.25684505,\n",
       "        -0.25724941, -0.25694825, -0.25651849, -0.25671019, -0.25552091,\n",
       "        -0.25675816, -0.25620047, -0.25614619, -0.25631742, -0.25625638,\n",
       "        -0.25623577, -0.25642413, -0.2570451 , -0.25634387, -0.25645093,\n",
       "        -0.2561189 , -0.25633025, -0.25619892, -0.25591631, -0.25596616,\n",
       "        -0.25633269, -0.25613816, -0.25607802, -0.25597619, -0.25605645,\n",
       "        -0.2571421 , -0.25597169, -0.25670099, -0.25654768, -0.25714826,\n",
       "        -0.25636231, -0.25600952, -0.25586592, -0.25604003, -0.25626497,\n",
       "        -0.25651572, -0.25666364, -0.25711036, -0.25631301, -0.25620844,\n",
       "        -0.25683745, -0.25664487, -0.2561991 , -0.25584271]),\n",
       " 'mean_test_neg_log_loss': array([-0.25467343, -0.25467332, -0.25471845, -0.25468008, -0.2547329 ,\n",
       "        -0.25465365, -0.25458089, -0.25436424, -0.22618084, -0.25467317,\n",
       "        -0.25465774, -0.25466342, -0.25470456, -0.25474272, -0.25464284,\n",
       "        -0.25628709, -0.249299  , -0.22430174, -0.2547376 , -0.25491282,\n",
       "        -0.25470457, -0.25459116, -0.25491265, -0.2554972 , -0.25294345,\n",
       "        -0.24696119, -0.22436161, -0.25461887, -0.25451228, -0.25470164,\n",
       "        -0.25472154, -0.25484418, -0.25458055, -0.25400886, -0.24703428,\n",
       "        -0.2239298 , -0.25481406, -0.25466266, -0.25472454, -0.25478349,\n",
       "        -0.25750992, -0.25404759, -0.25419942, -0.2475906 , -0.22242436,\n",
       "        -0.25474086, -0.25480521, -0.25467117, -0.25458779, -0.25530295,\n",
       "        -0.25528665, -0.25433092, -0.2468316 , -0.22257682, -0.25460417,\n",
       "        -0.25466436, -0.25507642, -0.25517272, -0.25597685, -0.25513405,\n",
       "        -0.26234056, -0.24834967, -0.22271607, -0.25526482, -0.25528346,\n",
       "        -0.25454749, -0.25508193, -0.25450937, -1.98296722, -0.25452453,\n",
       "        -0.24795562, -0.22250241, -0.25539199, -0.25535698, -0.2548161 ,\n",
       "        -0.25497263, -0.34176152, -0.25467842, -0.25474131, -0.24824405,\n",
       "        -0.2225507 , -0.25467343, -0.25467375, -0.25472909, -0.25466495,\n",
       "        -0.25467366, -0.25465159, -0.25468375, -0.25468884, -0.25499024,\n",
       "        -0.25467342, -0.25467652, -0.2546635 , -0.25465103, -0.25470098,\n",
       "        -0.25463668, -0.25480721, -0.25470367, -0.25499765, -0.25469019,\n",
       "        -0.25467815, -0.25457882, -0.25466525, -0.25465972, -0.25444748,\n",
       "        -0.25481706, -0.2547558 , -0.2545226 , -0.25470584, -0.25469722,\n",
       "        -0.25469398, -0.25466909, -0.25537127, -0.254722  , -0.25508229,\n",
       "        -0.25503955, -0.25515325, -0.25472823, -0.25470784, -0.25471745,\n",
       "        -0.25452353, -0.25506682, -0.25500521, -0.25491636, -0.25504819,\n",
       "        -0.2548002 , -0.25475006, -0.25467494, -0.25491794, -0.25512698,\n",
       "        -0.25465237, -0.25449614, -0.25489118, -0.25464163, -0.25494372,\n",
       "        -0.25474256, -0.25482478, -0.25502887, -0.25479649, -0.25471835,\n",
       "        -0.25524174, -0.25538674, -0.25491511, -0.25508238, -0.25467157,\n",
       "        -0.25484183, -0.25465506, -0.25449233, -0.2548168 , -0.2548201 ,\n",
       "        -0.2546498 , -0.25494573, -0.25481728, -0.25477505, -0.25514872,\n",
       "        -0.25464311, -0.25463649, -0.25487341, -0.25472981, -0.25465088,\n",
       "        -0.25516121, -0.25513021, -0.25467343, -0.25467343, -0.25467343,\n",
       "        -0.25467343, -0.25467343, -0.2546735 , -0.25479686, -0.25475468,\n",
       "        -0.25484172, -0.25467343, -0.25467343, -0.25467343, -0.25467343,\n",
       "        -0.25467343, -0.25529126, -0.25554735, -0.25432274, -0.25455083,\n",
       "        -0.25467343, -0.25467343, -0.25467343, -0.25467343, -0.25467343,\n",
       "        -0.25467314, -0.25482916, -0.25454478, -0.25515547, -0.25467343,\n",
       "        -0.25467343, -0.25467343, -0.25467343, -0.25467348, -0.25540075,\n",
       "        -0.25459493, -0.25420608, -0.25469148, -0.25467343, -0.25467343,\n",
       "        -0.25467343, -0.25467343, -0.25502406, -0.25530004, -0.25479094,\n",
       "        -0.25441557, -0.25471624, -0.25467343, -0.25467343, -0.25467343,\n",
       "        -0.25467343, -0.25469673, -0.25496877, -0.25479207, -0.25593572,\n",
       "        -0.25489849, -0.25467343, -0.25467343, -0.25467343, -0.25467337,\n",
       "        -0.25472023, -0.25488284, -0.25479698, -0.2547904 , -0.25471274,\n",
       "        -0.25467343, -0.25467343, -0.25467343, -0.25527454, -0.25553281,\n",
       "        -0.25456129, -0.25493493, -0.25488206, -0.25469271, -0.25467343,\n",
       "        -0.25467343, -0.25467343, -0.25477456, -0.25472877, -0.25456827,\n",
       "        -0.25551544, -0.25476737, -0.25484676, -0.25478309, -0.25474589,\n",
       "        -0.25497819, -0.25487605, -0.2548767 , -0.25490471, -0.25466503,\n",
       "        -0.25457579, -0.25497622, -0.2546501 , -0.25467017, -0.25483494,\n",
       "        -0.25464104, -0.25465166, -0.25479586, -0.25463525, -0.25463094,\n",
       "        -0.25464861, -0.25471815, -0.25498829, -0.25477198, -0.25481218,\n",
       "        -0.25467307, -0.25466087, -0.25478604, -0.25484005, -0.25477912,\n",
       "        -0.25452943, -0.25449902, -0.25473844, -0.25472045, -0.25518226,\n",
       "        -0.25500681, -0.25444671, -0.25450029, -0.254936  , -0.25507693,\n",
       "        -0.25495771, -0.25472579, -0.25458171, -0.25498583, -0.25512649,\n",
       "        -0.25478789, -0.25467771, -0.25470301, -0.25476376, -0.25466737,\n",
       "        -0.25474352, -0.25483574, -0.25461941, -0.25471829, -0.25481013,\n",
       "        -0.25458547, -0.25489352, -0.25467104, -0.25457517, -0.2547962 ,\n",
       "        -0.25488637, -0.25459111, -0.25460935, -0.25454757, -0.25470738,\n",
       "        -0.25489169, -0.25467821, -0.25472319, -0.25463172, -0.25476545,\n",
       "        -0.25475805, -0.25446907, -0.25474705, -0.25460645, -0.25456477,\n",
       "        -0.25513417, -0.25505051, -0.25494575, -0.25467504, -0.25496854,\n",
       "        -0.25470008, -0.25516443, -0.25455355, -0.25463861]),\n",
       " 'std_test_neg_log_loss': array([1.26461899e-03, 1.26470218e-03, 1.29236012e-03, 1.33584410e-03,\n",
       "        1.34102211e-03, 1.25150279e-03, 1.22411131e-03, 1.55956134e-03,\n",
       "        4.85489540e-03, 1.26437348e-03, 1.27671803e-03, 1.29817821e-03,\n",
       "        1.23037970e-03, 1.33598403e-03, 1.22769817e-03, 2.45352347e-03,\n",
       "        7.36803539e-04, 3.84396363e-03, 1.21139844e-03, 1.58929483e-03,\n",
       "        1.27514625e-03, 1.17176840e-03, 1.56127757e-03, 1.24355792e-03,\n",
       "        1.83100806e-03, 1.58455230e-03, 3.87611809e-03, 1.31860260e-03,\n",
       "        1.12754803e-03, 1.33449295e-03, 1.22275583e-03, 1.20890584e-03,\n",
       "        2.64012193e-03, 1.66513198e-03, 1.32932684e-03, 4.23988082e-03,\n",
       "        1.26911529e-03, 1.21187290e-03, 1.32073592e-03, 1.53308926e-03,\n",
       "        2.44051711e-03, 2.27404284e-03, 9.85558411e-04, 6.30582501e-04,\n",
       "        3.87127126e-03, 1.18290899e-03, 1.36647130e-03, 1.25192809e-03,\n",
       "        1.28632474e-03, 1.93843743e-03, 2.90609021e-03, 1.17622429e-03,\n",
       "        1.47744068e-03, 3.75203358e-03, 1.42856227e-03, 1.05468114e-03,\n",
       "        1.66804987e-03, 2.08980988e-03, 5.15485161e-03, 1.09117165e-03,\n",
       "        6.53381114e-03, 1.05238945e-03, 3.65141433e-03, 1.44499330e-03,\n",
       "        1.68981789e-03, 1.49675105e-03, 1.85691552e-03, 3.17974462e-03,\n",
       "        1.13615597e+00, 1.20062669e-03, 1.80003252e-03, 3.91519140e-03,\n",
       "        1.45900193e-03, 1.86325510e-03, 1.49229994e-03, 1.65465330e-03,\n",
       "        5.22433826e-02, 1.35443715e-03, 1.17462226e-03, 1.97806820e-03,\n",
       "        3.90598338e-03, 1.26461666e-03, 1.26434581e-03, 1.25178394e-03,\n",
       "        1.25199016e-03, 1.26614475e-03, 1.27777855e-03, 1.25889880e-03,\n",
       "        1.40067653e-03, 1.10120305e-03, 1.26459951e-03, 1.26501817e-03,\n",
       "        1.29977899e-03, 1.22925847e-03, 1.30076968e-03, 1.18526951e-03,\n",
       "        1.37083636e-03, 1.36124269e-03, 1.40509647e-03, 1.28578260e-03,\n",
       "        1.26800053e-03, 1.18793501e-03, 1.23946114e-03, 1.23800012e-03,\n",
       "        1.10784044e-03, 1.38893581e-03, 1.22348851e-03, 1.13756477e-03,\n",
       "        1.30232130e-03, 1.27895087e-03, 1.35667996e-03, 1.23241910e-03,\n",
       "        9.74396848e-04, 1.19905971e-03, 1.29256582e-03, 1.32735159e-03,\n",
       "        1.62739014e-03, 1.33813490e-03, 1.30185498e-03, 1.35220498e-03,\n",
       "        1.18141587e-03, 1.14693783e-03, 1.97934947e-03, 1.11280549e-03,\n",
       "        1.68422431e-03, 1.50753463e-03, 1.36358819e-03, 1.36114252e-03,\n",
       "        1.16186817e-03, 1.46241730e-03, 1.35079777e-03, 1.40582370e-03,\n",
       "        1.39249295e-03, 1.14935539e-03, 1.10050868e-03, 1.34536722e-03,\n",
       "        1.68561385e-03, 1.51657865e-03, 1.30813162e-03, 1.11136428e-03,\n",
       "        1.90114658e-03, 1.36728654e-03, 1.26307469e-03, 1.07970287e-03,\n",
       "        1.14150536e-03, 1.23228047e-03, 1.22559227e-03, 1.31377697e-03,\n",
       "        1.58639078e-03, 1.31576750e-03, 1.16297431e-03, 1.47411426e-03,\n",
       "        1.34997078e-03, 1.36781413e-03, 2.06241765e-03, 1.65781566e-03,\n",
       "        1.28046338e-03, 1.51814594e-03, 1.44291697e-03, 1.15309659e-03,\n",
       "        1.27105544e-03, 1.13127668e-03, 1.26461816e-03, 1.26461816e-03,\n",
       "        1.26461816e-03, 1.26461813e-03, 1.26461813e-03, 1.26454017e-03,\n",
       "        1.16315233e-03, 1.44015938e-03, 1.14316072e-03, 1.26461816e-03,\n",
       "        1.26461816e-03, 1.26461816e-03, 1.26461814e-03, 1.26461814e-03,\n",
       "        1.20265288e-03, 9.14407235e-04, 1.35137937e-03, 1.18595471e-03,\n",
       "        1.26461816e-03, 1.26461816e-03, 1.26461816e-03, 1.26461814e-03,\n",
       "        1.26461822e-03, 1.27529652e-03, 1.45590837e-03, 1.30094340e-03,\n",
       "        1.69441859e-03, 1.26461816e-03, 1.26461816e-03, 1.26461815e-03,\n",
       "        1.26461813e-03, 1.26458558e-03, 1.41040433e-03, 1.32097474e-03,\n",
       "        8.06923544e-04, 1.27410181e-03, 1.26461816e-03, 1.26461816e-03,\n",
       "        1.26461813e-03, 1.26461811e-03, 1.16345275e-03, 1.18942131e-03,\n",
       "        1.08385221e-03, 1.40357128e-03, 1.42652107e-03, 1.26461816e-03,\n",
       "        1.26461816e-03, 1.26461814e-03, 1.26461732e-03, 1.22553924e-03,\n",
       "        1.16806910e-03, 1.09430572e-03, 1.93228414e-03, 1.32804077e-03,\n",
       "        1.26461816e-03, 1.26461813e-03, 1.26461813e-03, 1.26459338e-03,\n",
       "        1.36354832e-03, 1.13244798e-03, 1.23718129e-03, 1.37219413e-03,\n",
       "        1.29934527e-03, 1.26461816e-03, 1.26461814e-03, 1.26461815e-03,\n",
       "        1.15534348e-03, 1.41359607e-03, 1.09248169e-03, 1.43545583e-03,\n",
       "        1.54328266e-03, 1.26040507e-03, 1.26461816e-03, 1.26461814e-03,\n",
       "        1.26461781e-03, 1.40170945e-03, 1.18402072e-03, 1.36346759e-03,\n",
       "        1.17250124e-03, 1.22039600e-03, 1.23180491e-03, 1.39140440e-03,\n",
       "        1.12807079e-03, 1.58286131e-03, 1.47267946e-03, 1.48484202e-03,\n",
       "        1.52370979e-03, 1.18690020e-03, 1.16161559e-03, 1.51576678e-03,\n",
       "        1.23894544e-03, 1.31604096e-03, 1.51850965e-03, 1.18801296e-03,\n",
       "        1.19961057e-03, 1.12435050e-03, 1.21450067e-03, 1.24993460e-03,\n",
       "        1.22950402e-03, 1.18068851e-03, 1.08365412e-03, 1.33959833e-03,\n",
       "        1.41225503e-03, 1.22412665e-03, 1.29845650e-03, 1.41542161e-03,\n",
       "        1.22545345e-03, 1.14697844e-03, 1.41564454e-03, 1.18000640e-03,\n",
       "        1.69277845e-03, 1.18708465e-03, 1.12850607e-03, 1.23444102e-03,\n",
       "        1.39984316e-03, 1.47832407e-03, 1.23914650e-03, 1.28697728e-03,\n",
       "        1.46548947e-03, 1.44191134e-03, 1.57290093e-03, 1.20824169e-03,\n",
       "        1.05126721e-03, 1.61151739e-03, 1.19225430e-03, 1.17898457e-03,\n",
       "        1.49804871e-03, 1.04302228e-03, 1.35005200e-03, 1.11114781e-03,\n",
       "        1.53092526e-03, 1.28305001e-03, 1.38075583e-03, 1.14818264e-03,\n",
       "        1.57837976e-03, 1.12038448e-03, 1.16300433e-03, 1.03588542e-03,\n",
       "        1.21676879e-03, 1.25148530e-03, 1.16997518e-03, 1.69609022e-03,\n",
       "        1.50210948e-03, 1.49129584e-03, 1.32547347e-03, 1.30812015e-03,\n",
       "        1.22181631e-03, 1.42102142e-03, 1.82986622e-03, 1.05119837e-03,\n",
       "        1.44906150e-03, 1.35719973e-03, 1.04765449e-03, 1.73011773e-03,\n",
       "        1.38209294e-03, 1.49801208e-03, 1.17458988e-03, 1.16256124e-03,\n",
       "        1.27393677e-03, 1.95998815e-03, 1.53073082e-03, 9.40898738e-04]),\n",
       " 'rank_test_neg_log_loss': array([143, 103, 180, 155, 192,  82,  52,  25,   9, 102,  84,  88, 169,\n",
       "        198,  72, 320,  17,   7, 193, 257, 170,  57, 256, 314,  18,  11,\n",
       "          8,  62,  35, 166, 183, 243,  51,  19,  12,   6, 230,  87, 186,\n",
       "        214, 321,  20,  21,  13,   1, 195, 226,  98,  55, 308, 305,  24,\n",
       "         10,   4,  59,  90, 284, 299, 319, 292, 322,  16,   5, 302, 304,\n",
       "         41, 286,  34, 324,  38,  14,   2, 312, 309, 231, 269, 323, 154,\n",
       "        196,  15,   3, 106, 147, 190,  91, 146,  79, 156, 157, 274, 105,\n",
       "        150,  89,  78, 165,  68, 227, 168, 275, 158, 152,  50,  93,  85,\n",
       "         28, 233, 204,  36, 171, 163, 161,  95, 310, 184, 287, 280, 295,\n",
       "        188, 173, 176,  37, 283, 276, 259, 281, 225, 202, 148, 260, 290,\n",
       "         81,  31, 251,  71, 263, 197, 236, 279, 222, 179, 301, 311, 258,\n",
       "        288,  99, 242,  83,  30, 232, 235,  75, 264, 234, 211, 294,  73,\n",
       "         67, 245, 191,  77, 297, 291, 111, 111, 111, 128, 135, 145, 223,\n",
       "        203, 241, 111, 111, 111, 138, 132, 306, 317,  23,  43, 111, 111,\n",
       "        126, 136, 107, 101, 237,  40, 296, 111, 111, 141, 130, 144, 313,\n",
       "         58,  22, 159, 111, 111, 131, 110, 278, 307, 218,  26, 175, 111,\n",
       "        140, 133, 108, 162, 268, 219, 318, 254, 111, 139, 137, 104, 181,\n",
       "        249, 224, 217, 174, 111, 134, 142, 303, 316,  45, 261, 248, 160,\n",
       "        127, 129, 109, 210, 189,  47, 315, 208, 244, 213, 200, 271, 246,\n",
       "        247, 255,  92,  49, 270,  76,  96, 238,  70,  80, 220,  66,  64,\n",
       "         74, 177, 273, 209, 229, 100,  86, 215, 240, 212,  39,  32, 194,\n",
       "        182, 300, 277,  27,  33, 262, 285, 266, 187,  53, 272, 289, 216,\n",
       "        151, 167, 206,  94, 199, 239,  63, 178, 228,  54, 253,  97,  48,\n",
       "        221, 250,  56,  61,  42, 172, 252, 153, 185,  65, 207, 205,  29,\n",
       "        201,  60,  46, 293, 282, 265, 149, 267, 164, 298,  44,  69])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIAL_4_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FOUR NEG LOG LOSS RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL FOUR NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_4_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FOUR F1 RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL FOUR F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_4_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FOUR ROC AUC RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL FOUR ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_4_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 4 svm using best NEG LOG LOSS hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 4 svm using best F1 hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 4 svm using best ROC_AUC hyperparameters :0.9319\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 4 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 4 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 4 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL FIVE ON POKER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FIVE RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = pokerData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_5_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL FIVE RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.42376451, 0.45348978, 0.44938645, 0.43557324, 0.42316375,\n",
       "        0.43747578, 0.43587484, 0.46049652, 0.50803704, 0.47540917,\n",
       "        0.47420797, 0.49932971, 0.49092226, 0.49472532, 0.49252353,\n",
       "        0.49882884, 0.81620212, 2.17286859, 0.46209726, 0.47340708,\n",
       "        0.5004312 , 0.51494279, 0.55737877, 0.52715335, 0.62483754,\n",
       "        1.64421368, 3.49940915, 0.53245788, 0.57669616, 0.50633545,\n",
       "        0.53315849, 0.51914663, 0.71171241, 1.77142296, 2.07168121,\n",
       "        3.88003674, 0.53786254, 0.55988121, 0.55677862, 0.51183996,\n",
       "        0.54016476, 0.99415526, 2.5757153 , 2.29127007, 4.22153034,\n",
       "        0.60792289, 0.62033343, 0.58039927, 0.66156902, 1.67714272,\n",
       "        2.14734721, 2.61284695, 2.84344535, 3.93288198, 0.65136023,\n",
       "        0.66497149, 1.08253093, 2.31529136, 2.24533091, 2.61915245,\n",
       "        3.12698927, 2.60684195, 3.88824363, 0.79438314, 0.86784582,\n",
       "        1.39179707, 2.11561942, 2.42118235, 3.06213312, 3.12929096,\n",
       "        2.38825407, 3.68536921, 0.71981902, 0.94751468, 1.46686134,\n",
       "        2.29577413, 3.21936865, 3.43595481, 3.16692367, 2.43499422,\n",
       "        3.64233289, 0.50273237, 0.47290683, 0.4866188 , 0.5057354 ,\n",
       "        0.53976374, 0.5074367 , 0.48611836, 0.68248696, 1.19772983,\n",
       "        0.48811994, 0.47170563, 0.47400775, 0.46850314, 0.48241496,\n",
       "        0.47741008, 0.51524329, 0.77266436, 1.2504755 , 0.48051324,\n",
       "        0.50023022, 0.54616947, 0.50573492, 0.48922038, 0.49332442,\n",
       "        0.4846169 , 0.78467431, 1.22425284, 0.47620964, 0.46940389,\n",
       "        0.4786118 , 0.48992119, 0.49632697, 0.48611803, 1.90693989,\n",
       "        0.77306495, 1.1665029 , 0.5148428 , 0.49772806, 0.48121347,\n",
       "        0.49762788, 0.49772806, 0.48711901, 1.97053776, 0.72992806,\n",
       "        1.27359519, 0.56028237, 0.62143426, 0.49962974, 0.5364614 ,\n",
       "        0.51284094, 0.52985549, 2.13043199, 0.69790044, 1.27840004,\n",
       "        0.5151432 , 0.51194015, 0.52825379, 0.49492583, 0.50013032,\n",
       "        2.12152452, 2.48533754, 0.69289613, 1.28910856, 0.54947238,\n",
       "        0.54807148, 0.56398535, 0.57339334, 0.6702764 , 2.7297471 ,\n",
       "        2.32459908, 0.70550671, 1.22985826, 0.49012175, 0.48471689,\n",
       "        0.50563488, 0.61703076, 1.59126844, 2.87757468, 2.15505333,\n",
       "        0.72182069, 1.17481008, 0.37171969, 0.32217708, 0.31857395,\n",
       "        0.31046691, 0.30746465, 0.30796456, 0.32898273, 0.37522259,\n",
       "        0.80809512, 0.32998376, 0.37151952, 0.3274817 , 0.34009218,\n",
       "        0.35830817, 0.35710716, 0.32978382, 0.49382439, 1.18982334,\n",
       "        0.41145353, 0.34329519, 0.33608932, 0.37091918, 0.35350399,\n",
       "        0.35750747, 0.33018408, 0.62663903, 2.41537704, 0.32658062,\n",
       "        0.33168483, 0.32798238, 0.34469652, 0.31417012, 0.30956612,\n",
       "        0.3393918 , 0.74914455, 2.28366437, 0.32227721, 0.31567149,\n",
       "        0.30706444, 0.3140696 , 0.32688141, 0.32828259, 0.45048738,\n",
       "        1.06301403, 2.20739827, 0.31457052, 0.29775605, 0.30536265,\n",
       "        0.30596318, 0.3033607 , 0.30416174, 0.56608644, 2.36803637,\n",
       "        2.36913753, 0.324579  , 0.33819089, 0.32958322, 0.31607213,\n",
       "        0.33248634, 0.38082733, 0.7234221 , 2.22771549, 2.18017535,\n",
       "        0.30536256, 0.30095925, 0.30055861, 0.30246005, 0.30165958,\n",
       "        0.43417301, 1.05080376, 2.27255454, 2.29157057, 0.30616331,\n",
       "        0.29805613, 0.30055819, 0.31026688, 0.30606341, 0.57179189,\n",
       "        2.34091325, 2.30107884, 2.28076143, 0.25441852, 0.2387053 ,\n",
       "        0.23790522, 0.23880563, 0.25692167, 0.25181689, 0.25411816,\n",
       "        0.25401788, 0.25672116, 0.26122503, 0.26492825, 0.2593226 ,\n",
       "        0.26692944, 0.25842266, 0.25972333, 0.24681163, 0.24060693,\n",
       "        0.24481106, 0.24480314, 0.24160781, 0.24200802, 0.25201669,\n",
       "        0.23780484, 0.24691267, 0.2488142 , 0.24731259, 0.24270887,\n",
       "        0.3057632 , 0.3277822 , 0.33729067, 0.3212759 , 0.32117629,\n",
       "        0.30896516, 0.32688127, 0.3227778 , 0.31497068, 1.00776653,\n",
       "        1.00406332, 0.99925971, 0.99355435, 0.9520184 , 0.96633072,\n",
       "        0.96583071, 0.96462932, 0.94311075, 1.95317993, 1.96959348,\n",
       "        1.97269683, 1.98440666, 1.98150382, 1.98180423, 2.01713467,\n",
       "        2.08409181, 2.06227326, 2.03334866, 2.03014593, 1.99951997,\n",
       "        2.08469272, 2.01773515, 2.11411791, 2.07278228, 2.06617708,\n",
       "        1.97409782, 2.0066258 , 1.99001136, 1.96749201, 2.04065475,\n",
       "        1.93136086, 1.97303457, 2.08379188, 2.08819585, 2.03284817,\n",
       "        2.08379211, 2.05036325, 2.02113867, 2.10450964, 2.15405211,\n",
       "        2.07368321, 1.99791832, 1.92375469, 1.6634306 ]),\n",
       " 'std_fit_time': array([0.00681304, 0.03258794, 0.01513256, 0.01314966, 0.01129082,\n",
       "        0.00320343, 0.00941556, 0.01216958, 0.00912056, 0.0366047 ,\n",
       "        0.03568108, 0.05088479, 0.03007415, 0.02640904, 0.03538758,\n",
       "        0.01593664, 0.04914246, 0.09280564, 0.0043466 , 0.01276678,\n",
       "        0.03242957, 0.03810762, 0.06993549, 0.03199878, 0.00712415,\n",
       "        0.08686955, 0.27891335, 0.04965416, 0.06802686, 0.00868723,\n",
       "        0.03386262, 0.0442403 , 0.05101971, 0.11081349, 0.11004951,\n",
       "        0.16740745, 0.05026386, 0.07462589, 0.05955484, 0.02739923,\n",
       "        0.02856154, 0.0517135 , 0.25687955, 0.20207548, 0.32404367,\n",
       "        0.06246387, 0.02999335, 0.08248083, 0.04148771, 0.21804438,\n",
       "        0.17375313, 0.24150659, 0.11707954, 0.13129415, 0.03284942,\n",
       "        0.06582726, 0.11656848, 0.29337401, 0.08689029, 0.23783618,\n",
       "        0.10127049, 0.20092714, 0.09630524, 0.02463519, 0.04769668,\n",
       "        0.04997434, 0.05514567, 0.09627013, 0.07419334, 0.04052588,\n",
       "        0.06544734, 0.09573308, 0.02509128, 0.02403007, 0.06335838,\n",
       "        0.0684715 , 0.11563035, 0.04947635, 0.11913337, 0.06534901,\n",
       "        0.05832523, 0.01415644, 0.01325153, 0.01468738, 0.02859988,\n",
       "        0.03225579, 0.02331147, 0.01597805, 0.0222214 , 0.04307368,\n",
       "        0.00840715, 0.00627107, 0.0171333 , 0.01239764, 0.01155545,\n",
       "        0.01172738, 0.02592128, 0.02997069, 0.08431167, 0.0063725 ,\n",
       "        0.01920928, 0.0457433 , 0.03065395, 0.0151966 , 0.02138282,\n",
       "        0.01179853, 0.02399768, 0.03673394, 0.01107121, 0.01210556,\n",
       "        0.01620836, 0.01473991, 0.02065592, 0.01899683, 0.03715133,\n",
       "        0.02256347, 0.0633567 , 0.02363916, 0.03660283, 0.01245477,\n",
       "        0.01269383, 0.01891773, 0.02604996, 0.10877555, 0.09941213,\n",
       "        0.09374871, 0.07013251, 0.07920322, 0.02095279, 0.05058182,\n",
       "        0.04632515, 0.03682477, 0.15417829, 0.02777047, 0.14280614,\n",
       "        0.0446754 , 0.0202066 , 0.04321636, 0.01602311, 0.02364802,\n",
       "        0.0686151 , 0.05392615, 0.02186982, 0.06968533, 0.02822886,\n",
       "        0.0286121 , 0.03741129, 0.07303901, 0.06283174, 0.0692912 ,\n",
       "        0.10690136, 0.04934996, 0.03927327, 0.02597942, 0.01840495,\n",
       "        0.03110667, 0.04915871, 0.09517584, 0.07121718, 0.05646891,\n",
       "        0.0755008 , 0.02534118, 0.04096637, 0.01717123, 0.02292557,\n",
       "        0.01036074, 0.00582424, 0.00972748, 0.01772574, 0.04403713,\n",
       "        0.05869648, 0.01177698, 0.04720887, 0.02492624, 0.02105986,\n",
       "        0.0443914 , 0.02527351, 0.04281896, 0.03498238, 0.10162872,\n",
       "        0.02518776, 0.02341013, 0.01960418, 0.04550853, 0.04059902,\n",
       "        0.01960399, 0.02215147, 0.04420874, 0.03637506, 0.02802702,\n",
       "        0.02064607, 0.00989068, 0.02408598, 0.01223885, 0.02024539,\n",
       "        0.01286964, 0.03160242, 0.02222373, 0.01127474, 0.01539287,\n",
       "        0.00693876, 0.02026511, 0.01002058, 0.02372692, 0.03613961,\n",
       "        0.03416912, 0.02357257, 0.02166263, 0.00798207, 0.01223101,\n",
       "        0.01355234, 0.00559413, 0.00710824, 0.0341312 , 0.08647038,\n",
       "        0.05004225, 0.00858994, 0.01369163, 0.01396388, 0.01865088,\n",
       "        0.01965007, 0.03808402, 0.01410663, 0.03231782, 0.03428439,\n",
       "        0.00637264, 0.0117211 , 0.00521578, 0.00692406, 0.01032064,\n",
       "        0.0147625 , 0.03915431, 0.02718122, 0.06732093, 0.00975208,\n",
       "        0.00397296, 0.00627917, 0.01815936, 0.02039521, 0.02527755,\n",
       "        0.00329533, 0.09166565, 0.06986302, 0.01365943, 0.00929784,\n",
       "        0.00556008, 0.00664207, 0.01129526, 0.01763145, 0.01175904,\n",
       "        0.01367081, 0.00963602, 0.02084348, 0.01614901, 0.01145298,\n",
       "        0.0235776 , 0.01171707, 0.00608801, 0.00952443, 0.00617293,\n",
       "        0.00139415, 0.00263004, 0.00451396, 0.00762619, 0.00738597,\n",
       "        0.00340005, 0.00153776, 0.00802191, 0.00342971, 0.00515236,\n",
       "        0.01272346, 0.01357289, 0.02100151, 0.0137707 , 0.01335105,\n",
       "        0.01668328, 0.01468371, 0.01904018, 0.01645323, 0.02675194,\n",
       "        0.02977908, 0.03223208, 0.0392455 , 0.01946556, 0.02673065,\n",
       "        0.04387171, 0.01203777, 0.01259111, 0.02222501, 0.02109764,\n",
       "        0.01831908, 0.01973171, 0.02096702, 0.02374669, 0.0376641 ,\n",
       "        0.02144676, 0.04861043, 0.05441906, 0.04925357, 0.03321997,\n",
       "        0.08659134, 0.08094527, 0.0915153 , 0.10850389, 0.08214239,\n",
       "        0.05261836, 0.08161116, 0.0816674 , 0.07254806, 0.05895508,\n",
       "        0.08212964, 0.09434296, 0.09396919, 0.11910246, 0.03969947,\n",
       "        0.07644781, 0.1135901 , 0.10178886, 0.09791108, 0.04985519,\n",
       "        0.07839276, 0.10235323, 0.0800517 , 0.14894374]),\n",
       " 'mean_score_time': array([0.04293733, 0.04684024, 0.04113503, 0.04063497, 0.03873324,\n",
       "        0.04123554, 0.04053493, 0.04994278, 0.04884195, 0.04884181,\n",
       "        0.04203625, 0.04303703, 0.04263687, 0.05124388, 0.04543929,\n",
       "        0.04744067, 0.0662569 , 0.14542494, 0.04513927, 0.0494431 ,\n",
       "        0.04904103, 0.05444689, 0.04754109, 0.04974275, 0.04794106,\n",
       "        0.07706647, 0.21738706, 0.04934249, 0.05735044, 0.05744915,\n",
       "        0.0555479 , 0.05624871, 0.05834994, 0.07576528, 0.08717523,\n",
       "        0.26983199, 0.04613948, 0.05084367, 0.04644036, 0.04173574,\n",
       "        0.059551  , 0.08787551, 0.11690059, 0.10709209, 0.23270025,\n",
       "        0.06895933, 0.06075225, 0.04944248, 0.07626567, 0.11840138,\n",
       "        0.10539031, 0.11489897, 0.0964828 , 0.21088142, 0.0518445 ,\n",
       "        0.06026592, 0.05394645, 0.07596493, 0.09117808, 0.1274096 ,\n",
       "        0.19116421, 0.11980314, 0.21378393, 0.04203572, 0.040835  ,\n",
       "        0.05825009, 0.07136188, 0.11049457, 0.18135624, 0.16604309,\n",
       "        0.09768386, 0.2063777 , 0.04103503, 0.05174484, 0.05294552,\n",
       "        0.08136988, 0.17495046, 0.18175645, 0.1749506 , 0.09848461,\n",
       "        0.20417509, 0.04383779, 0.04373751, 0.04694018, 0.04944224,\n",
       "        0.04423809, 0.04814157, 0.04403777, 0.04383779, 0.06825886,\n",
       "        0.04483843, 0.04173579, 0.04343724, 0.04333749, 0.04714046,\n",
       "        0.04684043, 0.0436378 , 0.04483876, 0.06595731, 0.04613976,\n",
       "        0.04914217, 0.04503903, 0.042837  , 0.04393778, 0.04834156,\n",
       "        0.04323702, 0.04293685, 0.06735811, 0.0455389 , 0.04193592,\n",
       "        0.04694033, 0.04543967, 0.04513898, 0.04533911, 0.05835013,\n",
       "        0.04624   , 0.06595674, 0.04734073, 0.04413776, 0.04543943,\n",
       "        0.04303694, 0.04573903, 0.04463825, 0.05410366, 0.04433804,\n",
       "        0.07236233, 0.04403734, 0.04974294, 0.04543915, 0.04623966,\n",
       "        0.04353757, 0.04593959, 0.04984264, 0.04323707, 0.07606521,\n",
       "        0.05064425, 0.05054369, 0.0511445 , 0.04764071, 0.04473834,\n",
       "        0.06245351, 0.05674868, 0.04173584, 0.07116146, 0.06055217,\n",
       "        0.0469408 , 0.05584769, 0.04954271, 0.06255393, 0.09868488,\n",
       "        0.05254517, 0.04123526, 0.07005987, 0.04383788, 0.04293675,\n",
       "        0.04874201, 0.0569488 , 0.09167895, 0.09388099, 0.05084367,\n",
       "        0.04183602, 0.06385503, 0.02812414, 0.02792416, 0.02682309,\n",
       "        0.02632289, 0.02712317, 0.02822485, 0.03583112, 0.03262806,\n",
       "        0.03953376, 0.02922497, 0.02752376, 0.02802415, 0.0279242 ,\n",
       "        0.02872462, 0.026723  , 0.02792416, 0.03543067, 0.04553914,\n",
       "        0.03332834, 0.02672291, 0.02722306, 0.03312831, 0.02692332,\n",
       "        0.02772408, 0.02672305, 0.03793225, 0.04794149, 0.02782397,\n",
       "        0.02922511, 0.02692304, 0.02602253, 0.02752361, 0.02722359,\n",
       "        0.0280241 , 0.0454391 , 0.04433808, 0.02722325, 0.02562199,\n",
       "        0.02552166, 0.02632308, 0.02742324, 0.02792377, 0.03422914,\n",
       "        0.04493866, 0.04904237, 0.02662277, 0.02902498, 0.02652278,\n",
       "        0.02622247, 0.02612252, 0.02592225, 0.04113574, 0.04724073,\n",
       "        0.0443378 , 0.03623128, 0.0297256 , 0.02622252, 0.02792377,\n",
       "        0.0301259 , 0.03292861, 0.03743205, 0.0436378 , 0.04313655,\n",
       "        0.02592258, 0.02782354, 0.0263226 , 0.02572241, 0.02622232,\n",
       "        0.03272843, 0.04493852, 0.04413795, 0.0420361 , 0.0283246 ,\n",
       "        0.02662287, 0.02642283, 0.02542214, 0.02692289, 0.03703189,\n",
       "        0.04443841, 0.04714041, 0.04533887, 0.0314271 , 0.02071791,\n",
       "        0.02251902, 0.02422099, 0.02472119, 0.02171831, 0.02161846,\n",
       "        0.02311983, 0.02221899, 0.02261944, 0.02251925, 0.0221189 ,\n",
       "        0.02352018, 0.02251935, 0.02191868, 0.02191887, 0.02191887,\n",
       "        0.02191863, 0.0236208 , 0.02231917, 0.02191892, 0.022119  ,\n",
       "        0.0216186 , 0.02362018, 0.02151852, 0.0228199 , 0.02171884,\n",
       "        0.02762361, 0.03362875, 0.02872453, 0.03082671, 0.02712331,\n",
       "        0.02672286, 0.02922516, 0.02672305, 0.02662287, 0.04473934,\n",
       "        0.0411355 , 0.03873277, 0.03693171, 0.03673186, 0.03713212,\n",
       "        0.03793259, 0.03693194, 0.03803277, 0.03673172, 0.03563104,\n",
       "        0.03663139, 0.03893375, 0.03753252, 0.03803277, 0.03873343,\n",
       "        0.03703198, 0.03843307, 0.03923378, 0.03963418, 0.03973398,\n",
       "        0.03823333, 0.04483857, 0.03883338, 0.03893375, 0.04283652,\n",
       "        0.03843341, 0.03703189, 0.03753266, 0.04073505, 0.04303722,\n",
       "        0.04455342, 0.03939605, 0.04654045, 0.04133568, 0.04343753,\n",
       "        0.04603944, 0.04744096, 0.03903322, 0.04103556, 0.04373755,\n",
       "        0.04233637, 0.04363785, 0.02502131, 0.02041759]),\n",
       " 'std_score_time': array([0.00507768, 0.00799827, 0.00282011, 0.00309148, 0.00087258,\n",
       "        0.00291145, 0.00134266, 0.00565643, 0.00329819, 0.00563128,\n",
       "        0.00259027, 0.00563513, 0.00394564, 0.01003165, 0.00826215,\n",
       "        0.00599173, 0.01126861, 0.00657516, 0.0040951 , 0.01167324,\n",
       "        0.00510398, 0.022079  , 0.00823499, 0.00901111, 0.00737124,\n",
       "        0.00660879, 0.02400291, 0.00708149, 0.00913276, 0.01354472,\n",
       "        0.0121429 , 0.01335909, 0.00769197, 0.00696034, 0.01702484,\n",
       "        0.06052158, 0.00353028, 0.00939782, 0.00538436, 0.00103046,\n",
       "        0.00288322, 0.0085664 , 0.01508105, 0.01940516, 0.03180474,\n",
       "        0.01557127, 0.0043115 , 0.0056389 , 0.0182213 , 0.03735227,\n",
       "        0.01069357, 0.01999853, 0.00687136, 0.01255925, 0.00951927,\n",
       "        0.01389278, 0.00479382, 0.01160511, 0.007592  , 0.01324232,\n",
       "        0.0272024 , 0.01361512, 0.00949156, 0.00197708, 0.00120927,\n",
       "        0.01416654, 0.00493978, 0.01976142, 0.01019504, 0.00344385,\n",
       "        0.0098491 , 0.01007599, 0.00216992, 0.01332912, 0.01182341,\n",
       "        0.01522714, 0.01137043, 0.00611595, 0.01037518, 0.00634858,\n",
       "        0.00636135, 0.00147099, 0.00172179, 0.00705882, 0.00708705,\n",
       "        0.00264039, 0.00773628, 0.00262853, 0.00225142, 0.00282398,\n",
       "        0.00225147, 0.00128951, 0.00267449, 0.00150465, 0.00685735,\n",
       "        0.00264044, 0.00156347, 0.00258304, 0.00272964, 0.00407062,\n",
       "        0.00600001, 0.00602191, 0.00172165, 0.00231287, 0.00709542,\n",
       "        0.00218409, 0.0019867 , 0.0047745 , 0.0033645 , 0.00086087,\n",
       "        0.00548556, 0.00376423, 0.00182934, 0.0048581 , 0.00967059,\n",
       "        0.00410947, 0.00400812, 0.00665852, 0.00255944, 0.00208503,\n",
       "        0.00164449, 0.00403509, 0.00294222, 0.00769261, 0.00194055,\n",
       "        0.01166171, 0.00148434, 0.00785916, 0.00292496, 0.00427689,\n",
       "        0.00179066, 0.0014642 , 0.0044829 , 0.00666584, 0.01235151,\n",
       "        0.00487657, 0.00533393, 0.00671695, 0.00553149, 0.00116736,\n",
       "        0.00357232, 0.01304448, 0.00160124, 0.01100676, 0.00808798,\n",
       "        0.00502849, 0.0107214 , 0.00429331, 0.0066913 , 0.00838806,\n",
       "        0.00674366, 0.00132783, 0.00513312, 0.00103029, 0.00165653,\n",
       "        0.00663594, 0.00203645, 0.01366596, 0.02005364, 0.00676313,\n",
       "        0.00254378, 0.00211388, 0.00213251, 0.00146417, 0.00238124,\n",
       "        0.00060035, 0.00080073, 0.0032982 , 0.01270996, 0.004794  ,\n",
       "        0.00114124, 0.00522587, 0.00230397, 0.00286635, 0.00289042,\n",
       "        0.00380609, 0.00060047, 0.00198654, 0.00300954, 0.00262906,\n",
       "        0.01013098, 0.00163255, 0.001632  , 0.00450268, 0.00282048,\n",
       "        0.00153777, 0.00147092, 0.00317138, 0.00715776, 0.00287648,\n",
       "        0.00372601, 0.00135772, 0.00070776, 0.00260958, 0.00191468,\n",
       "        0.0006332 , 0.0077617 , 0.00248429, 0.00128973, 0.00073567,\n",
       "        0.00044809, 0.00103031, 0.00135775, 0.00198676, 0.00441497,\n",
       "        0.00198666, 0.00777219, 0.00135757, 0.00492368, 0.0009497 ,\n",
       "        0.0010308 , 0.00102063, 0.00037441, 0.00386873, 0.00341756,\n",
       "        0.00125011, 0.01144901, 0.00132769, 0.00074892, 0.00257877,\n",
       "        0.0048764 , 0.00737804, 0.00037413, 0.00135774, 0.00153146,\n",
       "        0.00132016, 0.00116691, 0.00087255, 0.00074886, 0.0004002 ,\n",
       "        0.00177914, 0.00208498, 0.00162615, 0.0007077 , 0.0044489 ,\n",
       "        0.00097057, 0.00080068, 0.00037469, 0.00146416, 0.00122584,\n",
       "        0.0026556 , 0.01000566, 0.00280596, 0.01298565, 0.00074902,\n",
       "        0.00126582, 0.00361676, 0.00222902, 0.00112352, 0.00066392,\n",
       "        0.00180135, 0.00175097, 0.00165681, 0.00104955, 0.00058326,\n",
       "        0.00381159, 0.00232538, 0.00111454, 0.00111471, 0.00111439,\n",
       "        0.00073557, 0.00210844, 0.00087258, 0.00132015, 0.00058373,\n",
       "        0.00097117, 0.00217947, 0.00063305, 0.00194091, 0.00067899,\n",
       "        0.00193556, 0.00666445, 0.00132833, 0.00526392, 0.00168644,\n",
       "        0.00172199, 0.00505084, 0.00128993, 0.00146423, 0.00982946,\n",
       "        0.00466667, 0.00201641, 0.00073548, 0.00156967, 0.00037452,\n",
       "        0.0016261 , 0.00132012, 0.0022823 , 0.00180709, 0.00102057,\n",
       "        0.00177302, 0.00318671, 0.00284835, 0.00126584, 0.0082328 ,\n",
       "        0.00219285, 0.00397077, 0.00377938, 0.00495816, 0.00294535,\n",
       "        0.00294547, 0.00843713, 0.00332853, 0.0025791 , 0.0102248 ,\n",
       "        0.00407028, 0.00100088, 0.00358099, 0.00480624, 0.00495391,\n",
       "        0.00737277, 0.00501162, 0.00890134, 0.00967592, 0.00860606,\n",
       "        0.00448685, 0.00962824, 0.00371814, 0.00423479, 0.01079177,\n",
       "        0.00942941, 0.01207378, 0.00342331, 0.00097055]),\n",
       " 'param_classifier': masked_array(data=[SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True),\n",
       "                    SVC(max_iter=7000, probability=True)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 10000, 10000, 10000, 10000, 10000,\n",
       "                    10000, 10000, 10000, 10000, 100000, 100000, 100000,\n",
       "                    100000, 100000, 100000, 100000, 100000, 100000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__gamma': masked_array(data=[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06,\n",
       "                    1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08, 1e-07,\n",
       "                    1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 1e-08,\n",
       "                    1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                    1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                    0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                    0.01, 0.1, 1.0, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001,\n",
       "                    0.001, 0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                    'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'rbf'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'sigmoid'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'poly'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 1000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 10000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-08,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-07,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-06,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1e-05,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.0001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.001,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.01,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'linear'},\n",
       "  {'classifier': SVC(max_iter=7000, probability=True),\n",
       "   'classifier__C': 100000,\n",
       "   'classifier__gamma': 1.0,\n",
       "   'classifier__kernel': 'linear'}],\n",
       " 'split0_test_recall_micro': array([0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.931,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.924, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.893, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.904, 0.858, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.686, 0.705, 0.858, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.869, 0.747, 0.705, 0.858, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.905,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.904, 0.894,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.88 , 0.889,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.881, 0.889,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.898, 0.875, 0.89 ,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.853, 0.876, 0.89 ,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.731, 0.828, 0.873, 0.89 ,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.873,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.879, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.875, 0.856, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.652, 0.652, 0.652, 0.652, 0.652, 0.652, 0.652, 0.652, 0.652,\n",
       "        0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 ,\n",
       "        0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 ,\n",
       "        0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 ]),\n",
       " 'split1_test_recall_micro': array([0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.932,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.899, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.796, 0.885, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.846, 0.793, 0.885, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.745, 0.646, 0.793, 0.885, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.888,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.907, 0.864,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.87 , 0.868,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.875, 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.892, 0.865, 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.858, 0.87 , 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.631, 0.808, 0.866, 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.839,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.839, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.839, 0.838, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734,\n",
       "        0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676,\n",
       "        0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676,\n",
       "        0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676]),\n",
       " 'split2_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.764, 0.885, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.874, 0.765, 0.885, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.69 , 0.66 , 0.765, 0.885, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.887,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.901, 0.874,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.881, 0.877,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.878, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.898, 0.875, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.855, 0.874, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.621, 0.807, 0.873, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865, 0.861, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601]),\n",
       " 'split3_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.931,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.929, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.913, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.832, 0.892, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.7  , 0.65 , 0.892, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.786, 0.781, 0.65 , 0.892, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.893,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.905, 0.872,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.868, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.871, 0.863,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.888, 0.858, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.854, 0.874, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.734, 0.849, 0.87 , 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.846,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.846, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.875, 0.857, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.619, 0.619, 0.619, 0.619, 0.619, 0.619, 0.619, 0.619, 0.619,\n",
       "        0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668,\n",
       "        0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668,\n",
       "        0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668]),\n",
       " 'split4_test_recall_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.932,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.908, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.688, 0.889, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.669, 0.677, 0.889, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.716, 0.745, 0.677, 0.889, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.89 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.909, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.877, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.896, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.906, 0.893, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.882, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.636, 0.844, 0.892, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.851, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705,\n",
       "        0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633,\n",
       "        0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633,\n",
       "        0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633]),\n",
       " 'mean_test_recall_micro': array([0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9322, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.927 , 0.9372, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9032, 0.9372, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.7968, 0.8818, 0.9372, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.755 , 0.718 , 0.8818, 0.9372,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.7612, 0.7158, 0.718 , 0.8818,\n",
       "        0.9372, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.8926, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9052, 0.8766, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.8752, 0.878 , 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8802, 0.873 , 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8964, 0.8732, 0.8762,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8562, 0.8752,\n",
       "        0.8762, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.6706, 0.8272,\n",
       "        0.8748, 0.8762, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.854 , 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8522, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8522, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8552, 0.8522,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8526,\n",
       "        0.8522, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.8526, 0.8522, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.8602, 0.8526, 0.8522, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.6622, 0.6622, 0.6622, 0.6622, 0.6622, 0.6622, 0.6622, 0.6622,\n",
       "        0.6622, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536,\n",
       "        0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536,\n",
       "        0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536,\n",
       "        0.6536, 0.6536, 0.6536, 0.6536]),\n",
       " 'std_test_recall_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00146969, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00167332, 0.00213542,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00693974, 0.00213542, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.07161676, 0.01218852, 0.00213542, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.08674561, 0.05349392,\n",
       "        0.01218852, 0.00213542, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.06262715, 0.05303357, 0.05349392, 0.01218852,\n",
       "        0.00213542, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00652993, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00271293, 0.00995188, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.00526878,\n",
       "        0.0069282 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00856505, 0.00920869,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00611882, 0.01180508, 0.00813388, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00292575, 0.00391918, 0.00813388, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.05078031, 0.01752027,\n",
       "        0.00897552, 0.00813388, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.01280625, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00757364, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00757364, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.01467515,\n",
       "        0.00757364, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00796492, 0.00757364,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00796492, 0.00757364, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.01472956, 0.00796492, 0.00757364, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.05040397, 0.05040397,\n",
       "        0.05040397, 0.05040397, 0.05040397, 0.05040397, 0.05040397,\n",
       "        0.05040397, 0.05040397, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708]),\n",
       " 'rank_test_recall_micro': array([  7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   6,   7,   7,   7,\n",
       "          7,   7,   7,   7, 249,   1,   7,   7,   7,   7,   7,   7,   7,\n",
       "        251,   1,   7,   7,   7,   7,   7,   7, 282, 254,   1,   7,   7,\n",
       "          7,   7,   7, 284, 285, 254,   1,   7,   7,   7,   7, 283, 287,\n",
       "        285, 254,   1,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7, 253,   7,   7,   7,   7,   7,   7,   7, 250, 259,\n",
       "          7,   7,   7,   7,   7,   7,   7, 263, 258,   7,   7,   7,   7,\n",
       "          7,   7,   7, 257, 267,   7,   7,   7,   7,   7,   7, 252, 266,\n",
       "        260,   7,   7,   7,   7,   7,   7, 269, 263, 260,   7,   7,   7,\n",
       "          7,   7, 288, 281, 265, 260,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7, 271,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 275,   7,   7,   7,   7,   7,   7,   7,   7, 275,   7,\n",
       "          7,   7,   7,   7,   7,   7, 270, 275,   7,   7,   7,   7,   7,\n",
       "          7,   7, 272, 275,   7,   7,   7,   7,   7,   7,   7, 272, 275,\n",
       "          7,   7,   7,   7,   7,   7, 268, 272, 275,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 289, 289, 289, 289, 289, 289, 289, 289, 289, 298, 298,\n",
       "        298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298,\n",
       "        298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298]),\n",
       " 'split0_test_f1_micro': array([0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.931,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.924, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.893, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.904, 0.858, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.686, 0.705, 0.858, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.869, 0.747, 0.705, 0.858, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.905,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.904, 0.894,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.88 , 0.889,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.881, 0.889,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.898, 0.875, 0.89 ,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.853, 0.876, 0.89 ,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.731, 0.828, 0.873, 0.89 ,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.873,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.879, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.856, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.875, 0.856, 0.856,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.652, 0.652, 0.652, 0.652, 0.652, 0.652, 0.652, 0.652, 0.652,\n",
       "        0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 ,\n",
       "        0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 ,\n",
       "        0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 , 0.69 ]),\n",
       " 'split1_test_f1_micro': array([0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.932,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.899, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.796, 0.885, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.846, 0.793, 0.885, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.745, 0.646, 0.793, 0.885, 0.936,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.888,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.907, 0.864,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.87 , 0.868,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.875, 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.892, 0.865, 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.858, 0.87 , 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.631, 0.808, 0.866, 0.865,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.839,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.839, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.838, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.839, 0.838, 0.838,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "        0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734,\n",
       "        0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676,\n",
       "        0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676,\n",
       "        0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676]),\n",
       " 'split2_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.903, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.764, 0.885, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.874, 0.765, 0.885, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.69 , 0.66 , 0.765, 0.885, 0.941,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.887,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.901, 0.874,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.881, 0.877,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.878, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.898, 0.875, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.855, 0.874, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.621, 0.807, 0.873, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.865, 0.861, 0.859,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601,\n",
       "        0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601, 0.601]),\n",
       " 'split3_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.931,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.929, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.913, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.832, 0.892, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.7  , 0.65 , 0.892, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.786, 0.781, 0.65 , 0.892, 0.938,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.893,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.905, 0.872,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.868, 0.875,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.871, 0.863,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.888, 0.858, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.854, 0.874, 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.734, 0.849, 0.87 , 0.878,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.846,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.846, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.857, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.875, 0.857, 0.857,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.619, 0.619, 0.619, 0.619, 0.619, 0.619, 0.619, 0.619, 0.619,\n",
       "        0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668,\n",
       "        0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668,\n",
       "        0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668]),\n",
       " 'split4_test_f1_micro': array([0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.932,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.908, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.688, 0.889, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.669, 0.677, 0.889, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.716, 0.745, 0.677, 0.889, 0.935,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.89 ,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.909, 0.879,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.877, 0.881,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.896, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.906, 0.893, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.861, 0.882, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.636, 0.844, 0.892, 0.873,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.851, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.847, 0.851, 0.851,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927,\n",
       "        0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705,\n",
       "        0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633,\n",
       "        0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633,\n",
       "        0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633]),\n",
       " 'mean_test_f1_micro': array([0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9322, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.927 , 0.9372, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9032, 0.9372, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.7968, 0.8818, 0.9372, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.755 , 0.718 , 0.8818, 0.9372,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.7612, 0.7158, 0.718 , 0.8818,\n",
       "        0.9372, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.8926, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9052, 0.8766, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.8752, 0.878 , 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8802, 0.873 , 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8964, 0.8732, 0.8762,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8562, 0.8752,\n",
       "        0.8762, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.6706, 0.8272,\n",
       "        0.8748, 0.8762, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.854 , 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8522, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8522, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8552, 0.8522,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.8526,\n",
       "        0.8522, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.8526, 0.8522, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.8602, 0.8526, 0.8522, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274, 0.9274,\n",
       "        0.6622, 0.6622, 0.6622, 0.6622, 0.6622, 0.6622, 0.6622, 0.6622,\n",
       "        0.6622, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536,\n",
       "        0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536,\n",
       "        0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536,\n",
       "        0.6536, 0.6536, 0.6536, 0.6536]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00146969, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00167332, 0.00213542,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00693974, 0.00213542, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.07161676, 0.01218852, 0.00213542, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.08674561, 0.05349392,\n",
       "        0.01218852, 0.00213542, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.06262715, 0.05303357, 0.05349392, 0.01218852,\n",
       "        0.00213542, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00652993, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00271293, 0.00995188, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.00526878,\n",
       "        0.0069282 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00856505, 0.00920869,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00611882, 0.01180508, 0.00813388, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.00292575, 0.00391918, 0.00813388, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.05078031, 0.01752027,\n",
       "        0.00897552, 0.00813388, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.01280625, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00757364, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00757364, 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.01467515,\n",
       "        0.00757364, 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.00796492, 0.00757364,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.00796492, 0.00757364, 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.01472956, 0.00796492, 0.00757364, 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.0004899 , 0.0004899 , 0.05040397, 0.05040397,\n",
       "        0.05040397, 0.05040397, 0.05040397, 0.05040397, 0.05040397,\n",
       "        0.05040397, 0.05040397, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708, 0.03232708,\n",
       "        0.03232708, 0.03232708, 0.03232708, 0.03232708]),\n",
       " 'rank_test_f1_micro': array([  7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   6,   7,   7,   7,\n",
       "          7,   7,   7,   7, 249,   1,   7,   7,   7,   7,   7,   7,   7,\n",
       "        251,   1,   7,   7,   7,   7,   7,   7, 282, 254,   1,   7,   7,\n",
       "          7,   7,   7, 284, 285, 254,   1,   7,   7,   7,   7, 283, 287,\n",
       "        285, 254,   1,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7, 253,   7,   7,   7,   7,   7,   7,   7, 250, 259,\n",
       "          7,   7,   7,   7,   7,   7,   7, 263, 258,   7,   7,   7,   7,\n",
       "          7,   7,   7, 257, 267,   7,   7,   7,   7,   7,   7, 252, 266,\n",
       "        260,   7,   7,   7,   7,   7,   7, 269, 263, 260,   7,   7,   7,\n",
       "          7,   7, 288, 281, 265, 260,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7, 271,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 275,   7,   7,   7,   7,   7,   7,   7,   7, 275,   7,\n",
       "          7,   7,   7,   7,   7,   7, 270, 275,   7,   7,   7,   7,   7,\n",
       "          7,   7, 272, 275,   7,   7,   7,   7,   7,   7,   7, 272, 275,\n",
       "          7,   7,   7,   7,   7,   7, 268, 272, 275,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7, 289, 289, 289, 289, 289, 289, 289, 289, 289, 298, 298,\n",
       "        298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298,\n",
       "        298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298]),\n",
       " 'split0_test_roc_auc_ovo': array([0.48027419, 0.4892391 , 0.5       , 0.49872785, 0.49378891,\n",
       "        0.49859315, 0.52473958, 0.59900323, 0.57161458, 0.51900742,\n",
       "        0.5       , 0.48326748, 0.49872785, 0.49378891, 0.49859315,\n",
       "        0.45930615, 0.63483297, 0.67784662, 0.50692948, 0.52919959,\n",
       "        0.52937919, 0.49872785, 0.49378891, 0.53723659, 0.52405113,\n",
       "        0.62248563, 0.68106442, 0.48566212, 0.44713841, 0.48653017,\n",
       "        0.49872785, 0.50884519, 0.56981861, 0.54322318, 0.63248324,\n",
       "        0.67961267, 0.51370929, 0.44713841, 0.48653017, 0.4454921 ,\n",
       "        0.50327766, 0.56038973, 0.54030472, 0.63320163, 0.68290529,\n",
       "        0.48566212, 0.55286159, 0.52631106, 0.47843331, 0.53479705,\n",
       "        0.52479945, 0.57957675, 0.66804358, 0.68229167, 0.48729346,\n",
       "        0.5075431 , 0.52396133, 0.48856561, 0.56710967, 0.54489943,\n",
       "        0.57721205, 0.65556154, 0.68648228, 0.50743834, 0.52586207,\n",
       "        0.49492636, 0.47121947, 0.55143977, 0.50667505, 0.50176604,\n",
       "        0.65518738, 0.68535979, 0.52039931, 0.51953125, 0.47262632,\n",
       "        0.51441272, 0.52695462, 0.52126736, 0.50067349, 0.65568127,\n",
       "        0.68654215, 0.48010207, 0.47065074, 0.5       , 0.52021971,\n",
       "        0.51800467, 0.46982759, 0.47386853, 0.52244971, 0.52191092,\n",
       "        0.47065074, 0.47475156, 0.5       , 0.47978029, 0.51800467,\n",
       "        0.46982759, 0.49893738, 0.54057411, 0.53066631, 0.5       ,\n",
       "        0.5       , 0.47065074, 0.47978029, 0.51800467, 0.51590936,\n",
       "        0.52218032, 0.56059926, 0.51601413, 0.5       , 0.48795199,\n",
       "        0.47065074, 0.47978029, 0.47858297, 0.50101772, 0.55387931,\n",
       "        0.57743654, 0.52735872, 0.47780472, 0.48795199, 0.47065074,\n",
       "        0.46123683, 0.52658046, 0.50519337, 0.55545079, 0.56170678,\n",
       "        0.51596923, 0.47780472, 0.48795199, 0.47526042, 0.4843301 ,\n",
       "        0.4741529 , 0.50303819, 0.55322079, 0.57399425, 0.50396612,\n",
       "        0.47780472, 0.49794959, 0.45355903, 0.49401341, 0.45270594,\n",
       "        0.5131705 , 0.53862847, 0.57484734, 0.49549509, 0.52608657,\n",
       "        0.46714859, 0.48908944, 0.50068846, 0.49304059, 0.5391074 ,\n",
       "        0.53779035, 0.55522629, 0.49551006, 0.52165649, 0.51110512,\n",
       "        0.51438278, 0.51975575, 0.52054897, 0.50172114, 0.53984076,\n",
       "        0.56052443, 0.49556992, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.52682741, 0.50225994, 0.50224497, 0.4736141 ,\n",
       "        0.50411578, 0.5       , 0.5       , 0.5       , 0.50399605,\n",
       "        0.50225994, 0.50225994, 0.50233477, 0.49113985, 0.51055136,\n",
       "        0.5       , 0.5       , 0.49946121, 0.50030681, 0.50225994,\n",
       "        0.5       , 0.50248443, 0.52162656, 0.52568247, 0.5       ,\n",
       "        0.5       , 0.5       , 0.52681244, 0.50225994, 0.50225994,\n",
       "        0.4738835 , 0.48371648, 0.47153376, 0.5       , 0.5       ,\n",
       "        0.50826898, 0.50225994, 0.50225994, 0.50234974, 0.49082555,\n",
       "        0.53042684, 0.47148886, 0.5       , 0.5       , 0.50431034,\n",
       "        0.50225994, 0.5       , 0.50225994, 0.51460728, 0.51424808,\n",
       "        0.47153376, 0.5       , 0.5       , 0.52681992, 0.50225994,\n",
       "        0.50224497, 0.4737488 , 0.51237727, 0.47153376, 0.52846624,\n",
       "        0.5       , 0.50806693, 0.50225994, 0.50220007, 0.50246947,\n",
       "        0.49073575, 0.52806214, 0.47153376, 0.47153376, 0.5       ,\n",
       "        0.49591415, 0.50225994, 0.5       , 0.50223   , 0.52225515,\n",
       "        0.5131705 , 0.47153376, 0.47153376, 0.52827167, 0.52827167,\n",
       "        0.47172833, 0.52770295, 0.5286608 , 0.5282567 , 0.52777778,\n",
       "        0.47172833, 0.47171336, 0.52916966, 0.52915469, 0.47141403,\n",
       "        0.47195283, 0.47083034, 0.52916966, 0.47083034, 0.52916966,\n",
       "        0.52916966, 0.52855603, 0.47144397, 0.52855603, 0.52855603,\n",
       "        0.52855603, 0.47144397, 0.47144397, 0.52855603, 0.47144397,\n",
       "        0.51332016, 0.48667984, 0.48667984, 0.48667984, 0.51182352,\n",
       "        0.51332016, 0.51332016, 0.51332016, 0.51332016, 0.49883261,\n",
       "        0.50116739, 0.50116739, 0.50116739, 0.49890745, 0.50116739,\n",
       "        0.50116739, 0.49883261, 0.49883261, 0.47425766, 0.52574234,\n",
       "        0.52574234, 0.47425766, 0.47425766, 0.47425766, 0.52574234,\n",
       "        0.47425766, 0.52574234, 0.4894187 , 0.5105813 , 0.5105364 ,\n",
       "        0.5105813 , 0.4894187 , 0.5105364 , 0.5105813 , 0.5105813 ,\n",
       "        0.5105813 , 0.48940374, 0.5105813 , 0.5105813 , 0.4894187 ,\n",
       "        0.4894187 , 0.5105813 , 0.51143439, 0.4894187 , 0.5105813 ,\n",
       "        0.5105813 , 0.4894187 , 0.5105813 , 0.5105813 , 0.4894187 ,\n",
       "        0.4894187 , 0.4894187 , 0.5105813 , 0.5105813 ]),\n",
       " 'split1_test_roc_auc_ovo': array([0.3643738 , 0.4373653 , 0.5       , 0.46449952, 0.48233956,\n",
       "        0.41473599, 0.52240481, 0.59315134, 0.58966415, 0.46069804,\n",
       "        0.51837883, 0.50496887, 0.56027   , 0.51766044, 0.41473599,\n",
       "        0.49323515, 0.56414631, 0.64110393, 0.44463901, 0.5       ,\n",
       "        0.40385536, 0.53550048, 0.51766044, 0.41816331, 0.53785022,\n",
       "        0.59990122, 0.64586327, 0.5       , 0.53184866, 0.52798731,\n",
       "        0.43973   , 0.53241739, 0.48371648, 0.50056873, 0.60295438,\n",
       "        0.64732998, 0.48618594, 0.53184866, 0.52798731, 0.48647031,\n",
       "        0.46988745, 0.50353209, 0.5392421 , 0.59871887, 0.64969468,\n",
       "        0.48618594, 0.49326509, 0.53288135, 0.42807112, 0.52725395,\n",
       "        0.52138709, 0.46409543, 0.57845426, 0.64876676, 0.48603628,\n",
       "        0.52755328, 0.57305136, 0.44751257, 0.5550018 , 0.58658106,\n",
       "        0.48389607, 0.59536638, 0.64979945, 0.54627634, 0.54027478,\n",
       "        0.3987069 , 0.58204622, 0.56169181, 0.54534842, 0.49354945,\n",
       "        0.59593511, 0.64951509, 0.56437081, 0.50098779, 0.54802742,\n",
       "        0.44320223, 0.45319983, 0.52777778, 0.49354945, 0.59580041,\n",
       "        0.64954502, 0.50908465, 0.47782717, 0.43673671, 0.5       ,\n",
       "        0.43998443, 0.4399545 , 0.46105723, 0.54588721, 0.46795678,\n",
       "        0.45725575, 0.5       , 0.5       , 0.59880867, 0.43998443,\n",
       "        0.5600455 , 0.56926485, 0.52632603, 0.50474437, 0.429912  ,\n",
       "        0.5       , 0.45780951, 0.40119133, 0.43998443, 0.48204023,\n",
       "        0.57251257, 0.49782986, 0.49823396, 0.5       , 0.4088392 ,\n",
       "        0.45780951, 0.40119133, 0.5204891 , 0.56616679, 0.50731861,\n",
       "        0.49333992, 0.46423012, 0.429912  , 0.5911608 , 0.54219049,\n",
       "        0.53585967, 0.43395295, 0.41545438, 0.49568966, 0.51275144,\n",
       "        0.49311542, 0.570088  , 0.5911608 , 0.43793403, 0.58719468,\n",
       "        0.5024545 , 0.45674689, 0.49045139, 0.4950012 , 0.49574952,\n",
       "        0.570088  , 0.38851473, 0.46108716, 0.57041727, 0.53042684,\n",
       "        0.55021252, 0.47322498, 0.52707435, 0.4951808 , 0.46740302,\n",
       "        0.44511794, 0.5025443 , 0.53458752, 0.40785141, 0.44062799,\n",
       "        0.5939296 , 0.48862548, 0.49615362, 0.5105813 , 0.47699653,\n",
       "        0.5235273 , 0.55157447, 0.57932232, 0.50187081, 0.54489943,\n",
       "        0.47765505, 0.49591415, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.38850724, 0.60859674, 0.60859674, 0.51788494,\n",
       "        0.57037237, 0.5       , 0.5       , 0.5       , 0.6013829 ,\n",
       "        0.60859674, 0.60859674, 0.60859674, 0.51605903, 0.55076628,\n",
       "        0.5       , 0.5       , 0.5       , 0.57443576, 0.60859674,\n",
       "        0.5       , 0.60859674, 0.57647869, 0.45977011, 0.5       ,\n",
       "        0.5       , 0.5       , 0.38849976, 0.60859674, 0.39140326,\n",
       "        0.51788494, 0.57845426, 0.47216236, 0.5       , 0.5       ,\n",
       "        0.39831777, 0.60858926, 0.60859674, 0.60859674, 0.51601413,\n",
       "        0.5573665 , 0.47216236, 0.5       , 0.5       , 0.42512273,\n",
       "        0.60859674, 0.39140326, 0.60859674, 0.57658345, 0.45977011,\n",
       "        0.47214739, 0.5       , 0.49515086, 0.38845486, 0.60859674,\n",
       "        0.60859674, 0.51788494, 0.56987847, 0.47216236, 0.47216236,\n",
       "        0.5       , 0.39666397, 0.60858926, 0.39140326, 0.60859674,\n",
       "        0.51604406, 0.57969648, 0.47216236, 0.47216236, 0.5       ,\n",
       "        0.42712823, 0.60859674, 0.5       , 0.39144816, 0.54120271,\n",
       "        0.45971025, 0.47216236, 0.47216236, 0.54835668, 0.45164332,\n",
       "        0.54835668, 0.54835668, 0.54835668, 0.54835668, 0.45164332,\n",
       "        0.54835668, 0.54835668, 0.41344887, 0.41344887, 0.58568307,\n",
       "        0.58655113, 0.58655113, 0.41344887, 0.58655113, 0.58655113,\n",
       "        0.41338901, 0.54108297, 0.45891703, 0.45891703, 0.45927622,\n",
       "        0.45891703, 0.45891703, 0.54108297, 0.54108297, 0.54108297,\n",
       "        0.54299868, 0.54299868, 0.45700132, 0.45700132, 0.45700132,\n",
       "        0.54299868, 0.45700132, 0.45700132, 0.54299868, 0.56534363,\n",
       "        0.56534363, 0.56534363, 0.56534363, 0.43458154, 0.43465637,\n",
       "        0.56534363, 0.43465637, 0.56534363, 0.47144397, 0.52855603,\n",
       "        0.47144397, 0.47144397, 0.52855603, 0.52855603, 0.52855603,\n",
       "        0.47144397, 0.52855603, 0.43735034, 0.56264966, 0.56264966,\n",
       "        0.43729047, 0.56264966, 0.43691631, 0.56264966, 0.56264966,\n",
       "        0.56264966, 0.56264966, 0.56264966, 0.56264966, 0.43735034,\n",
       "        0.43735034, 0.56264966, 0.56264966, 0.43735034, 0.43735034,\n",
       "        0.56264966, 0.43735034, 0.43735034, 0.56264966, 0.43735034,\n",
       "        0.56264966, 0.56264966, 0.56264966, 0.43735034]),\n",
       " 'split2_test_roc_auc_ovo': array([0.45580825, 0.44946875, 0.5       , 0.45866028, 0.43588834,\n",
       "        0.42919419, 0.55084157, 0.55007315, 0.61473896, 0.39952121,\n",
       "        0.53996542, 0.55412215, 0.44108998, 0.43588834, 0.57080581,\n",
       "        0.5149621 , 0.62140356, 0.70024087, 0.5       , 0.5       ,\n",
       "        0.45842384, 0.58963219, 0.56411166, 0.49690414, 0.56991917,\n",
       "        0.64590445, 0.69855625, 0.57856393, 0.53999498, 0.40030441,\n",
       "        0.51004123, 0.51290804, 0.55951589, 0.56984528, 0.6371858 ,\n",
       "        0.69709329, 0.42136218, 0.53999498, 0.59969559, 0.46100989,\n",
       "        0.46545788, 0.5645402 , 0.54065996, 0.6395354 , 0.69103456,\n",
       "        0.42143607, 0.46000502, 0.50927281, 0.57043638, 0.55670819,\n",
       "        0.49319502, 0.55947156, 0.63167383, 0.6881382 , 0.45608902,\n",
       "        0.44113431, 0.58414978, 0.45926616, 0.59855773, 0.57424894,\n",
       "        0.56380133, 0.63445198, 0.68769488, 0.49131829, 0.4419914 ,\n",
       "        0.49318024, 0.44757725, 0.55453592, 0.42653426, 0.54844764,\n",
       "        0.63372789, 0.68629103, 0.55311729, 0.44924709, 0.4787723 ,\n",
       "        0.54537394, 0.49232315, 0.52563136, 0.54847719, 0.63369833,\n",
       "        0.68651269, 0.45202524, 0.49919463, 0.5511519 , 0.5       ,\n",
       "        0.54425086, 0.44689749, 0.4794225 , 0.53641885, 0.48870269,\n",
       "        0.48005793, 0.44867077, 0.5511519 , 0.57129346, 0.54425086,\n",
       "        0.44689749, 0.54717678, 0.54636403, 0.52235079, 0.53708383,\n",
       "        0.5       , 0.5511519 , 0.42870654, 0.54425086, 0.52866073,\n",
       "        0.37512376, 0.53103988, 0.52093216, 0.53708383, 0.44867077,\n",
       "        0.4488481 , 0.57129346, 0.53525144, 0.57634733, 0.55868836,\n",
       "        0.55308773, 0.51178496, 0.53708383, 0.55132923, 0.4488481 ,\n",
       "        0.54037919, 0.47620103, 0.48358972, 0.51370602, 0.51883377,\n",
       "        0.54006886, 0.53708383, 0.55132923, 0.469034  , 0.57676109,\n",
       "        0.52979858, 0.56959407, 0.50911025, 0.53089211, 0.52164147,\n",
       "        0.46291617, 0.46142365, 0.57560846, 0.47271357, 0.46149754,\n",
       "        0.53922655, 0.54190126, 0.50364262, 0.52220301, 0.55249664,\n",
       "        0.55379705, 0.51163719, 0.49770212, 0.48527434, 0.52372508,\n",
       "        0.56396388, 0.53915267, 0.52164147, 0.56878131, 0.59651845,\n",
       "        0.4628275 , 0.51011512, 0.45034062, 0.55029481, 0.51075054,\n",
       "        0.52499594, 0.52164147, 0.5       , 0.5       , 0.5       ,\n",
       "        0.53203736, 0.528875  , 0.52864595, 0.52864595, 0.54509317,\n",
       "        0.59212957, 0.5       , 0.5       , 0.5       , 0.5151542 ,\n",
       "        0.52866073, 0.5       , 0.52864595, 0.56437765, 0.57914025,\n",
       "        0.5       , 0.5       , 0.5       , 0.5046401 , 0.52864595,\n",
       "        0.5       , 0.52864595, 0.58307103, 0.62019181, 0.5       ,\n",
       "        0.5       , 0.51892243, 0.52888239, 0.52864595, 0.52864595,\n",
       "        0.54491584, 0.56347623, 0.5079724 , 0.5       , 0.5       ,\n",
       "        0.51819834, 0.52866073, 0.52864595, 0.52864595, 0.43562235,\n",
       "        0.55252619, 0.50791329, 0.5       , 0.5       , 0.50500214,\n",
       "        0.52864595, 0.5       , 0.52864595, 0.58024856, 0.62017703,\n",
       "        0.5079724 , 0.5       , 0.48188293, 0.47113239, 0.52864595,\n",
       "        0.52864595, 0.54491584, 0.59733121, 0.48721018, 0.50795762,\n",
       "        0.5       , 0.52059967, 0.52866073, 0.47088856, 0.52864595,\n",
       "        0.43562235, 0.59430184, 0.51278982, 0.4920276 , 0.5       ,\n",
       "        0.50464749, 0.52864595, 0.5       , 0.52873461, 0.55591021,\n",
       "        0.62019181, 0.48721018, 0.5079724 , 0.47914173, 0.52085827,\n",
       "        0.52085827, 0.52240989, 0.47914173, 0.47911218, 0.47914173,\n",
       "        0.52085827, 0.52235079, 0.48726929, 0.48728407, 0.51271593,\n",
       "        0.48728407, 0.48728407, 0.48728407, 0.51264205, 0.48787516,\n",
       "        0.51271593, 0.48919035, 0.51080965, 0.51080965, 0.51070621,\n",
       "        0.51080965, 0.51080965, 0.48939723, 0.48913124, 0.51080965,\n",
       "        0.49182072, 0.49182072, 0.50817928, 0.50817928, 0.50817928,\n",
       "        0.50817928, 0.49182072, 0.50817928, 0.50817928, 0.56103796,\n",
       "        0.43896204, 0.56103796, 0.43896204, 0.56103796, 0.43896204,\n",
       "        0.56103796, 0.43896204, 0.43896204, 0.48487535, 0.51633639,\n",
       "        0.51648417, 0.48390005, 0.51633639, 0.48390005, 0.51609995,\n",
       "        0.51608518, 0.51609995, 0.48416604, 0.51609995, 0.51609995,\n",
       "        0.48390005, 0.51641028, 0.48390005, 0.48390005, 0.48390005,\n",
       "        0.51609995, 0.51609995, 0.48483102, 0.51609995, 0.48512657,\n",
       "        0.51609995, 0.48390005, 0.48483102, 0.51627728, 0.48390005,\n",
       "        0.51646939, 0.48390005, 0.48390005, 0.51609995, 0.51609995,\n",
       "        0.48390005, 0.48390005, 0.51609995, 0.48390005]),\n",
       " 'split3_test_roc_auc_ovo': array([0.46143843, 0.50036205, 0.5       , 0.54159093, 0.44779891,\n",
       "        0.47021619, 0.51997163, 0.56721491, 0.60853246, 0.49072719,\n",
       "        0.5       , 0.51339569, 0.54159093, 0.44779891, 0.47021619,\n",
       "        0.52017851, 0.58166718, 0.66812963, 0.5       , 0.50930236,\n",
       "        0.47506317, 0.54159093, 0.44779891, 0.51054366, 0.54024619,\n",
       "        0.61030574, 0.68126672, 0.50587401, 0.49182072, 0.47745711,\n",
       "        0.54159093, 0.46918178, 0.502091  , 0.54578771, 0.60825169,\n",
       "        0.68104506, 0.50587401, 0.49182072, 0.47745711, 0.48057514,\n",
       "        0.49282558, 0.57396817, 0.58122386, 0.6102023 , 0.68420742,\n",
       "        0.49412599, 0.49182072, 0.46424613, 0.53346337, 0.5578756 ,\n",
       "        0.55656042, 0.58617428, 0.64246132, 0.67652318, 0.54225591,\n",
       "        0.5326654 , 0.47416175, 0.47837331, 0.58153419, 0.57201756,\n",
       "        0.51472566, 0.63476231, 0.67773492, 0.54974805, 0.47660002,\n",
       "        0.52162669, 0.45104993, 0.5238433 , 0.47880185, 0.47621581,\n",
       "        0.63499874, 0.67816347, 0.49779078, 0.46210341, 0.48787516,\n",
       "        0.46752671, 0.47729456, 0.54374843, 0.52512893, 0.63353578,\n",
       "        0.67587297, 0.53935955, 0.5546098 , 0.5       , 0.5       ,\n",
       "        0.54837375, 0.47453119, 0.46548743, 0.60687739, 0.53399536,\n",
       "        0.55447681, 0.5       , 0.5       , 0.51255338, 0.54837375,\n",
       "        0.47453119, 0.51728214, 0.5953067 , 0.535148  , 0.54155399,\n",
       "        0.5       , 0.49907641, 0.48744662, 0.54837375, 0.47884618,\n",
       "        0.55636831, 0.60542921, 0.56099363, 0.5       , 0.48308729,\n",
       "        0.50092359, 0.48744662, 0.54880229, 0.53624152, 0.58785891,\n",
       "        0.56640215, 0.52996114, 0.56106752, 0.48308729, 0.49907641,\n",
       "        0.47775266, 0.50587401, 0.53368503, 0.57113091, 0.57076148,\n",
       "        0.54923084, 0.56106752, 0.48308729, 0.47763444, 0.49201283,\n",
       "        0.52536537, 0.45372464, 0.59826218, 0.55090068, 0.44802057,\n",
       "        0.56106752, 0.50628777, 0.52421274, 0.5281583 , 0.45966514,\n",
       "        0.50933191, 0.59730165, 0.53635974, 0.56879609, 0.46267973,\n",
       "        0.53111377, 0.48500835, 0.51444489, 0.48085591, 0.42756868,\n",
       "        0.43551891, 0.58581963, 0.56878131, 0.53007935, 0.52704999,\n",
       "        0.49004744, 0.45996069, 0.45319265, 0.50217966, 0.47451641,\n",
       "        0.53200041, 0.5687222 , 0.5       , 0.5       , 0.5       ,\n",
       "        0.43234916, 0.57788417, 0.57792851, 0.57792851, 0.57766251,\n",
       "        0.55864403, 0.5       , 0.5       , 0.5       , 0.5852507 ,\n",
       "        0.54800431, 0.5       , 0.57792851, 0.55540778, 0.58029289,\n",
       "        0.5       , 0.5       , 0.5       , 0.56908425, 0.57792851,\n",
       "        0.5       , 0.57792851, 0.56520518, 0.49318024, 0.5       ,\n",
       "        0.5       , 0.44538281, 0.57791373, 0.42207149, 0.57792851,\n",
       "        0.57745563, 0.55316162, 0.52047406, 0.5       , 0.5       ,\n",
       "        0.58690576, 0.54800431, 0.57792851, 0.57792851, 0.54996971,\n",
       "        0.53010891, 0.47952594, 0.5       , 0.5       , 0.56896603,\n",
       "        0.42207149, 0.5       , 0.57792851, 0.54668913, 0.49331324,\n",
       "        0.52047406, 0.5       , 0.45908883, 0.57791373, 0.57792851,\n",
       "        0.57792851, 0.57742608, 0.58023378, 0.52048884, 0.47952594,\n",
       "        0.5       , 0.55359016, 0.5480117 , 0.57792851, 0.57792851,\n",
       "        0.55564422, 0.56193938, 0.52048884, 0.52047406, 0.5       ,\n",
       "        0.56906208, 0.57792851, 0.5       , 0.57792851, 0.54667435,\n",
       "        0.56649082, 0.52048884, 0.52047406, 0.55421081, 0.55421081,\n",
       "        0.55421081, 0.44578919, 0.55421081, 0.44578919, 0.55421081,\n",
       "        0.55421081, 0.55421081, 0.44849345, 0.44729648, 0.55267397,\n",
       "        0.44732603, 0.55255575, 0.44732603, 0.44732603, 0.44732603,\n",
       "        0.55267397, 0.47398442, 0.52601558, 0.47398442, 0.52601558,\n",
       "        0.47398442, 0.52601558, 0.47398442, 0.47398442, 0.47398442,\n",
       "        0.45620724, 0.54165004, 0.45885239, 0.4585864 , 0.54110328,\n",
       "        0.45892628, 0.54077818, 0.54111806, 0.45892628, 0.46814736,\n",
       "        0.46814736, 0.46814736, 0.46814736, 0.46814736, 0.46814736,\n",
       "        0.46814736, 0.53188219, 0.53177875, 0.52165625, 0.47810731,\n",
       "        0.47810731, 0.52189269, 0.47810731, 0.52189269, 0.47810731,\n",
       "        0.47810731, 0.47810731, 0.51957264, 0.48042736, 0.48042736,\n",
       "        0.48042736, 0.51957264, 0.51957264, 0.48042736, 0.51957264,\n",
       "        0.51973519, 0.52010462, 0.48042736, 0.48042736, 0.48042736,\n",
       "        0.51957264, 0.48042736, 0.48042736, 0.48042736, 0.48042736,\n",
       "        0.48042736, 0.48042736, 0.48042736, 0.51957264, 0.5199273 ,\n",
       "        0.51957264, 0.51957264, 0.51957264, 0.51957264]),\n",
       " 'split4_test_roc_auc_ovo': array([0.49891386, 0.55090068, 0.5       , 0.48972233, 0.460936  ,\n",
       "        0.49394866, 0.46443824, 0.49863309, 0.65064799, 0.50683454,\n",
       "        0.54490107, 0.4778561 , 0.48945634, 0.460936  , 0.49394866,\n",
       "        0.50447016, 0.60169053, 0.69508357, 0.4834715 , 0.45277889,\n",
       "        0.44716348, 0.48972233, 0.460936  , 0.48997355, 0.53805914,\n",
       "        0.64603745, 0.70337368, 0.47429475, 0.48431381, 0.50232744,\n",
       "        0.52741943, 0.54671868, 0.52778886, 0.57451493, 0.64203278,\n",
       "        0.70581194, 0.47429475, 0.48431381, 0.50232744, 0.48827415,\n",
       "        0.51219873, 0.59965125, 0.57426372, 0.64015605, 0.70426032,\n",
       "        0.47427997, 0.48431381, 0.50856349, 0.46213297, 0.5361233 ,\n",
       "        0.55960456, 0.58355869, 0.63142262, 0.7070828 , 0.49988917,\n",
       "        0.52368075, 0.49010654, 0.4831464 , 0.58695749, 0.49349056,\n",
       "        0.49415555, 0.62728495, 0.70678725, 0.49839665, 0.51292282,\n",
       "        0.48152089, 0.50708575, 0.56338757, 0.54428042, 0.48174255,\n",
       "        0.62907302, 0.70624049, 0.51364691, 0.49028387, 0.49904686,\n",
       "        0.50144079, 0.51206573, 0.51756291, 0.48228931, 0.62635398,\n",
       "        0.70634393, 0.54256624, 0.53130588, 0.5       , 0.50454404,\n",
       "        0.54392576, 0.47642269, 0.47463463, 0.52693177, 0.51573052,\n",
       "        0.51723781, 0.5       , 0.5       , 0.50454404, 0.54392576,\n",
       "        0.47642269, 0.45243901, 0.53002025, 0.46448257, 0.5       ,\n",
       "        0.51048455, 0.50362785, 0.50454404, 0.45607424, 0.54909784,\n",
       "        0.52056272, 0.53315305, 0.48821504, 0.48440248, 0.51048455,\n",
       "        0.50362785, 0.50454404, 0.51137119, 0.49427377, 0.51420845,\n",
       "        0.5123465 , 0.50423372, 0.48440248, 0.51048455, 0.50362785,\n",
       "        0.52124248, 0.50546024, 0.48087068, 0.5070562 , 0.5281583 ,\n",
       "        0.50483959, 0.48440248, 0.51048455, 0.49136262, 0.51914409,\n",
       "        0.52107993, 0.50897726, 0.51898154, 0.5303749 , 0.51493254,\n",
       "        0.48440248, 0.50427805, 0.53179353, 0.50990823, 0.53901967,\n",
       "        0.47221114, 0.52405018, 0.530966  , 0.51434145, 0.5342318 ,\n",
       "        0.50537158, 0.52642934, 0.4630935 , 0.43749908, 0.47543261,\n",
       "        0.51825745, 0.51830178, 0.51409023, 0.4794225 , 0.53624152,\n",
       "        0.46392103, 0.48531867, 0.56773212, 0.50423372, 0.5128046 ,\n",
       "        0.51471088, 0.51409023, 0.5       , 0.5       , 0.5       ,\n",
       "        0.51904065, 0.49035776, 0.49040209, 0.49038732, 0.55332417,\n",
       "        0.47719112, 0.5       , 0.5       , 0.5       , 0.50044332,\n",
       "        0.49040209, 0.49040209, 0.49044642, 0.53990631, 0.50980479,\n",
       "        0.5       , 0.5       , 0.5       , 0.50977524, 0.49040209,\n",
       "        0.5       , 0.49040209, 0.4964756 , 0.43764685, 0.5       ,\n",
       "        0.5       , 0.49925374, 0.49043904, 0.49040209, 0.49038732,\n",
       "        0.55364927, 0.49920941, 0.48964845, 0.5       , 0.5       ,\n",
       "        0.500133  , 0.49040209, 0.5       , 0.49040209, 0.53980287,\n",
       "        0.49533774, 0.48964845, 0.5       , 0.5       , 0.50972352,\n",
       "        0.49040209, 0.5       , 0.49040209, 0.49607661, 0.43758774,\n",
       "        0.48964845, 0.5       , 0.50845266, 0.4903947 , 0.49040209,\n",
       "        0.49040209, 0.55367883, 0.51484388, 0.48964845, 0.48964845,\n",
       "        0.5       , 0.4986922 , 0.49040209, 0.5       , 0.49040209,\n",
       "        0.54061563, 0.49784989, 0.48964845, 0.48964845, 0.5       ,\n",
       "        0.50972352, 0.49040209, 0.5       , 0.49040209, 0.49034298,\n",
       "        0.43752863, 0.48963367, 0.48964845, 0.48351583, 0.48351583,\n",
       "        0.51643983, 0.51648417, 0.48348628, 0.48351583, 0.51648417,\n",
       "        0.48351583, 0.48351583, 0.4834715 , 0.4834715 , 0.4834715 ,\n",
       "        0.5165285 , 0.5165285 , 0.5165285 , 0.5165285 , 0.4834715 ,\n",
       "        0.5165285 , 0.46539877, 0.53460123, 0.46539877, 0.46539877,\n",
       "        0.46483723, 0.46539877, 0.46539877, 0.53460123, 0.46539877,\n",
       "        0.51737081, 0.48271786, 0.48262919, 0.4830134 , 0.48262919,\n",
       "        0.51737081, 0.51737081, 0.51737081, 0.51737081, 0.5027412 ,\n",
       "        0.4972588 , 0.49731791, 0.4972588 , 0.4972588 , 0.50297764,\n",
       "        0.49827844, 0.4972588 , 0.5027412 , 0.47806298, 0.47806298,\n",
       "        0.47806298, 0.52193702, 0.47806298, 0.52193702, 0.52193702,\n",
       "        0.47806298, 0.47806298, 0.49619482, 0.50380518, 0.50380518,\n",
       "        0.50380518, 0.49619482, 0.49619482, 0.49619482, 0.49619482,\n",
       "        0.50380518, 0.50380518, 0.50380518, 0.49619482, 0.50380518,\n",
       "        0.50380518, 0.50380518, 0.49619482, 0.50380518, 0.50374607,\n",
       "        0.50380518, 0.49619482, 0.49615049, 0.50380518, 0.50380518,\n",
       "        0.50380518, 0.49619482, 0.50380518, 0.49619482]),\n",
       " 'mean_test_roc_auc_ovo': array([0.45216171, 0.48546718, 0.5       , 0.49064018, 0.46415034,\n",
       "        0.46133764, 0.51647917, 0.56161514, 0.60703963, 0.47535768,\n",
       "        0.52064906, 0.50672206, 0.50622702, 0.47121452, 0.48965996,\n",
       "        0.49843041, 0.60074811, 0.67648092, 0.487008  , 0.49825617,\n",
       "        0.46277701, 0.53103476, 0.49685918, 0.49056425, 0.54202517,\n",
       "        0.6249269 , 0.68202486, 0.50887896, 0.49902332, 0.47892129,\n",
       "        0.50350189, 0.51401421, 0.52858617, 0.54678797, 0.62458158,\n",
       "        0.68217859, 0.48028523, 0.49902332, 0.51879952, 0.47236432,\n",
       "        0.48872946, 0.56041629, 0.55513887, 0.62436285, 0.68242045,\n",
       "        0.47233802, 0.49645325, 0.50825497, 0.49450743, 0.54255162,\n",
       "        0.53110931, 0.55457534, 0.63041112, 0.68056052, 0.49431277,\n",
       "        0.50651537, 0.52908615, 0.47137281, 0.57783217, 0.55424751,\n",
       "        0.52675813, 0.62948543, 0.68169976, 0.51863553, 0.49953022,\n",
       "        0.47799222, 0.49179572, 0.55097967, 0.500328  , 0.5003443 ,\n",
       "        0.62978443, 0.68111397, 0.52986502, 0.48443068, 0.49726961,\n",
       "        0.49439128, 0.49236758, 0.52719757, 0.51002368, 0.62901396,\n",
       "        0.68096335, 0.50462755, 0.50671764, 0.49757772, 0.50495275,\n",
       "        0.51890789, 0.46152669, 0.47089407, 0.54771299, 0.50565925,\n",
       "        0.49593581, 0.48468447, 0.51023038, 0.53339597, 0.51890789,\n",
       "        0.48554489, 0.51702003, 0.54771822, 0.51147841, 0.50170996,\n",
       "        0.50209691, 0.49646328, 0.46033376, 0.50133759, 0.51091087,\n",
       "        0.50934954, 0.54561025, 0.51687778, 0.50429726, 0.46780676,\n",
       "        0.47637196, 0.48885115, 0.5188994 , 0.53480942, 0.54439073,\n",
       "        0.54052257, 0.50751373, 0.49805411, 0.52480277, 0.49287872,\n",
       "        0.50729417, 0.48961374, 0.48375864, 0.52860672, 0.53844235,\n",
       "        0.52064479, 0.52608931, 0.52480277, 0.4702451 , 0.53188856,\n",
       "        0.51057026, 0.49841621, 0.53400523, 0.53623263, 0.49686204,\n",
       "        0.51125578, 0.47169076, 0.50925218, 0.51504215, 0.48866303,\n",
       "        0.51683053, 0.53502131, 0.53457801, 0.51920329, 0.50857955,\n",
       "        0.50050978, 0.50294172, 0.5021033 , 0.46090427, 0.48129235,\n",
       "        0.52989204, 0.53742517, 0.51923534, 0.52210419, 0.52958232,\n",
       "        0.49094121, 0.50534494, 0.51422734, 0.51206003, 0.51656235,\n",
       "        0.52197734, 0.5191876 , 0.5       , 0.5       , 0.5       ,\n",
       "        0.49668543, 0.50249032, 0.54156665, 0.5415607 , 0.53351578,\n",
       "        0.54049057, 0.5       , 0.5       , 0.5       , 0.54124543,\n",
       "        0.53558476, 0.52025175, 0.54159048, 0.53337812, 0.54611112,\n",
       "        0.5       , 0.5       , 0.49989224, 0.53164843, 0.54156665,\n",
       "        0.5       , 0.54161155, 0.54857141, 0.5072943 , 0.5       ,\n",
       "        0.5       , 0.4927118 , 0.50250947, 0.51039524, 0.49812499,\n",
       "        0.53355784, 0.5356036 , 0.4923582 , 0.5       , 0.5       ,\n",
       "        0.50236477, 0.53558327, 0.54348623, 0.54158461, 0.50644692,\n",
       "        0.53315324, 0.48414778, 0.5       , 0.5       , 0.50262495,\n",
       "        0.51039524, 0.47828065, 0.54156665, 0.542841  , 0.50501924,\n",
       "        0.49235521, 0.5       , 0.48891506, 0.49094312, 0.54156665,\n",
       "        0.54156365, 0.5335309 , 0.55493292, 0.48820872, 0.49555212,\n",
       "        0.5       , 0.49552259, 0.53558474, 0.48848408, 0.54160855,\n",
       "        0.5077324 , 0.55236995, 0.49332464, 0.48916925, 0.5       ,\n",
       "        0.50129509, 0.54156665, 0.5       , 0.49814867, 0.53127708,\n",
       "        0.5194184 , 0.48820576, 0.4923582 , 0.51869935, 0.50769998,\n",
       "        0.52231879, 0.51214857, 0.51877126, 0.49700612, 0.50585156,\n",
       "        0.51573399, 0.5160295 , 0.47237055, 0.47213112, 0.5211917 ,\n",
       "        0.50192851, 0.52274996, 0.47875143, 0.50677561, 0.5068787 ,\n",
       "        0.50489541, 0.49964251, 0.50035749, 0.48753318, 0.49799056,\n",
       "        0.48742087, 0.486517  , 0.48826147, 0.51347118, 0.49254396,\n",
       "        0.50434352, 0.50917343, 0.4786684 , 0.47869205, 0.50014732,\n",
       "        0.50815904, 0.50405824, 0.50739792, 0.50815904, 0.51922055,\n",
       "        0.49417584, 0.51860285, 0.49417584, 0.49198662, 0.46918216,\n",
       "        0.51879495, 0.4803184 , 0.50753165, 0.48605924, 0.50536101,\n",
       "        0.49396815, 0.49468628, 0.49506408, 0.50610869, 0.51408853,\n",
       "        0.48359142, 0.50531372, 0.48534051, 0.51471269, 0.51470371,\n",
       "        0.48320087, 0.51684922, 0.48942404, 0.50675064, 0.51457969,\n",
       "        0.52257426, 0.51841263, 0.5084589 , 0.51319062, 0.47922563,\n",
       "        0.49324936, 0.50827271, 0.50710745, 0.48545577, 0.48320102,\n",
       "        0.51478658, 0.47745825, 0.48168191, 0.52254175, 0.49332029,\n",
       "        0.51186925, 0.51034718, 0.52254175, 0.48951983]),\n",
       " 'std_test_roc_auc_ovo': array([0.04643737, 0.04031701, 0.        , 0.02955767, 0.02138099,\n",
       "        0.03386797, 0.02830045, 0.03612123, 0.02653314, 0.04265768,\n",
       "        0.01907461, 0.02712099, 0.04183677, 0.03022815, 0.0503478 ,\n",
       "        0.0216354 , 0.02566354, 0.02113639, 0.02254812, 0.02511485,\n",
       "        0.04079533, 0.03554008, 0.04162307, 0.03964826, 0.01508288,\n",
       "        0.0186104 , 0.02019018, 0.03654846, 0.03381263, 0.04288583,\n",
       "        0.03508627, 0.02625319, 0.03278012, 0.02626919, 0.01587607,\n",
       "        0.02001638, 0.0326024 , 0.03381263, 0.04393273, 0.01655632,\n",
       "        0.0183075 , 0.03154633, 0.01859347, 0.01682789, 0.01803101,\n",
       "        0.02622515, 0.03062471, 0.02395992, 0.05099615, 0.01241538,\n",
       "        0.02462343, 0.0462043 , 0.02920117, 0.01892613, 0.02795878,\n",
       "        0.03375443, 0.04365159, 0.01548612, 0.01524941, 0.03328688,\n",
       "        0.03731665, 0.01950091, 0.01855557, 0.02454882, 0.03569134,\n",
       "        0.04176128, 0.04983535, 0.01426848, 0.04451478, 0.0256528 ,\n",
       "        0.01915376, 0.01834866, 0.02495076, 0.02560015, 0.02689688,\n",
       "        0.03575419, 0.02586732, 0.00899683, 0.02381119, 0.01930674,\n",
       "        0.01854247, 0.0347391 , 0.03190711, 0.03630268, 0.00783373,\n",
       "        0.04090507, 0.01509494, 0.00665685, 0.03066402, 0.02398951,\n",
       "        0.03540738, 0.02049071, 0.02046076, 0.04439939, 0.04090507,\n",
       "        0.03871824, 0.04034033, 0.02485309, 0.02569276, 0.03999913,\n",
       "        0.00419382, 0.03227818, 0.0388997 , 0.0450438 , 0.0270553 ,\n",
       "        0.07001037, 0.03592609, 0.02503013, 0.0174709 , 0.03550796,\n",
       "        0.02227342, 0.05442701, 0.0238587 , 0.03315344, 0.02989732,\n",
       "        0.03228117, 0.02366509, 0.04633306, 0.04101271, 0.03168086,\n",
       "        0.03193475, 0.03212498, 0.03905364, 0.02932201, 0.02339248,\n",
       "        0.02109023, 0.0383391 , 0.04101271, 0.01772669, 0.04263007,\n",
       "        0.02045075, 0.04226785, 0.03805418, 0.02609198, 0.02599138,\n",
       "        0.04498718, 0.04465888, 0.04594928, 0.03316236, 0.03782   ,\n",
       "        0.02711625, 0.03969468, 0.02302669, 0.02694899, 0.03659384,\n",
       "        0.03995247, 0.01510582, 0.02345496, 0.03282414, 0.04408464,\n",
       "        0.05360174, 0.03289073, 0.02676834, 0.02897261, 0.0390842 ,\n",
       "        0.0250305 , 0.03107532, 0.05467509, 0.01913888, 0.02514213,\n",
       "        0.02688017, 0.02677734, 0.        , 0.        , 0.        ,\n",
       "        0.0343821 , 0.06342242, 0.04504441, 0.04505037, 0.03551866,\n",
       "        0.0429395 , 0.        , 0.        , 0.        , 0.04309538,\n",
       "        0.04167722, 0.04436172, 0.04502128, 0.02673169, 0.03118857,\n",
       "        0.        , 0.        , 0.00021552, 0.03293138, 0.04504441,\n",
       "        0.        , 0.0450053 , 0.03372157, 0.06386313, 0.        ,\n",
       "        0.        , 0.02480348, 0.06342851, 0.06040466, 0.06126439,\n",
       "        0.03540156, 0.03725093, 0.01940709, 0.        , 0.        ,\n",
       "        0.06043757, 0.0416746 , 0.04298033, 0.04502874, 0.0408865 ,\n",
       "        0.02194678, 0.01356699, 0.        , 0.        , 0.04575285,\n",
       "        0.06040466, 0.0434387 , 0.04504441, 0.03327683, 0.06336878,\n",
       "        0.01941021, 0.        , 0.01721937, 0.06284527, 0.04504441,\n",
       "        0.04504702, 0.03544302, 0.03486899, 0.01777985, 0.0203765 ,\n",
       "        0.        , 0.05280367, 0.04167504, 0.06009216, 0.0450079 ,\n",
       "        0.04227216, 0.03509958, 0.0202632 , 0.0178249 , 0.        ,\n",
       "        0.04517592, 0.04504441, 0.        , 0.06125682, 0.02323524,\n",
       "        0.06735151, 0.01777961, 0.01940709, 0.03173306, 0.03601893,\n",
       "        0.02929561, 0.03487299, 0.03176347, 0.03671195, 0.03628878,\n",
       "        0.03330307, 0.03335829, 0.03902108, 0.039167  , 0.04271472,\n",
       "        0.04789275, 0.04231113, 0.04311355, 0.04758147, 0.04753974,\n",
       "        0.0478371 , 0.0299784 , 0.0299784 , 0.02726556, 0.02980726,\n",
       "        0.0273575 , 0.02677762, 0.02757088, 0.02678835, 0.02903859,\n",
       "        0.02904629, 0.02722445, 0.01904153, 0.01911387, 0.0284489 ,\n",
       "        0.02738306, 0.02819742, 0.02761162, 0.02738306, 0.03787279,\n",
       "        0.04206967, 0.03817916, 0.04206967, 0.04173113, 0.02922857,\n",
       "        0.03807385, 0.03764027, 0.04178651, 0.01835959, 0.02263543,\n",
       "        0.02248755, 0.02261269, 0.02273191, 0.022411  , 0.01846842,\n",
       "        0.01643875, 0.02261269, 0.02687275, 0.02687528, 0.02687667,\n",
       "        0.02565218, 0.02562939, 0.02894163, 0.029886  , 0.02694766,\n",
       "        0.02074669, 0.02457649, 0.02934909, 0.02765414, 0.0223511 ,\n",
       "        0.029886  , 0.02950096, 0.02976848, 0.0269881 , 0.02562126,\n",
       "        0.0268795 , 0.02075124, 0.02456134, 0.02075124, 0.02994875,\n",
       "        0.02824651, 0.02883886, 0.02075124, 0.0287908 ]),\n",
       " 'rank_test_roc_auc_ovo': array([324, 283, 197, 262, 318, 321, 116,  19,  16, 306,  93, 162, 166,\n",
       "        313, 264, 222,  17,   8, 279, 224, 319,  73, 233, 263,  37,  13,\n",
       "          3, 144, 220, 298, 180, 126,  79,  30,  14,   2, 296, 220, 104,\n",
       "        308, 271,  20,  21,  15,   1, 309, 236, 148, 242,  36,  72,  23,\n",
       "          9,   7, 244, 164,  77, 312,  18,  24,  81,  11,   4, 108, 219,\n",
       "        303, 259,  26, 195, 194,  10,   5,  75, 287, 230, 243, 254,  80,\n",
       "        140,  12,   6, 176, 163, 229, 174, 101, 320, 314,  29, 169, 237,\n",
       "        286, 139,  66, 101, 282, 111,  28, 132, 189, 187, 235, 323, 190,\n",
       "        134, 141,  32, 112, 178, 317, 305, 270, 103,  60,  33,  50, 154,\n",
       "        227,  83, 251, 157, 265, 289,  78,  52,  94,  82,  83, 315,  69,\n",
       "        135, 223,  62,  54, 232, 133, 311, 142, 119, 272, 114,  59,  61,\n",
       "         99, 145, 192, 181, 186, 322, 294,  74,  53,  97,  90,  76, 261,\n",
       "        171, 124, 130, 115,  91, 100, 197, 197, 197, 234, 184,  42,  48,\n",
       "         65,  51, 197, 197, 197,  49,  56,  95,  40,  67,  31, 197, 197,\n",
       "        217,  70,  42, 197,  38,  27, 156, 197, 197, 252, 183, 136, 226,\n",
       "         63,  55, 255, 197, 197, 185,  58,  34,  41, 165,  68, 288, 197,\n",
       "        197, 182, 137, 302,  42,  35, 173, 257, 197, 269, 260,  42,  47,\n",
       "         64,  22, 275, 238, 197, 239,  57, 273,  39, 151,  25, 248, 268,\n",
       "        197, 191,  42, 197, 225,  71,  96, 276, 255, 107, 152,  89, 129,\n",
       "        106, 231, 168, 118, 117, 307, 310,  92, 188,  85, 299, 160, 159,\n",
       "        175, 218, 193, 277, 228, 278, 280, 274, 127, 253, 177, 143, 301,\n",
       "        300, 196, 149, 179, 155, 149,  98, 245, 109, 245, 258, 316, 105,\n",
       "        295, 153, 281, 170, 247, 241, 240, 167, 125, 290, 172, 285, 121,\n",
       "        122, 292, 113, 267, 161, 123,  86, 110, 146, 128, 297, 250, 147,\n",
       "        158, 284, 291, 120, 304, 293,  87, 249, 131, 138,  87, 266]),\n",
       " 'split0_test_neg_log_loss': array([-0.25878609, -0.25878612, -0.25878876, -0.25879033, -0.25893425,\n",
       "        -0.25885128, -0.25875609, -0.25467941, -0.24613352, -0.258786  ,\n",
       "        -0.25878876, -0.25884759, -0.25882132, -0.25882187, -0.25884044,\n",
       "        -0.26464953, -0.25067321, -0.23644864, -0.25877933, -0.25874758,\n",
       "        -0.25871236, -0.25880445, -0.2588015 , -0.25841102, -0.25923419,\n",
       "        -0.25141164, -0.23657867, -0.25882639, -0.25886874, -0.25889429,\n",
       "        -0.25895554, -0.25880072, -0.25707061, -0.25788823, -0.25083488,\n",
       "        -0.23599834, -0.25895235, -0.25901742, -0.25912767, -0.25897055,\n",
       "        -0.25932157, -0.25737423, -0.25742843, -0.2509436 , -0.23470137,\n",
       "        -0.25886876, -0.2578687 , -0.25858143, -0.25917369, -0.25936403,\n",
       "        -0.26315931, -0.25675412, -0.25032546, -0.23477146, -0.25885791,\n",
       "        -0.25898646, -0.25867618, -0.25966923, -0.25713999, -0.25773747,\n",
       "        -0.26163923, -0.25175771, -0.2346997 , -0.25877392, -0.25899503,\n",
       "        -0.25944927, -0.25882242, -0.25967042, -6.7220061 , -0.25963452,\n",
       "        -0.25312208, -0.23473574, -0.25869367, -0.25879375, -0.2590032 ,\n",
       "        -0.25878637, -0.28657938, -0.25870016, -0.25896851, -0.2518065 ,\n",
       "        -0.23472577, -0.25878607, -0.25878634, -0.25878876, -0.25878503,\n",
       "        -0.25876086, -0.25888319, -0.25927689, -0.25880804, -0.25897192,\n",
       "        -0.25878626, -0.25888113, -0.25878876, -0.25891074, -0.25871244,\n",
       "        -0.25901594, -0.25997573, -0.25827158, -0.25908932, -0.25878876,\n",
       "        -0.25878876, -0.25890414, -0.25881061, -0.25874777, -0.2587355 ,\n",
       "        -0.25876171, -0.25845016, -0.26025676, -0.25878876, -0.25882173,\n",
       "        -0.25908822, -0.25900262, -0.25880274, -0.25878451, -0.25813492,\n",
       "        -0.25755429, -0.2587734 , -0.25894402, -0.25895638, -0.2594039 ,\n",
       "        -0.25936204, -0.25852488, -0.25880703, -0.25883315, -0.25835601,\n",
       "        -0.26123735, -0.25901323, -0.25888783, -0.25892238, -0.25880531,\n",
       "        -0.2591709 , -0.25906315, -0.25896106, -0.25717181, -0.2588704 ,\n",
       "        -0.25885499, -0.25878924, -0.25910297, -0.25879181, -0.2616091 ,\n",
       "        -0.2585785 , -0.26282331, -0.25719522, -0.25965787, -0.25863915,\n",
       "        -0.2588021 , -0.25883059, -0.25880474, -0.25887001, -0.25812827,\n",
       "        -0.25873787, -0.25817304, -0.25992819, -0.25867933, -0.25933545,\n",
       "        -0.25876531, -0.25900803, -0.25869204, -0.25879325, -0.2581929 ,\n",
       "        -0.25759762, -0.26144187, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25914337, -0.2617188 ,\n",
       "        -0.25895073, -0.25878607, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25892558, -0.25926898, -0.25968721, -0.25919833,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878876, -0.25954172, -0.2587997 , -0.25942507, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25878608, -0.25884305,\n",
       "        -0.26059788, -0.25895304, -0.25911095, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25899575, -0.2596472 , -0.26017292,\n",
       "        -0.25862789, -0.25991169, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25878876, -0.25966277, -0.25943905, -0.26029137,\n",
       "        -0.25938974, -0.25878607, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25910581, -0.26134677, -0.25865441, -0.25960642, -0.25869689,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25920886, -0.25913389,\n",
       "        -0.25932296, -0.25860492, -0.25932192, -0.25953505, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25878876, -0.25937507, -0.25911066,\n",
       "        -0.25927738, -0.25898833, -0.25931036, -0.258631  , -0.25866642,\n",
       "        -0.25898111, -0.25847398, -0.25843086, -0.25846188, -0.25846255,\n",
       "        -0.25945807, -0.25995464, -0.25858284, -0.25848782, -0.26262219,\n",
       "        -0.25992773, -0.25884068, -0.25858356, -0.25902836, -0.25857737,\n",
       "        -0.25875303, -0.25871085, -0.25890516, -0.25869034, -0.25875061,\n",
       "        -0.25870703, -0.25890171, -0.25905979, -0.25870844, -0.25880424,\n",
       "        -0.25879932, -0.25902299, -0.25883971, -0.25889972, -0.2591156 ,\n",
       "        -0.25875794, -0.25876008, -0.25875779, -0.25877783, -0.25883375,\n",
       "        -0.25892729, -0.25880374, -0.25880826, -0.25892731, -0.25879455,\n",
       "        -0.25884201, -0.25878913, -0.25877652, -0.25911047, -0.25848685,\n",
       "        -0.2587841 , -0.25889467, -0.25883098, -0.25927712, -0.25852006,\n",
       "        -0.25904266, -0.25835714, -0.25889067, -0.25880822, -0.25899494,\n",
       "        -0.25880309, -0.25879268, -0.25904035, -0.25878885, -0.25878949,\n",
       "        -0.25881268, -0.25897651, -0.25882374, -0.25879867, -0.2588393 ,\n",
       "        -0.25878964, -0.25892677, -0.25899585, -0.25878789, -0.25885695,\n",
       "        -0.2588087 , -0.25879107, -0.25889074, -0.25878785, -0.25878602,\n",
       "        -0.25878972, -0.25884373, -0.25886963, -0.25892733]),\n",
       " 'split1_test_neg_log_loss': array([-0.25878608, -0.25878608, -0.25878876, -0.25888069, -0.25882043,\n",
       "        -0.25893936, -0.25869835, -0.25585679, -0.23848617, -0.2587877 ,\n",
       "        -0.25873353, -0.25878605, -0.25854997, -0.25876556, -0.25908019,\n",
       "        -0.26364879, -0.25752434, -0.23502346, -0.2589683 , -0.25878876,\n",
       "        -0.25902239, -0.25873172, -0.25872351, -0.26114998, -0.25834086,\n",
       "        -0.25400039, -0.23490401, -0.25878876, -0.25858823, -0.25865271,\n",
       "        -0.25920524, -0.2585716 , -0.26317895, -0.26029418, -0.2540998 ,\n",
       "        -0.23463878, -0.25890674, -0.25857501, -0.2585975 , -0.25884982,\n",
       "        -0.2626588 , -0.26124936, -0.25821844, -0.25408313, -0.23063173,\n",
       "        -0.25938538, -0.25890416, -0.25848081, -0.25884454, -0.26041156,\n",
       "        -0.26082349, -0.26675018, -0.25617078, -0.23084293, -0.25880324,\n",
       "        -0.25868301, -0.25765429, -0.25982525, -0.25854429, -0.2562785 ,\n",
       "        -0.28421878, -0.25481867, -0.23048309, -0.25858355, -0.25854903,\n",
       "        -0.26396129, -0.2580464 , -0.25715541, -3.4769051 , -0.25888332,\n",
       "        -0.25479985, -0.2310411 , -0.25780328, -0.25881252, -0.25880681,\n",
       "        -0.26136584, -0.3940143 , -0.25852254, -0.25878895, -0.25486829,\n",
       "        -0.23089662, -0.25878607, -0.25878608, -0.25882392, -0.25878876,\n",
       "        -0.25885529, -0.25966303, -0.25962049, -0.25797716, -0.26134317,\n",
       "        -0.25878612, -0.25878876, -0.25878876, -0.25874206, -0.2595447 ,\n",
       "        -0.25874471, -0.25862292, -0.25822762, -0.25859276, -0.25911791,\n",
       "        -0.25878876, -0.25890696, -0.25890652, -0.25906068, -0.25939673,\n",
       "        -0.2584143 , -0.26012287, -0.2589182 , -0.25878876, -0.25897647,\n",
       "        -0.25881095, -0.2592044 , -0.2587247 , -0.25869824, -0.25897308,\n",
       "        -0.25906542, -0.25942696, -0.25895623, -0.2587499 , -0.25878449,\n",
       "        -0.25824815, -0.25888623, -0.26056302, -0.26021678, -0.25868677,\n",
       "        -0.25906511, -0.25878551, -0.25877335, -0.26038902, -0.25862937,\n",
       "        -0.25883388, -0.25970839, -0.26143483, -0.26027595, -0.25889561,\n",
       "        -0.25868221, -0.25904038, -0.25910721, -0.25762974, -0.25884299,\n",
       "        -0.2579159 , -0.26087742, -0.25777739, -0.26008179, -0.26019275,\n",
       "        -0.25885657, -0.25878472, -0.25855969, -0.25882355, -0.25912383,\n",
       "        -0.25601187, -0.2609384 , -0.25977592, -0.25870146, -0.25895399,\n",
       "        -0.25927727, -0.25855224, -0.25706316, -0.25886489, -0.25803606,\n",
       "        -0.26113917, -0.25886727, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25878602, -0.25804626, -0.25861471,\n",
       "        -0.25710651, -0.25878607, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25836299, -0.25787895, -0.25863721, -0.25741635,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25878607, -0.25878606,\n",
       "        -0.25878876, -0.25808666, -0.25751102, -0.26159203, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25878598, -0.25960023,\n",
       "        -0.25859804, -0.25688528, -0.26007936, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25811406, -0.25798796, -0.2583929 ,\n",
       "        -0.25781362, -0.25893372, -0.25878607, -0.25878607, -0.25878607,\n",
       "        -0.25878607, -0.2587949 , -0.25797676, -0.25725458, -0.25970112,\n",
       "        -0.25970351, -0.25878607, -0.25878607, -0.25878607, -0.25878563,\n",
       "        -0.25824764, -0.25865798, -0.25674013, -0.25933722, -0.25944705,\n",
       "        -0.25878607, -0.25878607, -0.25878607, -0.25878783, -0.25851381,\n",
       "        -0.25848659, -0.25669862, -0.25985965, -0.25935026, -0.25878607,\n",
       "        -0.25878607, -0.25878607, -0.25878876, -0.26018407, -0.25805565,\n",
       "        -0.26767636, -0.25899546, -0.25994449, -0.25869186, -0.25880977,\n",
       "        -0.25875174, -0.25863812, -0.25824065, -0.25872089, -0.25879507,\n",
       "        -0.25871243, -0.2585569 , -0.25891501, -0.25965103, -0.25629849,\n",
       "        -0.25871156, -0.25787747, -0.25892443, -0.25729537, -0.25854765,\n",
       "        -0.26049573, -0.25875226, -0.25927386, -0.25901167, -0.26013798,\n",
       "        -0.25962691, -0.25895745, -0.25874653, -0.25852135, -0.25871643,\n",
       "        -0.25877617, -0.25864842, -0.25885875, -0.25899148, -0.25888935,\n",
       "        -0.25856225, -0.25886101, -0.25880552, -0.25860123, -0.25809249,\n",
       "        -0.25840281, -0.25857414, -0.25839949, -0.26038194, -0.25890664,\n",
       "        -0.25868663, -0.25966766, -0.25873946, -0.25922329, -0.25864748,\n",
       "        -0.25880374, -0.2588237 , -0.25877196, -0.25876727, -0.25876452,\n",
       "        -0.25880155, -0.25875183, -0.25907371, -0.2581639 , -0.25847666,\n",
       "        -0.25988183, -0.25835232, -0.26050375, -0.25828877, -0.25841057,\n",
       "        -0.25831304, -0.25866562, -0.25853466, -0.25837485, -0.25937758,\n",
       "        -0.25911724, -0.25839779, -0.25876632, -0.25881355, -0.25893385,\n",
       "        -0.25841486, -0.25921725, -0.2590055 , -0.25803451, -0.25887972,\n",
       "        -0.2587156 , -0.25854324, -0.25861024, -0.25932137]),\n",
       " 'split2_test_neg_log_loss': array([-0.26133263, -0.26133265, -0.26133139, -0.26146344, -0.26136849,\n",
       "        -0.26160763, -0.26093802, -0.26122991, -0.22793568, -0.26133333,\n",
       "        -0.2612999 , -0.26120012, -0.26140865, -0.26162283, -0.2611217 ,\n",
       "        -0.26163899, -0.25400891, -0.22354112, -0.26133139, -0.26133139,\n",
       "        -0.26148187, -0.26101962, -0.26104937, -0.26128605, -0.25975018,\n",
       "        -0.25174517, -0.22357492, -0.2610714 , -0.26128438, -0.26136268,\n",
       "        -0.26134329, -0.26138627, -0.26099241, -0.26036537, -0.24957012,\n",
       "        -0.22374775, -0.26281191, -0.26119259, -0.26112437, -0.26218177,\n",
       "        -0.26212819, -0.2597889 , -0.26054879, -0.25119493, -0.221028  ,\n",
       "        -0.26194384, -0.26163171, -0.2613173 , -0.2606165 , -0.25999828,\n",
       "        -0.26297646, -0.25971992, -0.25581717, -0.2201619 , -0.26163878,\n",
       "        -0.26292787, -0.26050972, -0.2618877 , -0.25824583, -0.26031723,\n",
       "        -0.27166015, -0.25542085, -0.22017295, -0.26147703, -0.26355194,\n",
       "        -0.26124873, -0.26295734, -0.26090973, -4.52875521, -0.26060109,\n",
       "        -0.25629982, -0.22028042, -0.26117298, -0.26135572, -0.26288513,\n",
       "        -0.26099258, -0.42402299, -0.26116502, -0.26065265, -0.25621365,\n",
       "        -0.22007502, -0.26133263, -0.26133261, -0.26132651, -0.26133139,\n",
       "        -0.2612688 , -0.26139629, -0.26140068, -0.25977383, -0.26175565,\n",
       "        -0.26133264, -0.26136613, -0.26104274, -0.26113186, -0.26124838,\n",
       "        -0.26141561, -0.26132645, -0.2588734 , -0.26099665, -0.26133163,\n",
       "        -0.26133139, -0.26132793, -0.2617782 , -0.26124965, -0.26106654,\n",
       "        -0.2625743 , -0.25972332, -0.26103764, -0.26103747, -0.26137594,\n",
       "        -0.26168468, -0.26131561, -0.26124386, -0.26122362, -0.26072719,\n",
       "        -0.2587798 , -0.26102897, -0.26127237, -0.26127441, -0.26137587,\n",
       "        -0.26111928, -0.26193226, -0.26150947, -0.25995298, -0.26008287,\n",
       "        -0.2604753 , -0.2612054 , -0.26128315, -0.26149741, -0.26096783,\n",
       "        -0.2609191 , -0.26078998, -0.26129291, -0.26069371, -0.26090785,\n",
       "        -0.26146617, -0.26193376, -0.26123711, -0.26133492, -0.26142197,\n",
       "        -0.26079218, -0.26026816, -0.26111207, -0.26088275, -0.26118524,\n",
       "        -0.26121685, -0.26132594, -0.26150302, -0.26142557, -0.26114643,\n",
       "        -0.26013675, -0.26011311, -0.26100174, -0.2612067 , -0.26122542,\n",
       "        -0.26196413, -0.2613123 , -0.26150211, -0.26079783, -0.26148631,\n",
       "        -0.26049175, -0.26111369, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133255, -0.26116562, -0.26053789,\n",
       "        -0.26010702, -0.26133263, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133139, -0.26107829, -0.26052379, -0.25912354,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133139, -0.26111535, -0.26027358, -0.25912884, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.2613325 , -0.26109309,\n",
       "        -0.26073678, -0.26131369, -0.26178003, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26131616, -0.26097713, -0.26252238,\n",
       "        -0.260548  , -0.26196159, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133139, -0.26108108, -0.26029606, -0.25904876,\n",
       "        -0.26134628, -0.26133263, -0.26133263, -0.26133263, -0.26133249,\n",
       "        -0.26114849, -0.26081271, -0.26092617, -0.26134193, -0.26183306,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133139, -0.26105471,\n",
       "        -0.26212822, -0.25839539, -0.26152316, -0.26133896, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133139, -0.26114002, -0.26090399,\n",
       "        -0.25924568, -0.26133733, -0.26139815, -0.26188002, -0.26132299,\n",
       "        -0.26130197, -0.26142861, -0.26185738, -0.26363754, -0.26188177,\n",
       "        -0.26131461, -0.26131568, -0.2620786 , -0.26153489, -0.26128338,\n",
       "        -0.26163681, -0.26158739, -0.26141795, -0.26140964, -0.26199823,\n",
       "        -0.26131308, -0.26141838, -0.26129035, -0.26128369, -0.26139552,\n",
       "        -0.26133207, -0.26129832, -0.26197932, -0.26218762, -0.26132579,\n",
       "        -0.26154955, -0.26136015, -0.26127331, -0.26128907, -0.26127604,\n",
       "        -0.26127582, -0.26146764, -0.26131069, -0.26132888, -0.26083732,\n",
       "        -0.26145155, -0.26087385, -0.26143459, -0.26115423, -0.26218468,\n",
       "        -0.2613322 , -0.26259506, -0.26155437, -0.26237093, -0.26126933,\n",
       "        -0.26124628, -0.26136746, -0.26127799, -0.26147291, -0.26130549,\n",
       "        -0.26125525, -0.26125185, -0.26210471, -0.26122987, -0.26123233,\n",
       "        -0.26208687, -0.26126258, -0.26142066, -0.26146874, -0.26148007,\n",
       "        -0.26125674, -0.26129301, -0.26202682, -0.26125741, -0.262351  ,\n",
       "        -0.26123675, -0.26138162, -0.26203639, -0.26126977, -0.26140003,\n",
       "        -0.2612413 , -0.26141003, -0.26162483, -0.26123766, -0.26125796,\n",
       "        -0.26139961, -0.2614703 , -0.26123583, -0.26147149]),\n",
       " 'split3_test_neg_log_loss': array([-0.26133269, -0.26133262, -0.26133139, -0.26119087, -0.26133361,\n",
       "        -0.26138584, -0.26117617, -0.25873139, -0.23531436, -0.26133262,\n",
       "        -0.26133139, -0.26131148, -0.26106959, -0.26189476, -0.26206096,\n",
       "        -0.26419819, -0.25581443, -0.22403767, -0.26133139, -0.26129308,\n",
       "        -0.2613769 , -0.26102889, -0.26145272, -0.26171639, -0.26064788,\n",
       "        -0.25319864, -0.22364605, -0.2613724 , -0.26136544, -0.26141285,\n",
       "        -0.26100627, -0.26138038, -0.26378394, -0.25943488, -0.25203745,\n",
       "        -0.22368874, -0.26132966, -0.26135278, -0.2615078 , -0.26137875,\n",
       "        -0.26191835, -0.25801147, -0.25904451, -0.25319443, -0.21892923,\n",
       "        -0.26133298, -0.26134402, -0.2622533 , -0.26132283, -0.26005864,\n",
       "        -0.26142652, -0.25813493, -0.25148399, -0.21950204, -0.26060464,\n",
       "        -0.26120664, -0.26251652, -0.26370832, -0.25928449, -0.25969791,\n",
       "        -0.27644383, -0.25484456, -0.21945848, -0.2609231 , -0.26247531,\n",
       "        -0.26124476, -0.26240163, -0.262158  , -9.27074007, -0.26233961,\n",
       "        -0.25491942, -0.21954191, -0.26217113, -0.26182259, -0.26165032,\n",
       "        -0.2637532 , -0.32040167, -0.26079956, -0.26126082, -0.25642176,\n",
       "        -0.21986886, -0.26133263, -0.26133255, -0.26133139, -0.26133139,\n",
       "        -0.26116252, -0.26138767, -0.26187211, -0.25734547, -0.2609628 ,\n",
       "        -0.26133233, -0.26133139, -0.26133139, -0.26133343, -0.26093958,\n",
       "        -0.26147105, -0.2612095 , -0.25954013, -0.2608037 , -0.26130937,\n",
       "        -0.26133139, -0.26135361, -0.26136803, -0.26128263, -0.26150139,\n",
       "        -0.26076881, -0.25858685, -0.26108668, -0.26133139, -0.26140453,\n",
       "        -0.26133338, -0.26140957, -0.26127344, -0.26119827, -0.26027728,\n",
       "        -0.25960219, -0.26129388, -0.26092551, -0.26133575, -0.2613697 ,\n",
       "        -0.2620046 , -0.26130502, -0.26116788, -0.2604123 , -0.26121397,\n",
       "        -0.26058867, -0.26094144, -0.2613657 , -0.26151497, -0.26172303,\n",
       "        -0.26123372, -0.2615065 , -0.26028476, -0.26076989, -0.26222286,\n",
       "        -0.26093439, -0.26133564, -0.26133018, -0.26107963, -0.26335116,\n",
       "        -0.26104668, -0.26030572, -0.26050222, -0.26058365, -0.26163057,\n",
       "        -0.2613182 , -0.26259314, -0.2612648 , -0.26147261, -0.26142402,\n",
       "        -0.26141686, -0.25862391, -0.2604453 , -0.26115653, -0.26126776,\n",
       "        -0.26229722, -0.26304597, -0.26139627, -0.26132248, -0.26168434,\n",
       "        -0.26075067, -0.26013017, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133095, -0.26082218, -0.25889109,\n",
       "        -0.26069984, -0.26133263, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133139, -0.26126572, -0.26057877, -0.26107218,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133139, -0.26093884, -0.26014448, -0.26286814, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133263, -0.26085934,\n",
       "        -0.25920726, -0.26118407, -0.26129439, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26120952, -0.26100195, -0.26062219,\n",
       "        -0.26106792, -0.26135297, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133139, -0.26127407, -0.26088138, -0.26435139,\n",
       "        -0.26137768, -0.26133263, -0.26133263, -0.26133263, -0.2613324 ,\n",
       "        -0.2621211 , -0.25866549, -0.26044396, -0.26133852, -0.26157464,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26131357, -0.2611519 ,\n",
       "        -0.26076423, -0.26060779, -0.26126856, -0.26124395, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133139, -0.26090423, -0.26116065,\n",
       "        -0.26093725, -0.26130427, -0.26126041, -0.26103659, -0.2613027 ,\n",
       "        -0.26128094, -0.26154913, -0.26087139, -0.26179663, -0.26089319,\n",
       "        -0.26122128, -0.2612331 , -0.26366307, -0.26258649, -0.26086309,\n",
       "        -0.26181539, -0.26079524, -0.2621692 , -0.26162618, -0.26200079,\n",
       "        -0.261026  , -0.26136278, -0.26100122, -0.26141957, -0.26117334,\n",
       "        -0.26148743, -0.26096867, -0.26165024, -0.26143634, -0.26175151,\n",
       "        -0.26326554, -0.26093749, -0.26218207, -0.26255108, -0.26091555,\n",
       "        -0.2615739 , -0.26091429, -0.26092134, -0.26165452, -0.26151732,\n",
       "        -0.2615758 , -0.26153324, -0.26159102, -0.26154562, -0.26170042,\n",
       "        -0.26156624, -0.26113347, -0.26112997, -0.26118258, -0.26144342,\n",
       "        -0.26180141, -0.26131971, -0.26133409, -0.26128037, -0.26151153,\n",
       "        -0.26170075, -0.26138443, -0.26127046, -0.26136978, -0.26161647,\n",
       "        -0.26142471, -0.26128745, -0.26130403, -0.26138644, -0.26132329,\n",
       "        -0.26133072, -0.26143045, -0.26156184, -0.26135654, -0.26158395,\n",
       "        -0.26129928, -0.26144403, -0.2615352 , -0.26143658, -0.26141328,\n",
       "        -0.26140764, -0.26151289, -0.26145051, -0.26131695, -0.26142992,\n",
       "        -0.26131812, -0.26127331, -0.26130774, -0.26131042]),\n",
       " 'split4_test_neg_log_loss': array([-0.26133263, -0.26133259, -0.26133139, -0.2613319 , -0.26134721,\n",
       "        -0.26151211, -0.26225137, -0.26175076, -0.23146497, -0.26133181,\n",
       "        -0.26111281, -0.26145888, -0.26136415, -0.26162185, -0.26157294,\n",
       "        -0.26298007, -0.25714005, -0.22846574, -0.26133677, -0.26133903,\n",
       "        -0.26152137, -0.26134271, -0.2622157 , -0.26374391, -0.26053428,\n",
       "        -0.25242799, -0.22871559, -0.26170605, -0.26177828, -0.26132712,\n",
       "        -0.26114062, -0.26075619, -0.26225193, -0.25843713, -0.25215095,\n",
       "        -0.22795233, -0.26184121, -0.26143954, -0.2614017 , -0.26142332,\n",
       "        -0.2613176 , -0.25709525, -0.25933756, -0.25120334, -0.2269327 ,\n",
       "        -0.2619933 , -0.26151655, -0.26128948, -0.26134109, -0.26181363,\n",
       "        -0.26041283, -0.25905113, -0.25382846, -0.22706003, -0.26238956,\n",
       "        -0.26133059, -0.26295048, -0.26156547, -0.2584305 , -0.26147398,\n",
       "        -0.29529011, -0.25402288, -0.22717899, -0.26143118, -0.26151722,\n",
       "        -0.26325415, -0.26178633, -0.25975178, -0.56263652, -0.26320908,\n",
       "        -0.25425931, -0.22683998, -0.26153962, -0.26198527, -0.26253017,\n",
       "        -0.26160909, -0.27406221, -0.26127087, -0.26347623, -0.25459282,\n",
       "        -0.22684519, -0.26133263, -0.26133256, -0.26133139, -0.26141938,\n",
       "        -0.26110632, -0.26154062, -0.26134074, -0.26080001, -0.2619643 ,\n",
       "        -0.26133263, -0.26133139, -0.26133139, -0.26133937, -0.26123944,\n",
       "        -0.26156759, -0.26223458, -0.26076217, -0.26186701, -0.26133139,\n",
       "        -0.26123321, -0.26132611, -0.26133151, -0.26136132, -0.26131336,\n",
       "        -0.26127848, -0.26064352, -0.26210345, -0.26140233, -0.261232  ,\n",
       "        -0.26131318, -0.26133889, -0.26125796, -0.26155837, -0.26066123,\n",
       "        -0.26127923, -0.26254477, -0.26140126, -0.26123912, -0.26131924,\n",
       "        -0.26191557, -0.26131725, -0.26166455, -0.26169873, -0.26013753,\n",
       "        -0.26219886, -0.26143358, -0.26123999, -0.26140021, -0.26118966,\n",
       "        -0.26092942, -0.26138154, -0.26092751, -0.26034539, -0.2617748 ,\n",
       "        -0.2617331 , -0.26133143, -0.26131529, -0.2611865 , -0.26125935,\n",
       "        -0.26136525, -0.26123906, -0.26031777, -0.26144656, -0.26126067,\n",
       "        -0.26228068, -0.26117375, -0.26227608, -0.26171687, -0.26280775,\n",
       "        -0.26242537, -0.26095249, -0.26128105, -0.26144731, -0.26080196,\n",
       "        -0.26160582, -0.2639501 , -0.26112983, -0.26144281, -0.2613568 ,\n",
       "        -0.26173896, -0.26123134, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26186941, -0.26045361,\n",
       "        -0.26196591, -0.26133263, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26134776, -0.26198861, -0.26081914, -0.26168486,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133139, -0.26151625, -0.26173814, -0.26511477, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133267, -0.26212857,\n",
       "        -0.26051324, -0.26227688, -0.26138918, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133139, -0.26165809, -0.26081753,\n",
       "        -0.26167641, -0.26158328, -0.26133263, -0.26133263, -0.26133263,\n",
       "        -0.26133263, -0.26133139, -0.26167697, -0.26136228, -0.26588622,\n",
       "        -0.26155474, -0.26133263, -0.26133263, -0.26133263, -0.26133266,\n",
       "        -0.26169071, -0.26051029, -0.2618497 , -0.2617867 , -0.26222882,\n",
       "        -0.26133263, -0.26133263, -0.26133263, -0.26133139, -0.26181972,\n",
       "        -0.26076795, -0.26175037, -0.26134554, -0.26139623, -0.26133263,\n",
       "        -0.26133263, -0.26133263, -0.26133139, -0.26177111, -0.26183405,\n",
       "        -0.26936868, -0.26249494, -0.26144818, -0.26141856, -0.26136694,\n",
       "        -0.26137358, -0.26129906, -0.26190444, -0.26152682, -0.26134902,\n",
       "        -0.26211207, -0.26133769, -0.26148752, -0.26138194, -0.2613744 ,\n",
       "        -0.26121443, -0.26120262, -0.26124849, -0.26121066, -0.26141053,\n",
       "        -0.26125832, -0.26167545, -0.26107648, -0.26136211, -0.26188952,\n",
       "        -0.26243143, -0.26153839, -0.2614885 , -0.26114386, -0.26141664,\n",
       "        -0.26115479, -0.26200034, -0.26146127, -0.26201918, -0.26161487,\n",
       "        -0.26115541, -0.26132208, -0.2611906 , -0.26125906, -0.26136532,\n",
       "        -0.26135271, -0.26177847, -0.26147915, -0.26151069, -0.26151373,\n",
       "        -0.26189154, -0.26141839, -0.2613381 , -0.26133569, -0.26136308,\n",
       "        -0.26133969, -0.26129256, -0.2614008 , -0.26131335, -0.26129021,\n",
       "        -0.26138637, -0.26142908, -0.26139529, -0.26132128, -0.26132089,\n",
       "        -0.26132514, -0.26141521, -0.26177736, -0.26134669, -0.26143627,\n",
       "        -0.26141716, -0.26141495, -0.26136655, -0.26135603, -0.26132607,\n",
       "        -0.26138716, -0.26132047, -0.26178671, -0.26132684, -0.26143161,\n",
       "        -0.26132342, -0.2613926 , -0.2618514 , -0.2613734 , -0.2613505 ,\n",
       "        -0.26141498, -0.26134633, -0.26132104, -0.26136229]),\n",
       " 'mean_test_neg_log_loss': array([-0.26031402, -0.26031401, -0.26031434, -0.26033145, -0.2603608 ,\n",
       "        -0.26045924, -0.260364  , -0.25844965, -0.23586694, -0.26031429,\n",
       "        -0.26025328, -0.26032082, -0.26024274, -0.26054538, -0.26053525,\n",
       "        -0.26342311, -0.25503219, -0.22950332, -0.26034944, -0.26029997,\n",
       "        -0.26042298, -0.26018548, -0.26044856, -0.26126147, -0.25970148,\n",
       "        -0.25255677, -0.22948385, -0.260353  , -0.26037701, -0.26032993,\n",
       "        -0.26033019, -0.26017903, -0.26145557, -0.25928396, -0.25173864,\n",
       "        -0.22920519, -0.26076837, -0.26031547, -0.26035181, -0.26056084,\n",
       "        -0.2614689 , -0.25870384, -0.25891554, -0.25212389, -0.22644461,\n",
       "        -0.26070485, -0.26025303, -0.26038446, -0.26025973, -0.26032923,\n",
       "        -0.26175972, -0.26008206, -0.25352517, -0.22646767, -0.26045882,\n",
       "        -0.26062691, -0.26046144, -0.2613312 , -0.25832902, -0.25910102,\n",
       "        -0.27785042, -0.25417293, -0.22639864, -0.26023776, -0.26101771,\n",
       "        -0.26183164, -0.26080283, -0.25992907, -4.9122086 , -0.26093352,\n",
       "        -0.25468009, -0.22648783, -0.26027614, -0.26055397, -0.26097513,\n",
       "        -0.26130141, -0.33981611, -0.26009163, -0.26062943, -0.25478061,\n",
       "        -0.22648229, -0.260314  , -0.26031403, -0.2603204 , -0.26033119,\n",
       "        -0.26023076, -0.26057416, -0.26070218, -0.2589409 , -0.26099957,\n",
       "        -0.26031399, -0.26033976, -0.26025661, -0.26029149, -0.26033691,\n",
       "        -0.26044298, -0.26067384, -0.25913498, -0.26026989, -0.26037581,\n",
       "        -0.2602947 , -0.26036375, -0.26043897, -0.26034041, -0.2604027 ,\n",
       "        -0.26035952, -0.25950534, -0.26068055, -0.26026974, -0.26036213,\n",
       "        -0.26044608, -0.26045422, -0.26026054, -0.2602926 , -0.25975474,\n",
       "        -0.25925619, -0.26061359, -0.26029988, -0.26031111, -0.26045064,\n",
       "        -0.26052993, -0.26039313, -0.26074239, -0.26022279, -0.25969543,\n",
       "        -0.26071306, -0.26027583, -0.26031   , -0.2607448 , -0.26026304,\n",
       "        -0.2602174 , -0.26048991, -0.26058021, -0.25985135, -0.2605343 ,\n",
       "        -0.26033418, -0.26048609, -0.26041855, -0.26000452, -0.26129691,\n",
       "        -0.2599397 , -0.26110273, -0.25938094, -0.26053052, -0.26058168,\n",
       "        -0.26049488, -0.26054163, -0.26048167, -0.26046172, -0.26052606,\n",
       "        -0.25974575, -0.25976019, -0.26048644, -0.26023827, -0.26031692,\n",
       "        -0.26078195, -0.26117373, -0.25995668, -0.26024425, -0.26015128,\n",
       "        -0.26034364, -0.26055687, -0.260314  , -0.260314  , -0.260314  ,\n",
       "        -0.260314  , -0.260314  , -0.26031364, -0.26020937, -0.26004322,\n",
       "        -0.259766  , -0.260314  , -0.260314  , -0.260314  , -0.260314  ,\n",
       "        -0.260314  , -0.26025982, -0.26029611, -0.26004922, -0.25969905,\n",
       "        -0.260314  , -0.260314  , -0.260314  , -0.260314  , -0.260314  ,\n",
       "        -0.26031434, -0.26023976, -0.25969338, -0.26162577, -0.260314  ,\n",
       "        -0.260314  , -0.260314  , -0.260314  , -0.26031397, -0.26050485,\n",
       "        -0.25993064, -0.26012259, -0.26073078, -0.260314  , -0.260314  ,\n",
       "        -0.260314  , -0.260314  , -0.26019338, -0.26025447, -0.26050558,\n",
       "        -0.25994677, -0.26074865, -0.260314  , -0.260314  , -0.260314  ,\n",
       "        -0.260314  , -0.26031557, -0.26033433, -0.25984667, -0.26185577,\n",
       "        -0.26067439, -0.260314  , -0.260314  , -0.260314  , -0.26031385,\n",
       "        -0.26046275, -0.25999865, -0.25972287, -0.26068216, -0.26075609,\n",
       "        -0.260314  , -0.260314  , -0.260314  , -0.26039461, -0.26033481,\n",
       "        -0.26029399, -0.25921142, -0.26066377, -0.26057289, -0.260314  ,\n",
       "        -0.260314  , -0.260314  , -0.26031434, -0.2606749 , -0.260213  ,\n",
       "        -0.26330107, -0.26062407, -0.26067232, -0.26033161, -0.26029377,\n",
       "        -0.26033787, -0.26027778, -0.26026094, -0.26082875, -0.26027632,\n",
       "        -0.26056369, -0.2604796 , -0.26094541, -0.26072843, -0.26048831,\n",
       "        -0.26066118, -0.26006068, -0.26046872, -0.26011404, -0.26050691,\n",
       "        -0.26056923, -0.26038394, -0.26030941, -0.26035347, -0.2606694 ,\n",
       "        -0.26071698, -0.26033291, -0.26058487, -0.26039952, -0.26040292,\n",
       "        -0.26070907, -0.26039387, -0.26052302, -0.26075011, -0.26036228,\n",
       "        -0.26026506, -0.26026502, -0.26019719, -0.2603243 , -0.26012924,\n",
       "        -0.26034203, -0.26031269, -0.2603425 , -0.26070396, -0.26062   ,\n",
       "        -0.26046372, -0.26072074, -0.26030768, -0.26064459, -0.26024203,\n",
       "        -0.26039504, -0.26033962, -0.26032316, -0.2604222 , -0.26027836,\n",
       "        -0.26043732, -0.26023487, -0.26054697, -0.26017861, -0.26032826,\n",
       "        -0.26070433, -0.26022205, -0.26080923, -0.2602559 , -0.26028794,\n",
       "        -0.26022607, -0.26035611, -0.26046272, -0.2602287 , -0.26069558,\n",
       "        -0.26036601, -0.26029414, -0.26062409, -0.26032693, -0.26040715,\n",
       "        -0.26023919, -0.26046477, -0.2605646 , -0.26015007, -0.26034082,\n",
       "        -0.26032761, -0.26029538, -0.26026889, -0.26047858]),\n",
       " 'std_test_neg_log_loss': array([1.24755871e-03, 1.24753683e-03, 1.24562932e-03, 1.22479987e-03,\n",
       "        1.21182300e-03, 1.27917829e-03, 1.40791239e-03, 2.81581900e-03,\n",
       "        6.24260632e-03, 1.24715288e-03, 1.22073432e-03, 1.23090940e-03,\n",
       "        1.27956958e-03, 1.43378754e-03, 1.32197619e-03, 1.05215435e-03,\n",
       "        2.50254099e-03, 5.38901002e-03, 1.20632336e-03, 1.25087282e-03,\n",
       "        1.27479804e-03, 1.16335748e-03, 1.42693418e-03, 1.70338429e-03,\n",
       "        8.55715571e-04, 9.46852196e-04, 5.46443466e-03, 1.27776466e-03,\n",
       "        1.35930092e-03, 1.27340326e-03, 1.02912011e-03, 1.24236240e-03,\n",
       "        2.38612319e-03, 9.87720901e-04, 1.50689280e-03, 5.24319278e-03,\n",
       "        1.57516543e-03, 1.25084206e-03, 1.23381989e-03, 1.37817789e-03,\n",
       "        1.15641225e-03, 1.58062212e-03, 1.05448557e-03, 1.27185814e-03,\n",
       "        5.86114172e-03, 1.31924146e-03, 1.56153565e-03, 1.55284238e-03,\n",
       "        1.05915809e-03, 8.15424502e-04, 1.11722530e-03, 3.47920151e-03,\n",
       "        2.31296781e-03, 5.94523936e-03, 1.44534739e-03, 1.58716379e-03,\n",
       "        2.07307665e-03, 1.48628942e-03, 6.91415056e-04, 1.85969011e-03,\n",
       "        1.13824364e-02, 1.28694899e-03, 5.88428948e-03, 1.28910593e-03,\n",
       "        1.94843773e-03, 1.60741182e-03, 1.98420278e-03, 1.65658569e-03,\n",
       "        2.94611858e+00, 1.62212730e-03, 1.02952330e-03, 5.92725730e-03,\n",
       "        1.70943899e-03, 1.44442694e-03, 1.73852009e-03, 1.58309282e-03,\n",
       "        5.92670014e-02, 1.22001608e-03, 1.71169729e-03, 1.65137930e-03,\n",
       "        5.87134620e-03, 1.24755239e-03, 1.24745673e-03, 1.23627109e-03,\n",
       "        1.26132238e-03, 1.16316866e-03, 1.09190528e-03, 1.04555173e-03,\n",
       "        1.23627709e-03, 1.07080769e-03, 1.24744785e-03, 1.22908962e-03,\n",
       "        1.20311835e-03, 1.19976030e-03, 1.02713750e-03, 1.27970531e-03,\n",
       "        1.25238698e-03, 9.43302741e-04, 1.23048089e-03, 1.16613090e-03,\n",
       "        1.23011861e-03, 1.19065430e-03, 1.30025209e-03, 1.17736810e-03,\n",
       "        1.11970154e-03, 1.56551020e-03, 8.58058212e-04, 1.05854560e-03,\n",
       "        1.21539062e-03, 1.19699518e-03, 1.23212917e-03, 1.10512271e-03,\n",
       "        1.22243332e-03, 1.27322696e-03, 1.02715297e-03, 1.21426648e-03,\n",
       "        1.35345245e-03, 1.11300942e-03, 1.19261952e-03, 1.12489120e-03,\n",
       "        1.48408195e-03, 1.40111151e-03, 1.03900103e-03, 9.18504477e-04,\n",
       "        1.04527523e-03, 1.02666691e-03, 1.13690293e-03, 1.20915615e-03,\n",
       "        1.00368590e-03, 1.28691609e-03, 1.00414759e-03, 9.55499626e-04,\n",
       "        9.01984606e-04, 1.35333304e-03, 1.41304664e-03, 1.30504091e-03,\n",
       "        1.30395325e-03, 1.07290460e-03, 1.51216077e-03, 1.43917793e-03,\n",
       "        1.40946363e-03, 9.33968047e-04, 1.57990597e-03, 6.21110551e-04,\n",
       "        1.08168069e-03, 1.40980503e-03, 1.49918477e-03, 1.50880499e-03,\n",
       "        1.32238031e-03, 1.68005782e-03, 2.23980088e-03, 1.16141992e-03,\n",
       "        5.85681344e-04, 1.26766925e-03, 9.78324892e-04, 1.46309363e-03,\n",
       "        2.13518851e-03, 1.77813462e-03, 1.17589121e-03, 1.66705009e-03,\n",
       "        1.43582903e-03, 9.57602127e-04, 1.24755292e-03, 1.24755292e-03,\n",
       "        1.24755292e-03, 1.24755287e-03, 1.24755289e-03, 1.24728036e-03,\n",
       "        1.40435686e-03, 1.14793125e-03, 1.64714705e-03, 1.24755292e-03,\n",
       "        1.24755292e-03, 1.24755292e-03, 1.24755288e-03, 1.24755289e-03,\n",
       "        1.33103780e-03, 1.50427272e-03, 8.02901376e-04, 1.52457013e-03,\n",
       "        1.24755292e-03, 1.24755292e-03, 1.24755290e-03, 1.24755289e-03,\n",
       "        1.24755385e-03, 1.24562932e-03, 1.26553464e-03, 1.43405058e-03,\n",
       "        2.22690342e-03, 1.24755292e-03, 1.24755292e-03, 1.24755288e-03,\n",
       "        1.24755290e-03, 1.24755875e-03, 1.15655276e-03, 8.64129843e-04,\n",
       "        1.95112568e-03, 9.89975016e-04, 1.24755292e-03, 1.24755292e-03,\n",
       "        1.24755290e-03, 1.24755289e-03, 1.36719621e-03, 1.30820260e-03,\n",
       "        1.32306454e-03, 1.47647596e-03, 1.14258648e-03, 1.24755292e-03,\n",
       "        1.24755290e-03, 1.24755290e-03, 1.24755296e-03, 1.24412737e-03,\n",
       "        1.36033617e-03, 1.44601111e-03, 2.73648752e-03, 9.28872797e-04,\n",
       "        1.24755292e-03, 1.24755292e-03, 1.24755290e-03, 1.24760822e-03,\n",
       "        1.51500805e-03, 1.12397725e-03, 1.81822262e-03, 1.00520489e-03,\n",
       "        1.41086249e-03, 1.24755292e-03, 1.24755289e-03, 1.24755294e-03,\n",
       "        1.14780945e-03, 1.27664402e-03, 1.26647133e-03, 1.77448797e-03,\n",
       "        8.96246805e-04, 9.25961849e-04, 1.24755289e-03, 1.24755288e-03,\n",
       "        1.24755293e-03, 1.24562932e-03, 8.24751191e-04, 1.40517670e-03,\n",
       "        4.34011639e-03, 1.39996983e-03, 8.78556244e-04, 1.38974008e-03,\n",
       "        1.27117399e-03, 1.20400838e-03, 1.40896524e-03, 1.61574356e-03,\n",
       "        1.96766546e-03, 1.38510277e-03, 1.26833186e-03, 1.09320326e-03,\n",
       "        1.93225089e-03, 1.46362525e-03, 2.17558123e-03, 1.17720676e-03,\n",
       "        1.44424807e-03, 1.43800883e-03, 1.69063878e-03, 1.60212803e-03,\n",
       "        9.52972350e-04, 1.35335214e-03, 1.00732618e-03, 1.23171842e-03,\n",
       "        1.11660740e-03, 1.35199211e-03, 1.16013890e-03, 1.38574176e-03,\n",
       "        1.49757180e-03, 1.34893069e-03, 1.72185365e-03, 1.32180742e-03,\n",
       "        1.39993182e-03, 1.52716762e-03, 1.13435267e-03, 1.31896890e-03,\n",
       "        1.20177229e-03, 1.16273466e-03, 1.34260663e-03, 1.39876223e-03,\n",
       "        1.38106853e-03, 1.36034126e-03, 1.42636651e-03, 9.82051289e-04,\n",
       "        1.46165268e-03, 1.39974793e-03, 1.34240441e-03, 1.27247211e-03,\n",
       "        1.27443568e-03, 1.36957552e-03, 1.32077322e-03, 1.20921705e-03,\n",
       "        1.24320638e-03, 1.15625010e-03, 1.34036315e-03, 1.24794317e-03,\n",
       "        1.37892534e-03, 1.31022690e-03, 1.39762244e-03, 1.31668672e-03,\n",
       "        1.19222423e-03, 1.35502006e-03, 9.77571802e-04, 1.41143776e-03,\n",
       "        1.38431844e-03, 1.36810735e-03, 1.25810916e-03, 1.47479218e-03,\n",
       "        1.34780625e-03, 1.34981511e-03, 1.15899251e-03, 1.34343318e-03,\n",
       "        1.43379592e-03, 1.24731912e-03, 1.23461442e-03, 1.33562800e-03,\n",
       "        1.20087767e-03, 1.32645177e-03, 1.44029398e-03, 1.23279719e-03,\n",
       "        1.28657425e-03, 1.31290227e-03, 1.25141830e-03, 1.11393675e-03]),\n",
       " 'rank_test_neg_log_loss': array([157, 156, 160, 177, 198, 227, 202,  19,   9, 159,  80, 167,  77,\n",
       "        253, 251, 321,  17,   8, 192, 109, 218,  60, 223, 310,  33,  12,\n",
       "          7, 194, 205, 174, 175,  59, 314,  27,  10,   6, 298, 163, 193,\n",
       "        257, 315,  20,  21,  11,   2, 286,  79, 207,  84, 173, 317,  51,\n",
       "         13,   3, 226, 270, 228, 313,  18,  23, 322,  14,   1,  72, 307,\n",
       "        318, 300,  41, 324, 303,  15,   5,  95, 255, 305, 312, 323,  52,\n",
       "        271,  16,   4, 122, 158, 166, 176,  70, 262, 283,  22, 306, 118,\n",
       "        186,  83, 100, 183, 221, 277,  24,  93, 204, 105, 201, 220, 187,\n",
       "        213, 197,  29, 280,  92, 199, 222, 225,  86, 101,  36,  26, 266,\n",
       "        108, 113, 224, 248, 208, 293,  67,  31, 288,  94, 112, 294,  88,\n",
       "         65, 241, 263,  40, 250, 180, 238, 216,  47, 311,  43, 308,  28,\n",
       "        249, 264, 242, 252, 237, 229, 247,  35,  37, 239,  73, 165, 299,\n",
       "        309,  45,  78,  57, 191, 256, 141, 141, 141, 124, 135, 115,  63,\n",
       "         48,  38, 141, 141, 141, 126, 129,  85, 107,  49,  32, 141, 141,\n",
       "        139, 133, 119, 160,  75,  30, 316, 141, 141, 125, 130, 117, 243,\n",
       "         42,  54, 292, 141, 141, 138, 128,  61,  81, 244,  44, 295, 141,\n",
       "        140, 137, 121, 164, 181,  39, 319, 278, 141, 127, 134, 116, 231,\n",
       "         46,  34, 281, 297, 141, 131, 123, 210, 182, 103,  25, 274, 261,\n",
       "        132, 136, 120, 160, 279,  64, 320, 268, 276, 178, 102, 184,  97,\n",
       "         87, 302,  96, 258, 236, 304, 291, 240, 273,  50, 234,  53, 245,\n",
       "        260, 206, 111, 195, 275, 289, 179, 265, 212, 214, 287, 209, 246,\n",
       "        296, 200,  90,  89,  62, 169,  55, 189, 114, 190, 284, 267, 232,\n",
       "        290, 110, 272,  76, 211, 185, 168, 217,  98, 219,  71, 254,  58,\n",
       "        172, 285,  66, 301,  82,  99,  68, 196, 230,  69, 282, 203, 104,\n",
       "        269, 170, 215,  74, 233, 259,  56, 188, 171, 106,  91, 235])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIAL_5_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FIVE NEG LOG LOSS RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 1000,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL FIVE NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_5_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FIVE F1 RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL FIVE F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_5_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------TRIAL FIVE ROC AUC RESULTS ---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(max_iter=7000, probability=True),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 1.0,\n",
       " 'classifier__kernel': 'rbf'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------------------------TRIAL FIVE ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_5_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 5 svm using best NEG LOG LOSS hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 5 svm using best F1 hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n",
      "Accuracy of Trial 5 svm using best ROC_AUC hyperparameters :0.927\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 5 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 5 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 5 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
